!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
!_TAG_PROGRAM_VERSION	5.8	//
ADIM	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set ADIM=%HDIM%$/;"	v
ADIM	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set ADIM=%HDIM%$/;"	v
ADIM	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set ADIM=%HDIM%$/;"	v
ALIGN	cnn/macros.h	13;"	d
ALIGN_DIM	examples/attentional.cc	/^unsigned ALIGN_DIM = 32;   \/\/ 128$/;"	v
ALIGN_DIM	ext/trainer/train_proc.h	/^unsigned ALIGN_DIM = 25;  \/\/ 1024$/;"	v
ALIGN_LAYER	cnn/macros.h	20;"	d
ALIGN_LAYER	ext/encdec/encdec.h	27;"	d
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	299;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	302;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	305;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	308;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	311;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	314;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	317;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	321;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	286;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	289;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	292;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	295;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	298;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	301;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	304;"	d	file:
ARCHITECTURE_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	308;"	d	file:
AWI	ext/dialogue/attention_with_intention.h	/^    AWI(Model& model,$/;"	f	class:cnn::AWI
AWI	ext/dialogue/attention_with_intention.h	/^class AWI : public AttentionWithIntention < Builder, Decoder > {$/;"	c	namespace:cnn
AWI_Bilinear	ext/dialogue/attention_with_intention.h	/^    AWI_Bilinear(Model& model,$/;"	f	class:cnn::AWI_Bilinear
AWI_Bilinear	ext/dialogue/attention_with_intention.h	/^class AWI_Bilinear : public AWI< Builder , Decoder> {$/;"	c	namespace:cnn
AWI_Bilinear_Simpler	ext/dialogue/attention_with_intention.h	/^    AWI_Bilinear_Simpler(Model& model,$/;"	f	class:cnn::AWI_Bilinear_Simpler
AWI_Bilinear_Simpler	ext/dialogue/attention_with_intention.h	/^class AWI_Bilinear_Simpler : public AWI_Bilinear < Builder, Decoder> {$/;"	c	namespace:cnn
AWI_Bilinear_Simpler_AE	ext/dialogue/attention_with_intention.h	/^    AWI_Bilinear_Simpler_AE(Model& model,$/;"	f	class:cnn::AWI_Bilinear_Simpler_AE
AWI_Bilinear_Simpler_AE	ext/dialogue/attention_with_intention.h	/^class AWI_Bilinear_Simpler_AE : public AWI_Bilinear_Simpler< Builder, Decoder > {$/;"	c	namespace:cnn
AWI_GeneralInputFeeding	ext/dialogue/attention_with_intention.h	/^    AWI_GeneralInputFeeding(Model& model,$/;"	f	class:cnn::AWI_GeneralInputFeeding
AWI_GeneralInputFeeding	ext/dialogue/attention_with_intention.h	/^class AWI_GeneralInputFeeding : public AWI_Bilinear_Simpler< Builder, Decoder> {$/;"	c	namespace:cnn
AWI_GeneralInputFeedingWDropout	ext/dialogue/attention_with_intention.h	/^    AWI_GeneralInputFeedingWDropout(Model& model,$/;"	f	class:cnn::AWI_GeneralInputFeedingWDropout
AWI_GeneralInputFeedingWDropout	ext/dialogue/attention_with_intention.h	/^class AWI_GeneralInputFeedingWDropout : public AWI_GeneralInputFeeding< Builder, Decoder> {$/;"	c	namespace:cnn
AWI_InputFeedingWithNNAttention	ext/dialogue/attention_with_intention.h	/^    AWI_InputFeedingWithNNAttention(Model& model,$/;"	f	class:cnn::AWI_InputFeedingWithNNAttention
AWI_InputFeedingWithNNAttention	ext/dialogue/attention_with_intention.h	/^class AWI_InputFeedingWithNNAttention: public AWI_GeneralInputFeedingWDropout< Builder, Decoder> {$/;"	c	namespace:cnn
AWI_LocalGeneralInputFeeding	ext/dialogue/attention_with_intention.h	/^    AWI_LocalGeneralInputFeeding(Model& model,$/;"	f	class:cnn::AWI_LocalGeneralInputFeeding
AWI_LocalGeneralInputFeeding	ext/dialogue/attention_with_intention.h	/^class AWI_LocalGeneralInputFeeding: public AWI_Bilinear_Simpler< Builder, Decoder> {$/;"	c	namespace:cnn
AccessElement	cnn/tensor.cc	/^    cnn::real TensorTools::AccessElement(const Tensor& v, const Dim& index) {$/;"	f	class:cnn::TensorTools
AccessElement	cnn/tensor.cc	/^    cnn::real TensorTools::AccessElement(const Tensor& v, int index) {$/;"	f	class:cnn::TensorTools
AccumulateScore	cnn/metric-util.h	/^    void AccumulateScore(const vector<string> & refTokens, const vector<string> & hypTokens)$/;"	f	class:BleuMetric
AdadeltaTrainer	cnn/training.h	/^  explicit AdadeltaTrainer(Model* m, cnn::real lam = 1e-6, cnn::real eps = 1e-6, cnn::real rho = 0.95) :$/;"	f	struct:cnn::AdadeltaTrainer
AdadeltaTrainer	cnn/training.h	/^struct AdadeltaTrainer : public Trainer {$/;"	s	namespace:cnn
AdagradTrainer	cnn/training.h	/^  explicit AdagradTrainer(Model* m, cnn::real lam = 1e-6, cnn::real e0 = 0.1, cnn::real eps = 1e-20) :$/;"	f	struct:cnn::AdagradTrainer
AdagradTrainer	cnn/training.h	/^struct AdagradTrainer : public Trainer {$/;"	s	namespace:cnn
AdamTrainer	cnn/training.h	/^  explicit AdamTrainer(Model* m, cnn::real lambda = 1e-6, cnn::real alpha = 0.001, cnn::real beta_1 = 0.9, cnn::real beta_2 = 0.999, cnn::real eps = 1e-8) :$/;"	f	struct:cnn::AdamTrainer
AdamTrainer	cnn/training.h	/^struct AdamTrainer : public Trainer {$/;"	s	namespace:cnn
AddVectorToAllColumns	cnn/conv.h	/^  explicit AddVectorToAllColumns(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::AddVectorToAllColumns
AddVectorToAllColumns	cnn/conv.h	/^struct AddVectorToAllColumns : public Node {$/;"	s	namespace:cnn
AffineTransform	cnn/nodes.h	/^  template <typename T> explicit AffineTransform(const T& a) : Node(a) {}$/;"	f	struct:cnn::AffineTransform
AffineTransform	cnn/nodes.h	/^struct AffineTransform : public Node {$/;"	s	namespace:cnn
AlignedMemoryPool	cnn/aligned-mem-pool.h	/^  explicit AlignedMemoryPool(unsigned long cap, bool b_allocate_on_cpu_only = false) {$/;"	f	class:cnn::AlignedMemoryPool
AlignedMemoryPool	cnn/aligned-mem-pool.h	/^class AlignedMemoryPool {$/;"	c	namespace:cnn
AllocateShadowLookupParameters	cnn/shadow-params.cc	/^vector<ShadowLookupParameters> AllocateShadowLookupParameters(const Model& m) {$/;"	f	namespace:cnn
AllocateShadowParameters	cnn/shadow-params.cc	/^vector<ShadowParameters> AllocateShadowParameters(const Model& m) {$/;"	f	namespace:cnn
AttMultiSource_LinearEncoder	ext/dialogue/attention_with_intention.h	/^    AttMultiSource_LinearEncoder(Model& model,$/;"	f	class:cnn::AttMultiSource_LinearEncoder
AttMultiSource_LinearEncoder	ext/dialogue/attention_with_intention.h	/^class AttMultiSource_LinearEncoder : public MultiSource_LinearEncoder <Builder, Decoder>{$/;"	c	namespace:cnn
AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature	ext/dialogue/attention_with_intention.h	/^    AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature(Model& model,$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature	ext/dialogue/attention_with_intention.h	/^class AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature : public AttMultiSource_LinearEncoder <Builder, Decoder>{$/;"	c	namespace:cnn
AttMultiSource_LinearEncoder_WithMaxEntropyFeature	ext/dialogue/attention_with_intention.h	/^    AttMultiSource_LinearEncoder_WithMaxEntropyFeature(Model& model,$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
AttMultiSource_LinearEncoder_WithMaxEntropyFeature	ext/dialogue/attention_with_intention.h	/^class AttMultiSource_LinearEncoder_WithMaxEntropyFeature : public AttMultiSource_LinearEncoder <Builder, Decoder>{$/;"	c	namespace:cnn
AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch	ext/dialogue/attention_with_intention.h	/^    AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch(Model& model,$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch
AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch	ext/dialogue/attention_with_intention.h	/^class AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch : public AttMultiSource_LinearEncoder_WithMaxEntropyFeature<Builder, Decoder>{$/;"	c	namespace:cnn
AttentionWithIntention	ext/dialogue/attention_with_intention.h	/^AttentionWithIntention<Builder, Decoder>::AttentionWithIntention(cnn::Model& model,$/;"	f	class:cnn::AttentionWithIntention
AttentionWithIntention	ext/dialogue/attention_with_intention.h	/^class AttentionWithIntention : public DialogueBuilder<Builder, Decoder>{$/;"	c	namespace:cnn
AttentionWithIntentionModel	ext/dialogue/dialogue_process.h	/^        explicit AttentionWithIntentionModel(cnn::Model& model,$/;"	f	class:cnn::AttentionWithIntentionModel
AttentionWithIntentionModel	ext/dialogue/dialogue_process.h	/^    class AttentionWithIntentionModel : public DialogueProcessInfo<DBuilder>{$/;"	c	namespace:cnn
AttentionalConversation	ext/dialogue/dialogue_process.h	/^        explicit AttentionalConversation(cnn::Model& model,$/;"	f	class:cnn::AttentionalConversation
AttentionalConversation	ext/dialogue/dialogue_process.h	/^    class AttentionalConversation: public DialogueProcessInfo<DBuilder>{$/;"	c	namespace:cnn
AttentionalModel	examples/attentional.h	/^AttentionalModel<Builder>::AttentionalModel(cnn::Model& model,$/;"	f	class:cnn::AttentionalModel
AttentionalModel	examples/attentional.h	/^struct AttentionalModel {$/;"	s	namespace:cnn
Average	cnn/nodes.h	/^  template <typename T> explicit Average(const T& a) : Node(a) {$/;"	f	struct:cnn::Average
Average	cnn/nodes.h	/^struct Average : public Node {$/;"	s	namespace:cnn
BC	cnn/deep-lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon2	file:
BC	cnn/dglstm.cc	/^        X2O, H2O, C2O, BO, X2C, H2C, BC, X2K, C2K, Q2K, BK, STAB, X2K0 };$/;"	e	enum:cnn::__anon3	file:
BC	cnn/lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon6	file:
BC	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
BC	cnn/treelstm.cc	/^enum { X2I, C2I, BI, X2F, C2F, BF, X2O, C2O, BO, X2C, BC };$/;"	e	enum:cnn::__anon16	file:
BE	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
BF	cnn/dglstm.cc	/^        X2F, H2F, C2F, BF, $/;"	e	enum:cnn::__anon3	file:
BF	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
BF	cnn/treelstm.cc	/^enum { X2I, C2I, BI, X2F, C2F, BF, X2O, C2O, BO, X2C, BC };$/;"	e	enum:cnn::__anon16	file:
BGAMMA	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
BH	cnn/gru.cc	/^enum { X2Z, H2Z, BZ, X2R, H2R, BR, X2H, H2H, BH };$/;"	e	enum:cnn::__anon5	file:
BI	cnn/deep-lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon2	file:
BI	cnn/dglstm.cc	/^    enum { X2I, H2I, C2I, BI, $/;"	e	enum:cnn::__anon3	file:
BI	cnn/lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon6	file:
BI	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
BI	cnn/treelstm.cc	/^enum { X2I, C2I, BI, X2F, C2F, BF, X2O, C2O, BO, X2C, BC };$/;"	e	enum:cnn::__anon16	file:
BINDIR	exp/encdec/encdec.bat	/^set BINDIR=C:\\dev\\cnn2\\msbuild\\examples\\Release$/;"	v
BINDIR	exp/lm/rnnlm2.bat	/^set BINDIR=C:\\dev\\cnn2\\msbuildcuda\\examples\\Release$/;"	v
BINDIR	exp/lm/rnnlm2.bat	/^set BINDIR=C:\\dev\\cnn\\msbuildcuda\\examples\\Release$/;"	v
BINDIR	exp/lm/rnnlm2.dglstm.bat	/^set BINDIR=\\\\gcr\\scratch\\b99\\kaisheny\\bin\\windows$/;"	v
BINDIR	exp/lm/rnnlm2_cls.bat	/^set BINDIR=C:\\dev\\mycnn\\msbuildx64\\examples\\Release$/;"	v
BINDIR	exp/lm/rnnlm2_cls_tst.bat	/^set BINDIR=C:\\dev\\mycnn\\msbuildx64\\examples\\Release$/;"	v
BK	cnn/dglstm.cc	/^        X2O, H2O, C2O, BO, X2C, H2C, BC, X2K, C2K, Q2K, BK, STAB, X2K0 };$/;"	e	enum:cnn::__anon3	file:
BO	cnn/deep-lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon2	file:
BO	cnn/dglstm.cc	/^        X2O, H2O, C2O, BO, X2C, H2C, BC, X2K, C2K, Q2K, BK, STAB, X2K0 };$/;"	e	enum:cnn::__anon3	file:
BO	cnn/lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon6	file:
BO	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
BO	cnn/treelstm.cc	/^enum { X2I, C2I, BI, X2F, C2F, BF, X2O, C2O, BO, X2C, BC };$/;"	e	enum:cnn::__anon16	file:
BOOST_AUTO_TEST_CASE	cnn/tests/test_edges.cc	/^BOOST_AUTO_TEST_CASE(EColumnConcat)$/;"	f
BOOST_AUTO_TEST_CASE	cnn/tests/test_edges.cc	/^BOOST_AUTO_TEST_CASE(EConstantMinus) {$/;"	f
BOOST_AUTO_TEST_CASE	cnn/tests/test_edges.cc	/^BOOST_AUTO_TEST_CASE(ELogisticSigmoid) {$/;"	f
BOOST_AUTO_TEST_CASE	cnn/tests/test_edges.cc	/^BOOST_AUTO_TEST_CASE(EMatrixMultiply) {$/;"	f
BOOST_AUTO_TEST_CASE	cnn/tests/test_edges.cc	/^BOOST_AUTO_TEST_CASE(EMultilinear) {$/;"	f
BOOST_AUTO_TEST_CASE	cnn/tests/test_edges.cc	/^BOOST_AUTO_TEST_CASE(ERowConcat)$/;"	f
BOOST_AUTO_TEST_CASE	cnn/tests/test_edges.cc	/^BOOST_AUTO_TEST_CASE(ESoftmaxUnif) {$/;"	f
BOOST_AUTO_TEST_CASE	cnn/tests/test_edges.cc	/^BOOST_AUTO_TEST_CASE(ESqrL2)$/;"	f
BOOST_AUTO_TEST_CASE	cnn/tests/test_edges.cc	/^BOOST_AUTO_TEST_CASE(ETanh) {$/;"	f
BOOST_AUTO_TEST_CASE	cnn/tests/test_edges.cc	/^BOOST_AUTO_TEST_CASE(MatrixVector) {$/;"	f
BOOST_AUTO_TEST_CASE	cnn/tests/test_edges.cc	/^BOOST_AUTO_TEST_CASE(TensorInner3D_1D) {$/;"	f
BOOST_AUTO_TEST_CASE	cnn/tests/test_init.cc	/^BOOST_AUTO_TEST_CASE(BernoulliInit) {$/;"	f
BOOST_AUTO_TEST_CASE	cnn/tests/test_init.cc	/^BOOST_AUTO_TEST_CASE(EOrthonormalRandom)$/;"	f
BOOST_AUTO_TEST_CASE	cnn/tests/test_init.cc	/^BOOST_AUTO_TEST_CASE(Rand01) {$/;"	f
BOOST_TEST_DYN_LINK	cnn/tests/test_edges.cc	1;"	d	file:
BOOST_TEST_DYN_LINK	cnn/tests/test_init.cc	1;"	d	file:
BOOST_TEST_MODULE	cnn/tests/test_edges.cc	2;"	d	file:
BOOST_TEST_MODULE	cnn/tests/test_init.cc	2;"	d	file:
BR	cnn/gru.cc	/^enum { X2Z, H2Z, BZ, X2R, H2R, BR, X2H, H2H, BH };$/;"	e	enum:cnn::__anon5	file:
BXI	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
BZ	cnn/gru.cc	/^enum { X2Z, H2Z, BZ, X2R, H2R, BR, X2H, H2H, BH };$/;"	e	enum:cnn::__anon5	file:
BinaryLogLoss	cnn/nodes.h	/^  BinaryLogLoss(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::BinaryLogLoss
BinaryLogLoss	cnn/nodes.h	/^struct BinaryLogLoss : public Node {$/;"	s	namespace:cnn
BleuMetric	cnn/metric-util.h	/^    BleuMetric()$/;"	f	class:BleuMetric
BleuMetric	cnn/metric-util.h	/^class BleuMetric$/;"	c
BlockDropout	cnn/nodes.h	/^  explicit BlockDropout(const std::initializer_list<VariableIndex>& a, cnn::real p) : Node(a), dropout_probability(p) {}$/;"	f	struct:cnn::BlockDropout
BlockDropout	cnn/nodes.h	/^struct BlockDropout : public Node {$/;"	s	namespace:cnn
BrevityPenalty	cnn/metric-util.h	/^    cnn::real BrevityPenalty(LossStats stats)$/;"	f	class:BleuMetric
BuildClassifier	examples/convmodel.h	/^        Expression BuildClassifier(const vector<int>& x, ComputationGraph& cg, bool for_training) {$/;"	f	struct:cnn::ConvNet
BuildClassifier	examples/textcat.cc	/^  Expression BuildClassifier(const vector<int>& x, ComputationGraph& cg) {$/;"	f	struct:NeuralBagOfWords
BuildClassifier	examples/textcat.cc	/^  Expression BuildClassifier(const vector<int>& x, ComputationGraph& cg, bool for_training) {$/;"	f	struct:ConvNet
BuildComputationGraph	examples/mp.cc	/^void BuildComputationGraph(ComputationGraph& cg, ModelParameters& model_parameters, cnn::real* x_value, cnn::real* y_value) {$/;"	f
BuildGraph	examples/attentional.h	/^Expression AttentionalModel<Builder>::BuildGraph(const std::vector<int> &source,$/;"	f	class:cnn::AttentionalModel
BuildGraph	examples/encdec.cc	/^  Expression BuildGraph(const vector<int>& insent, const vector<int>& osent, ComputationGraph& cg) {$/;"	f	struct:EncoderDecoder
BuildGraph	examples/mem_seq2seq_encdec.cc	/^  Expression BuildGraph(const Sentence& insent, const Sentence& osent, ComputationGraph& cg) {$/;"	f	struct:EncoderDecoder
BuildGraph	examples/regattentional.h	/^Expression RegAttentionalModel<Builder>::BuildGraph( FCorpus &source,$/;"	f	class:cnn::RegAttentionalModel
BuildGraph	examples/regattentional.h	/^Expression RegAttentionalModel<Builder>::BuildGraph(const std::vector<vector<cnn::real>> &source,$/;"	f	class:cnn::RegAttentionalModel
BuildGraph	examples/seq2seq_encdec.cc	/^  Expression BuildGraph(const Sentence& insent, const Sentence& osent, ComputationGraph& cg) {$/;"	f	struct:EncoderDecoder
BuildGraphWithoutNormalization	examples/attentional.h	/^vector<Expression> AttentionalModel<Builder>::BuildGraphWithoutNormalization(const std::vector<int> &source,$/;"	f	class:cnn::AttentionalModel
BuildLMGraph	examples/poisson-regression.cc	/^  Expression BuildLMGraph(const vector<int>& sent, unsigned len, ComputationGraph& cg, bool flag = false) {$/;"	f	struct:RNNLengthPredictor
BuildLMGraph	examples/rnnlm-aevb.cc	/^  Expression BuildLMGraph(const vector<int>& sent, ComputationGraph& cg, bool flag = false) {$/;"	f	struct:RNNLanguageModel
BuildLMGraph	examples/rnnlm.cc	/^  Expression BuildLMGraph(const vector<int>& sent, ComputationGraph& cg) {$/;"	f	struct:RNNLanguageModel
BuildLMGraph	examples/rnnlm2.cc	/^  Expression BuildLMGraph(const vector<int>& sent, ComputationGraph& cg) {$/;"	f	struct:RNNLanguageModel
BuildLMGraph	examples/rnnlm2_cls_based.cc	/^  Expression BuildLMGraph(const vector<int>& sent, ComputationGraph& cg) {$/;"	f	struct:RNNLanguageModel
BuildLMGraph	examples/skiprnnlm.cc	/^    Expression BuildLMGraph(const Document& doc, ComputationGraph& cg) {$/;"	f	struct:RNNSkipLM
BuildTaggingGraph	examples/tag-bilstm.cc	/^  Expression BuildTaggingGraph(const vector<int>& sent, const vector<int>& tags, ComputationGraph& cg, cnn::real* cor = 0, unsigned* ntagged = 0) {$/;"	f	struct:RNNLanguageModel
C2F	cnn/dglstm.cc	/^        X2F, H2F, C2F, BF, $/;"	e	enum:cnn::__anon3	file:
C2F	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
C2F	cnn/treelstm.cc	/^enum { X2I, C2I, BI, X2F, C2F, BF, X2O, C2O, BO, X2C, BC };$/;"	e	enum:cnn::__anon16	file:
C2I	cnn/deep-lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon2	file:
C2I	cnn/dglstm.cc	/^    enum { X2I, H2I, C2I, BI, $/;"	e	enum:cnn::__anon3	file:
C2I	cnn/lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon6	file:
C2I	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
C2I	cnn/treelstm.cc	/^enum { X2I, C2I, BI, X2F, C2F, BF, X2O, C2O, BO, X2C, BC };$/;"	e	enum:cnn::__anon16	file:
C2K	cnn/dglstm.cc	/^        X2O, H2O, C2O, BO, X2C, H2C, BC, X2K, C2K, Q2K, BK, STAB, X2K0 };$/;"	e	enum:cnn::__anon3	file:
C2O	cnn/deep-lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon2	file:
C2O	cnn/dglstm.cc	/^        X2O, H2O, C2O, BO, X2C, H2C, BC, X2K, C2K, Q2K, BK, STAB, X2K0 };$/;"	e	enum:cnn::__anon3	file:
C2O	cnn/lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon6	file:
C2O	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
C2O	cnn/treelstm.cc	/^enum { X2I, C2I, BI, X2F, C2F, BF, X2O, C2O, BO, X2C, BC };$/;"	e	enum:cnn::__anon16	file:
C2WBuilder	cnn/c2w.h	/^  explicit C2WBuilder(int vocab_size,$/;"	f	struct:cnn::C2WBuilder
C2WBuilder	cnn/c2w.h	/^struct C2WBuilder {$/;"	s	namespace:cnn
CHECK_CUDNN	cnn/cuda.h	55;"	d
CLIP	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set CLIP=5.0$/;"	v
CLIP	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set CLIP=5.0$/;"	v
CLIP	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set CLIP=5.0$/;"	v
CMAKE_BINARY_DIR	build/Makefile	/^CMAKE_BINARY_DIR = \/data\/kf_grp\/blpeng\/code\/code_dev\/cnn\/build$/;"	m
CMAKE_BINARY_DIR	build/cnn/Makefile	/^CMAKE_BINARY_DIR = \/data\/kf_grp\/blpeng\/code\/code_dev\/cnn\/build$/;"	m
CMAKE_BINARY_DIR	build/conversation/dev/src/Makefile	/^CMAKE_BINARY_DIR = \/data\/kf_grp\/blpeng\/code\/code_dev\/cnn\/build$/;"	m
CMAKE_BINARY_DIR	build/examples/Makefile	/^CMAKE_BINARY_DIR = \/data\/kf_grp\/blpeng\/code\/code_dev\/cnn\/build$/;"	m
CMAKE_COMMAND	build/Makefile	/^CMAKE_COMMAND = \/usr\/bin\/cmake$/;"	m
CMAKE_COMMAND	build/cnn/Makefile	/^CMAKE_COMMAND = \/usr\/bin\/cmake$/;"	m
CMAKE_COMMAND	build/conversation/dev/src/Makefile	/^CMAKE_COMMAND = \/usr\/bin\/cmake$/;"	m
CMAKE_COMMAND	build/examples/Makefile	/^CMAKE_COMMAND = \/usr\/bin\/cmake$/;"	m
CMAKE_EDIT_COMMAND	build/Makefile	/^CMAKE_EDIT_COMMAND = \/usr\/bin\/ccmake$/;"	m
CMAKE_EDIT_COMMAND	build/cnn/Makefile	/^CMAKE_EDIT_COMMAND = \/usr\/bin\/ccmake$/;"	m
CMAKE_EDIT_COMMAND	build/conversation/dev/src/Makefile	/^CMAKE_EDIT_COMMAND = \/usr\/bin\/ccmake$/;"	m
CMAKE_EDIT_COMMAND	build/examples/Makefile	/^CMAKE_EDIT_COMMAND = \/usr\/bin\/ccmake$/;"	m
CMAKE_SOURCE_DIR	build/Makefile	/^CMAKE_SOURCE_DIR = \/data\/kf_grp\/blpeng\/code\/code_dev\/cnn$/;"	m
CMAKE_SOURCE_DIR	build/cnn/Makefile	/^CMAKE_SOURCE_DIR = \/data\/kf_grp\/blpeng\/code\/code_dev\/cnn$/;"	m
CMAKE_SOURCE_DIR	build/conversation/dev/src/Makefile	/^CMAKE_SOURCE_DIR = \/data\/kf_grp\/blpeng\/code\/code_dev\/cnn$/;"	m
CMAKE_SOURCE_DIR	build/examples/Makefile	/^CMAKE_SOURCE_DIR = \/data\/kf_grp\/blpeng\/code\/code_dev\/cnn$/;"	m
CMDT	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set CMDT=AWI_InputFeedingWithNNAttention$/;"	v
CMDT	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set CMDT=AWI_InputFeedingWithNNAttention$/;"	v
CMDT	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set CMDT=AWI_InputFeedingWithNNAttention$/;"	v
CNN_ALIGN	cnn/macros.h	14;"	d
CNN_ALIGNED_MEM_POOL_H	cnn/aligned-mem-pool.h	2;"	d
CNN_C2W_H_	cnn/c2w.h	2;"	d
CNN_CNN_H_	cnn/cnn.h	2;"	d
CNN_CONFIG_H_	build/config.h	2;"	d
CNN_CONV_H_	cnn/conv.h	2;"	d
CNN_CUDA_H	cnn/cuda.h	2;"	d
CNN_DECODE_H_	cnn/decode.h	2;"	d
CNN_DEEP_LSTM_H_	cnn/deep-lstm.h	2;"	d
CNN_DEVICE_FUNC	cnn/functors.h	8;"	d
CNN_DEVICE_MIN	cnn/functors.h	9;"	d
CNN_DICT_H_	cnn/dict.h	2;"	d
CNN_DIM_H	cnn/dim.h	2;"	d
CNN_EIGEN_INIT_H	cnn/init.h	2;"	d
CNN_EIGEN_RANDOM_H	cnn/random.h	2;"	d
CNN_EIGEN_TENSOR_H	cnn/tensor.h	2;"	d
CNN_EXCEPT_H_	cnn/except.h	2;"	d
CNN_EXEC_H	cnn/exec.h	2;"	d
CNN_EXPF	cnn/functors.h	45;"	d
CNN_GPU_FUNCTORS_H	cnn/functors.h	2;"	d
CNN_GPU_KERNELS_H	cnn/gpu-kernels.h	2;"	d
CNN_GPU_OPS_H	cnn/gpu-ops.h	2;"	d
CNN_GRAD_CHECK_H	cnn/grad-check.h	2;"	d
CNN_GRAPH_H	cnn/graph.h	2;"	d
CNN_GRU_H_	cnn/gru.h	2;"	d
CNN_HELPER_H_	cnn/cnn-helper.h	2;"	d
CNN_LSTM_H_	cnn/lstm.h	2;"	d
CNN_MAX_TENSOR_DIM	cnn/dim.h	12;"	d
CNN_NODES_H_	cnn/nodes.h	2;"	d
CNN_PARAM_NODES_H_	cnn/param-nodes.h	2;"	d
CNN_RNN_H_	cnn/rnn.h	2;"	d
CNN_RNN_STATE_MACHINE_H_	cnn/rnn-state-machine.h	2;"	d
CNN_SAXE_INIT_H_	cnn/saxe-init.h	2;"	d
CNN_SHADOW_PARAMS_H	cnn/shadow-params.h	2;"	d
CNN_TEST_UTILS_H_	cnn/tests/test_utils.h	2;"	d
CNN_TRAINING_H_	cnn/training.h	2;"	d
CNN_TREELSTM_H_	cnn/treelstm.h	2;"	d
CNN_XFUNCTORS_H	cnn/simd-functors.h	2;"	d
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	107;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	112;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	119;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	122;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	125;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	133;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	13;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	152;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	160;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	171;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	178;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	195;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	198;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	201;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	24;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	32;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	38;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	44;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	50;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	56;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	70;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	77;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	85;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	88;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	90;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	99;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	104;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	112;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	117;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	124;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	127;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	12;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	135;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	154;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	162;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	165;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	182;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	185;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	188;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	18;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	29;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	37;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	43;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	49;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	55;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	61;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	75;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	82;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	90;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	93;"	d	file:
COMPILER_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	95;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	100;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	108;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	114;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	126;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	135;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	154;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	15;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	173;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	181;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	186;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	25;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	33;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	39;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	46;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	52;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	59;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	64;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	72;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	79;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	93;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	105;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	113;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	119;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	128;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	137;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	14;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	156;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	168;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	173;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	20;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	30;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	38;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	44;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	51;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	57;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	64;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	69;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	77;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	84;"	d	file:
COMPILER_VERSION_MAJOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	98;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	101;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	109;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	115;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	127;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	136;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	155;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	16;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	174;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	182;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	187;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	26;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	34;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	40;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	47;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	53;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	60;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	65;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	73;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	80;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	94;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	106;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	114;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	120;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	129;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	138;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	157;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	15;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	169;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	174;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	21;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	31;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	39;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	45;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	52;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	58;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	65;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	70;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	78;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	85;"	d	file:
COMPILER_VERSION_MINOR	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	99;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	103;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	116;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	129;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	140;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	143;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	156;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	175;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	17;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	183;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	188;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	28;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	35;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	41;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	61;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	66;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	74;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	81;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	95;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	100;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	108;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	121;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	131;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	142;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	145;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	158;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	170;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	175;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	22;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	33;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	40;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	46;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	66;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	71;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	79;"	d	file:
COMPILER_VERSION_PATCH	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	86;"	d	file:
COMPILER_VERSION_TWEAK	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	147;"	d	file:
COMPILER_VERSION_TWEAK	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	20;"	d	file:
COMPILER_VERSION_TWEAK	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	149;"	d	file:
COMPILER_VERSION_TWEAK	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	25;"	d	file:
CPUDEVICE	cnn/macros.h	52;"	d
CREATED	cnn/rnn-state-machine.h	/^enum RNNState {CREATED, GRAPH_READY, READING_INPUT};$/;"	e	enum:cnn::RNNState
CUBLAS_CHECK	cnn/cuda.h	23;"	d
CUDAMatrixMultiply	cnn/nodes.cc	/^inline void CUDAMatrixMultiply(const Tensor& l, const Tensor& r, Tensor& y, const cnn::real* acc_scalar) {$/;"	f	namespace:cnn
CUDA_CHECK	cnn/cuda.h	14;"	d
CheckGrad	cnn/grad-check.cc	/^void CheckGrad(Model& m, ComputationGraph& g) {$/;"	f	namespace:cnn
ClassificationBasedMultiSourceDialogue	ext/dialogue/dialogue_process.h	/^        explicit ClassificationBasedMultiSourceDialogue(cnn::Model& model,$/;"	f	class:cnn::ClassificationBasedMultiSourceDialogue
ClassificationBasedMultiSourceDialogue	ext/dialogue/dialogue_process.h	/^    class ClassificationBasedMultiSourceDialogue : public DialogueProcessInfo<DBuilder>{$/;"	c	namespace:cnn
ClassificationEncoderDecoder	ext/ir/ir.h	/^        ClassificationEncoderDecoder(Model& model,$/;"	f	class:cnn::ClassificationEncoderDecoder
ClassificationEncoderDecoder	ext/ir/ir.h	/^    class ClassificationEncoderDecoder: public DialogueBuilder<Builder, Decoder>{$/;"	c	namespace:cnn
ClassificationTrainProcess	ext/trainer/train_proc.h	/^    ClassificationTrainProcess(){$/;"	f	class:ClassificationTrainProcess
ClassificationTrainProcess	ext/trainer/train_proc.h	/^class ClassificationTrainProcess : public TrainProcess<Proc>{$/;"	c
Clear	cnn/dict.h	/^    void Clear() { words_.clear(); d_.clear(); }$/;"	f	class:cnn::stId2String
Clear	cnn/dict.h	/^  void Clear() { words_.clear(); d_.clear();  }$/;"	f	class:cnn::stDict
Clear	ext/ngram/ngram.h	/^    void Clear()$/;"	f	class:nGram
ClsBasedBuilder	cnn/approximator.cc	/^    ClsBasedBuilder::ClsBasedBuilder($/;"	f	class:cnn::ClsBasedBuilder
ClsBasedBuilder	cnn/approximator.h	/^        ClsBasedBuilder() { dparallel = 1; }$/;"	f	class:cnn::ClsBasedBuilder
ClsBasedBuilder	cnn/approximator.h	/^        ClsBasedBuilder(const ClsBasedBuilder& ref)$/;"	f	class:cnn::ClsBasedBuilder
ClsBasedBuilder	cnn/approximator.h	/^    class ClsBasedBuilder{$/;"	c	namespace:cnn
ClsBasedMultiSource_LinearEncoder	ext/dialogue/attention_with_intention.h	/^    ClsBasedMultiSource_LinearEncoder(Model& model,$/;"	f	class:cnn::ClsBasedMultiSource_LinearEncoder
ClsBasedMultiSource_LinearEncoder	ext/dialogue/attention_with_intention.h	/^class ClsBasedMultiSource_LinearEncoder : public MultiSource_LinearEncoder <Builder, Decoder>{$/;"	c	namespace:cnn
ColumnSlices	cnn/nodes.h	/^    explicit ColumnSlices(const std::initializer_list<VariableIndex>& a, unsigned rows, unsigned start_column, unsigned end_column) : Node(a), start_column(start_column), rows(rows), end_column(end_column) {}$/;"	f	struct:cnn::ColumnSlices
ColumnSlices	cnn/nodes.h	/^struct ColumnSlices : public Node {$/;"	s	namespace:cnn
CompareHypothesis	cnn/decode.h	/^struct CompareHypothesis$/;"	s	namespace:cnn
CompareHypothesis	examples/attentional.h	/^struct CompareHypothesis$/;"	s	namespace:cnn
CompareHypothesis	examples/cxtattentional.h	/^struct CompareHypothesis$/;"	s	namespace:cnn
ComputationGraph	cnn/cnn.cc	/^ComputationGraph::ComputationGraph() : $/;"	f	class:cnn::ComputationGraph
ComputationGraph	cnn/cnn.h	/^struct ComputationGraph {$/;"	s	namespace:cnn
ComputeNgramModel	ext/ngram/ngram.h	/^    void ComputeNgramModel()$/;"	f	class:nGram
Concatenate	cnn/nodes.h	/^  template <typename T> explicit Concatenate(const T& a) : Node(a) {}$/;"	f	struct:cnn::Concatenate
Concatenate	cnn/nodes.h	/^struct Concatenate : public Node {$/;"	s	namespace:cnn
ConcatenateColumns	cnn/nodes.h	/^    template <typename T> explicit ConcatenateColumns(const T& a) : Node(a) { aux_mem = nullptr; }$/;"	f	struct:cnn::ConcatenateColumns
ConcatenateColumns	cnn/nodes.h	/^struct ConcatenateColumns : public Node {$/;"	s	namespace:cnn
ConstParameterNode	cnn/param-nodes.h	/^  explicit ConstParameterNode(Parameters* p) : dim(p->dim), params(p) {}$/;"	f	struct:cnn::ConstParameterNode
ConstParameterNode	cnn/param-nodes.h	/^struct ConstParameterNode : public Node {$/;"	s	namespace:cnn
ConstScalarMultiply	cnn/nodes.h	/^  explicit ConstScalarMultiply(const std::initializer_list<VariableIndex>& a, cnn::real alpha) : Node(a), alpha(alpha) {}$/;"	f	struct:cnn::ConstScalarMultiply
ConstScalarMultiply	cnn/nodes.h	/^struct ConstScalarMultiply : public Node {$/;"	s	namespace:cnn
Constant	cnn/tensor.cc	/^    void TensorTools::Constant(Tensor& d, cnn::real c) {$/;"	f	class:cnn::TensorTools
ConstantMinusX	cnn/nodes.h	/^  explicit ConstantMinusX(const std::initializer_list<VariableIndex>& a, cnn::real o) : Node(a), c(o) {}$/;"	f	struct:cnn::ConstantMinusX
ConstantMinusX	cnn/nodes.h	/^struct ConstantMinusX : public Node {$/;"	s	namespace:cnn
ConstantPlusX	cnn/nodes.h	/^  explicit ConstantPlusX(const std::initializer_list<VariableIndex>& a, cnn::real o) : Node(a), c(o) {}$/;"	f	struct:cnn::ConstantPlusX
ConstantPlusX	cnn/nodes.h	/^struct ConstantPlusX : public Node {$/;"	s	namespace:cnn
Contains	cnn/dict.h	/^    inline bool Contains(const T& words) {$/;"	f	class:cnn::stId2String
Contains	cnn/dict.h	/^    inline bool Contains(const int& id) {$/;"	f	class:cnn::stId2String
Contains	cnn/dict.h	/^  inline bool Contains(const T& words) {$/;"	f	class:cnn::stDict
Conv1DNarrow	cnn/conv.h	/^  explicit Conv1DNarrow(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Conv1DNarrow
Conv1DNarrow	cnn/conv.h	/^struct Conv1DNarrow : public Node {$/;"	s	namespace:cnn
Conv1DWide	cnn/conv.h	/^  explicit Conv1DWide(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Conv1DWide
Conv1DWide	cnn/conv.h	/^struct Conv1DWide : public Node {$/;"	s	namespace:cnn
ConvLayer	examples/convmodel.h	/^        ConvLayer() {};$/;"	f	struct:cnn::ConvLayer
ConvLayer	examples/convmodel.h	/^        ConvLayer(Model&m, int in_rows, int k_fold_rows, int filter_width, int in_nfmaps, int out_nfmaps) :$/;"	f	struct:cnn::ConvLayer
ConvLayer	examples/convmodel.h	/^    struct ConvLayer {$/;"	s	namespace:cnn
ConvLayer	examples/textcat.cc	/^  ConvLayer(Model&m, int in_rows, int k_fold_rows, int filter_width, int in_nfmaps, int out_nfmaps) :$/;"	f	struct:ConvLayer
ConvLayer	examples/textcat.cc	/^struct ConvLayer {$/;"	s	file:
ConvNet	examples/convmodel.h	/^        explicit ConvNet(Model& m, unsigned vocab_size, unsigned input_dim, unsigned output_dim) :$/;"	f	struct:cnn::ConvNet
ConvNet	examples/convmodel.h	/^    struct ConvNet {$/;"	s	namespace:cnn
ConvNet	examples/textcat.cc	/^  explicit ConvNet(Model& m) :$/;"	f	struct:ConvNet
ConvNet	examples/textcat.cc	/^struct ConvNet {$/;"	s	file:
Convert	cnn/dict.h	/^    inline T Convert(const int& id)$/;"	f	class:cnn::stId2String
Convert	cnn/dict.h	/^    inline int Convert(const int & id, const T& word)$/;"	f	class:cnn::stId2String
Convert	cnn/dict.h	/^  inline const T& Convert(const int& id) const {$/;"	f	class:cnn::stDict
Convert	cnn/dict.h	/^  inline int Convert(const T& word, bool backofftounk = false)$/;"	f	class:cnn::stDict
CopyElements	cnn/tensor.cc	/^    void TensorTools::CopyElements(Tensor& v, const Tensor& v_src) {$/;"	f	class:cnn::TensorTools
Corpus	cnn/data-util.h	/^typedef vector<Dialogue> Corpus;$/;"	t
Corpus	examples/attentional.cc	/^typedef vector<SentencePair> Corpus;$/;"	t	file:
Corpus	examples/mem_seq2seq_encdec.cc	/^typedef vector<SentencePair> Corpus;  $/;"	t	file:
Corpus	examples/seq2seq_encdec.cc	/^typedef vector<SentencePair> Corpus;  $/;"	t	file:
Corpus	examples/skiprnnlm.cc	/^typedef vector<Document> Corpus;$/;"	t	file:
CorpusWithClassId	cnn/data-util.h	/^typedef vector<DialogueWithClassId> CorpusWithClassId;$/;"	t
Cost	cnn/simd-functors.h	/^    Cost = 5 * NumTraits<Scalar>::MulCost,$/;"	e	enum:Eigen::internal::functor_traits::__anon13
Cost	cnn/simd-functors.h	/^    Cost = NumTraits<Scalar>::AddCost * 2 + NumTraits<Scalar>::MulCost * 6,$/;"	e	enum:Eigen::internal::functor_traits::__anon10
Cost	cnn/simd-functors.h	/^    Cost = NumTraits<Scalar>::AddCost * 2,$/;"	e	enum:Eigen::internal::functor_traits::__anon8
Cost	cnn/simd-functors.h	/^    Cost = NumTraits<Scalar>::AddCost * 2,$/;"	e	enum:Eigen::internal::functor_traits::__anon9
Cost	cnn/simd-functors.h	/^    Cost = NumTraits<Scalar>::AddCost + 2 * NumTraits<Scalar>::MulCost,$/;"	e	enum:Eigen::internal::functor_traits::__anon14
Cost	cnn/simd-functors.h	/^    Cost = NumTraits<Scalar>::AddCost + 6 * NumTraits<Scalar>::MulCost,$/;"	e	enum:Eigen::internal::functor_traits::__anon15
Cost	cnn/simd-functors.h	/^    Cost = NumTraits<Scalar>::AddCost + NumTraits<Scalar>::MulCost * 2,$/;"	e	enum:Eigen::internal::functor_traits::__anon12
Cost	cnn/simd-functors.h	/^    Cost = NumTraits<Scalar>::MulCost * 8,$/;"	e	enum:Eigen::internal::functor_traits::__anon11
CrossEntropyLoss	examples/textcat.cc	/^Expression CrossEntropyLoss(const Expression& y_pred, int y_true) {$/;"	f
Cube	cnn/nodes.h	/^  explicit Cube(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Cube
Cube	cnn/nodes.h	/^struct Cube : public Node {$/;"	s	namespace:cnn
CwiseMultiply	cnn/nodes.h	/^  explicit CwiseMultiply(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::CwiseMultiply
CwiseMultiply	cnn/nodes.h	/^struct CwiseMultiply : public Node {$/;"	s	namespace:cnn
CwiseQuotient	cnn/nodes.h	/^  explicit CwiseQuotient(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::CwiseQuotient
CwiseQuotient	cnn/nodes.h	/^struct CwiseQuotient : public Node {$/;"	s	namespace:cnn
CxtAttentionalModel	examples/cxtattentional.h	/^CxtAttentionalModel<Builder>::CxtAttentionalModel(cnn::Model& model,$/;"	f	class:cnn::CxtAttentionalModel
CxtAttentionalModel	examples/cxtattentional.h	/^struct CxtAttentionalModel{$/;"	s	namespace:cnn
CxtEncDecModel	ext/dialogue/cxtencdec.h	/^    CxtEncDecModel(cnn::Model& model, int vocab_size_src, int vocab_size_tgt, const vector<unsigned int>& layers, const vector<unsigned>& hidden_dims, int hidden_replicates, int decoder_use_additional_input = 0, int mem_slots = 0, cnn::real iscale = 1.0) :$/;"	f	class:cnn::CxtEncDecModel
CxtEncDecModel	ext/dialogue/cxtencdec.h	/^class CxtEncDecModel : public DialogueBuilder<Builder, Decoder>{$/;"	c	namespace:cnn
DATADIR	exp/encdec/encdec.bat	/^set DATADIR=c:\\data\\ptbdata$/;"	v
DATADIR	exp/lm/rnnlm2.bat	/^set DATADIR=c:\\data\\ptbdata$/;"	v
DATADIR	exp/lm/rnnlm2.dglstm.bat	/^set DATADIR=\\\\gcr\\scratch\\b99\\kaisheny\\data\\ptddata$/;"	v
DATADIR	exp/lm/rnnlm2_cls.bat	/^set DATADIR=c:\/data\/ptbdata$/;"	v
DATADIR	exp/lm/rnnlm2_cls_tst.bat	/^set DATADIR=c:\/data\/ptbdata$/;"	v
DBG_NEW_RNNEM	examples/attentional.h	25;"	d
DBG_NEW_RNNEM	examples/regattentional.h	25;"	d
DEC	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	325;"	d	file:
DEC	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	312;"	d	file:
DECODER_LAYER	cnn/macros.h	19;"	d
DECODER_LAYER	ext/encdec/encdec.h	26;"	d
DGLSTMBuilder	cnn/dglstm.cc	/^DGLSTMBuilder::DGLSTMBuilder(unsigned ilayers,$/;"	f	class:cnn::DGLSTMBuilder
DGLSTMBuilder	cnn/dglstm.h	/^  DGLSTMBuilder(const DGLSTMBuilder& ref) :$/;"	f	struct:cnn::DGLSTMBuilder
DGLSTMBuilder	cnn/dglstm.h	/^struct DGLSTMBuilder: public RNNBuilder {$/;"	s	namespace:cnn
DIALOGUE_	ext/dialogue/dialogue.h	2;"	d
DNNBuilder	cnn/dnn.cc	/^    DNNBuilder::DNNBuilder(unsigned ilayers,$/;"	f	class:cnn::DNNBuilder
DNNBuilder	cnn/dnn.h	/^        DNNBuilder() { dparallel = 1; }$/;"	f	class:cnn::DNNBuilder
DNNBuilder	cnn/dnn.h	/^        DNNBuilder(const DNNBuilder& ref)$/;"	f	class:cnn::DNNBuilder
DNNBuilder	cnn/dnn.h	/^    class DNNBuilder  {$/;"	c	namespace:cnn
DUMB_ADDITIVE	examples/embed-cl.cc	43;"	d	file:
DataReader	cnn/data-util.h	/^    DataReader(const string& train_filename)$/;"	f	class:DataReader
DataReader	cnn/data-util.h	/^class DataReader{$/;"	c
Datum	examples/mp.cc	/^typedef pair<cnn::real, cnn::real> Datum;$/;"	t	file:
DeepLSTMBuilder	cnn/deep-lstm.cc	/^DeepLSTMBuilder::DeepLSTMBuilder(unsigned layers,$/;"	f	class:cnn::DeepLSTMBuilder
DeepLSTMBuilder	cnn/deep-lstm.h	/^struct DeepLSTMBuilder : public RNNBuilder {$/;"	s	namespace:cnn
Dialogue	cnn/data-util.h	/^typedef vector<SentencePair> Dialogue;$/;"	t
DialogueBuilder	ext/dialogue/dialogue.h	/^    DialogueBuilder() {};$/;"	f	class:cnn::DialogueBuilder
DialogueBuilder	ext/dialogue/dialogue.h	/^    DialogueBuilder(cnn::Model& model, unsigned int vocab_size_src, unsigned int vocab_size_tgt, const vector<unsigned int>& layers, const vector<unsigned int>& hidden_dims, int hidden_replicates, int decoder_use_additional_input = 0, int mem_slots = 0, cnn::real iscale = 1.0) :$/;"	f	class:cnn::DialogueBuilder
DialogueBuilder	ext/dialogue/dialogue.h	/^class DialogueBuilder{$/;"	c	namespace:cnn
DialogueProcessInfo	ext/dialogue/dialogue_process.h	/^        DialogueProcessInfo(cnn::Model& model,$/;"	f	class:cnn::DialogueProcessInfo
DialogueProcessInfo	ext/dialogue/dialogue_process.h	/^    class DialogueProcessInfo{$/;"	c	namespace:cnn
DialogueSeq2SeqModel	ext/dialogue/dialogue_process.h	/^        DialogueSeq2SeqModel(cnn::Model& model,$/;"	f	class:cnn::DialogueSeq2SeqModel
DialogueSeq2SeqModel	ext/dialogue/dialogue_process.h	/^    class DialogueSeq2SeqModel : public DialogueProcessInfo<DBuilder> {$/;"	c	namespace:cnn
DialogueWithClassId	cnn/data-util.h	/^typedef vector<SentencePairAndClassId> DialogueWithClassId;$/;"	t
Dict	cnn/dict.h	/^typedef stDict<std::string> Dict;$/;"	t	namespace:cnn
Dim	cnn/dim.h	/^  Dim() : nd(), bd(1) {}$/;"	f	struct:cnn::Dim
Dim	cnn/dim.h	/^  Dim(const std::vector<unsigned int> & x) : nd(), bd(1) {$/;"	f	struct:cnn::Dim
Dim	cnn/dim.h	/^  Dim(const std::vector<unsigned int> & x, unsigned int b) : nd(), bd(b) {$/;"	f	struct:cnn::Dim
Dim	cnn/dim.h	/^  Dim(std::initializer_list<unsigned int> x) : nd(), bd(1) {$/;"	f	struct:cnn::Dim
Dim	cnn/dim.h	/^  Dim(std::initializer_list<unsigned int> x, unsigned int b) : nd(), bd(b) {$/;"	f	struct:cnn::Dim
Dim	cnn/dim.h	/^struct Dim {$/;"	s	namespace:cnn
Document	examples/skiprnnlm.cc	/^typedef vector<Sentence> Document;$/;"	t	file:
DotProduct	cnn/nodes.h	/^  explicit DotProduct(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::DotProduct
DotProduct	cnn/nodes.h	/^struct DotProduct : public Node {$/;"	s	namespace:cnn
Dropout	cnn/nodes.h	/^  explicit Dropout(const std::initializer_list<VariableIndex>& a, cnn::real p) : Node(a), p(p) {}$/;"	f	struct:cnn::Dropout
Dropout	cnn/nodes.h	/^struct Dropout : public Node {$/;"	s	namespace:cnn
DynamicMemoryNetDialogue	ext/dialogue/attention_with_intention.h	/^    DynamicMemoryNetDialogue(Model& model,$/;"	f	class:cnn::DynamicMemoryNetDialogue
DynamicMemoryNetDialogue	ext/dialogue/attention_with_intention.h	/^class DynamicMemoryNetDialogue {$/;"	c	namespace:cnn
EACHEPOCH	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set EACHEPOCH=1$/;"	v
EACHEPOCH	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set EACHEPOCH=1$/;"	v
EACHEPOCH	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set EACHEPOCH=1$/;"	v
EIGEN_BACKEND	cnn/tensor.h	26;"	d
EMBEDDING_LAYER	cnn/macros.h	21;"	d
EMatrix	cnn/tensor.h	/^    typedef Eigen::MatrixXd  EMatrix;$/;"	t	namespace:cnn
ENCODER_LAYER	cnn/macros.h	17;"	d
ENCODER_LAYER	ext/encdec/encdec.h	24;"	d
ENC_DEC_H_	ext/encdec/encdec.h	2;"	d
EQUALS	build/Makefile	/^EQUALS = =$/;"	m
EQUALS	build/cnn/Makefile	/^EQUALS = =$/;"	m
EQUALS	build/conversation/dev/src/Makefile	/^EQUALS = =$/;"	m
EQUALS	build/examples/Makefile	/^EQUALS = =$/;"	m
ETA	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set ETA=%1$/;"	v
ETA	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set ETA=%1$/;"	v
ETA	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set ETA=%1$/;"	v
EVector	cnn/tensor.h	/^    typedef Eigen::VectorXd EVector;$/;"	t	namespace:cnn
EXTMEM	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
Eigen	cnn/simd-functors.h	/^namespace Eigen { namespace internal {$/;"	n
EmbedSource	examples/embed-cl.cc	/^  Expression EmbedSource(const vector<int>& sent, ComputationGraph& cg) {$/;"	f	struct:Encoder
EmbedTarget	examples/embed-cl.cc	/^  Expression EmbedTarget(const vector<int>& sent, ComputationGraph& cg) {$/;"	f	struct:Encoder
EncModel	ext/encdec/encdec.h	/^    EncModel() {};$/;"	f	class:cnn::EncModel
EncModel	ext/encdec/encdec.h	/^    EncModel(cnn::Model& model, int layers, unsigned int vocab_size_src, const vector<unsigned>& hidden_dims, int hidden_replicates, int decoder_use_additional_input = 0, int mem_slots = 0, cnn::real iscale = 1.0) :$/;"	f	class:cnn::EncModel
EncModel	ext/encdec/encdec.h	/^class EncModel{$/;"	c	namespace:cnn
Encoder	examples/embed-cl.cc	/^  explicit Encoder(Model& model) {$/;"	f	struct:Encoder
Encoder	examples/embed-cl.cc	/^struct Encoder {$/;"	s	file:
EncoderDecoder	examples/encdec.cc	/^    explicit EncoderDecoder(Model& model) :$/;"	f	struct:EncoderDecoder
EncoderDecoder	examples/encdec.cc	/^struct EncoderDecoder {$/;"	s	file:
EncoderDecoder	examples/mem_seq2seq_encdec.cc	/^  explicit EncoderDecoder(Model& model,$/;"	f	struct:EncoderDecoder
EncoderDecoder	examples/mem_seq2seq_encdec.cc	/^struct EncoderDecoder {$/;"	s	file:
EncoderDecoder	examples/seq2seq_encdec.cc	/^  explicit EncoderDecoder(Model& model,$/;"	f	struct:EncoderDecoder
EncoderDecoder	examples/seq2seq_encdec.cc	/^struct EncoderDecoder {$/;"	s	file:
EvaluateProcess	ext/trainer/eval_proc.h	/^    EvaluateProcess()$/;"	f	class:EvaluateProcess
EvaluateProcess	ext/trainer/eval_proc.h	/^class EvaluateProcess{$/;"	c
ExecutionEngine	cnn/exec.h	/^  explicit ExecutionEngine(const ComputationGraph& cg) : cg(cg) {}$/;"	f	class:cnn::ExecutionEngine
ExecutionEngine	cnn/exec.h	/^class ExecutionEngine {$/;"	c	namespace:cnn
Exp	cnn/nodes.h	/^  explicit Exp(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Exp
Exp	cnn/nodes.h	/^struct Exp : public Node {$/;"	s	namespace:cnn
ExponentialLinearUnits	cnn/nodes.h	/^    explicit ExponentialLinearUnits(const std::initializer_list<VariableIndex>& a, cnn::real scale) : Node(a), scale(scale) {}$/;"	f	struct:cnn::ExponentialLinearUnits
ExponentialLinearUnits	cnn/nodes.h	/^struct ExponentialLinearUnits : public Node {$/;"	s	namespace:cnn
Expression	cnn/expr.h	/^  Expression() : pg(nullptr) { }$/;"	f	struct:cnn::expr::Expression
Expression	cnn/expr.h	/^  Expression(ComputationGraph *pg, VariableIndex i) : pg(pg), i(i) { }$/;"	f	struct:cnn::expr::Expression
Expression	cnn/expr.h	/^typedef struct Expression{$/;"	s	namespace:cnn::expr
FBCorpus	cnn/data-util.h	/^typedef vector<FBDialogue> FBCorpus;$/;"	t
FBDialogue	cnn/data-util.h	/^typedef vector<FBTurns> FBDialogue;$/;"	t
FBTurns	cnn/data-util.h	/^typedef pair<StatementsQuery, Sentence> FBTurns;$/;"	t
FBinaryLogLoss	cnn/functors.h	/^struct FBinaryLogLoss {$/;"	s	namespace:cnn
FBinaryLogLossBackward	cnn/functors.h	/^  explicit FBinaryLogLossBackward(cnn::real d) : d(d) {}$/;"	f	struct:cnn::FBinaryLogLossBackward
FBinaryLogLossBackward	cnn/functors.h	/^struct FBinaryLogLossBackward {$/;"	s	namespace:cnn
FConstantMinus	cnn/functors.h	/^  FConstantMinus(cnn::real c) : c(c) {}$/;"	f	struct:cnn::FConstantMinus
FConstantMinus	cnn/functors.h	/^struct FConstantMinus {$/;"	s	namespace:cnn
FConstantMultiply	cnn/functors.h	/^    FConstantMultiply(cnn::real c) : c(c) {}$/;"	f	struct:cnn::FConstantMultiply
FConstantMultiply	cnn/functors.h	/^struct FConstantMultiply{$/;"	s	namespace:cnn
FConstantPlus	cnn/functors.h	/^  FConstantPlus(cnn::real c) : c(c) {}$/;"	f	struct:cnn::FConstantPlus
FConstantPlus	cnn/functors.h	/^struct FConstantPlus {$/;"	s	namespace:cnn
FCopy	cnn/functors.h	/^struct FCopy {$/;"	s	namespace:cnn
FCorpus	cnn/data-util.h	/^typedef vector<FMatrix>   FCorpus;$/;"	t
FCorpusPointers	cnn/data-util.h	/^typedef vector<FCorpus*>  FCorpusPointers;$/;"	t
FErf	cnn/functors.h	/^struct FErf {$/;"	s	namespace:cnn
FErfBackward	cnn/functors.h	/^struct FErfBackward {$/;"	s	namespace:cnn
FEuclideanBackward	cnn/functors.h	/^  FEuclideanBackward(int i, const cnn::real* s) : i(i), scalar(s) {}$/;"	f	struct:cnn::FEuclideanBackward
FEuclideanBackward	cnn/functors.h	/^struct FEuclideanBackward {$/;"	s	namespace:cnn
FExp	cnn/functors.h	/^struct FExp {$/;"	s	namespace:cnn
FExponentialLinearUnits	cnn/functors.h	/^    explicit FExponentialLinearUnits(cnn::real scale) : a(scale) {}$/;"	f	struct:cnn::FExponentialLinearUnits
FExponentialLinearUnits	cnn/functors.h	/^struct FExponentialLinearUnits {$/;"	s	namespace:cnn
FExponentialLinearUnitsBackward	cnn/functors.h	/^    FExponentialLinearUnitsBackward(cnn::real m) : a(m) {}$/;"	f	struct:cnn::FExponentialLinearUnitsBackward
FExponentialLinearUnitsBackward	cnn/functors.h	/^struct FExponentialLinearUnitsBackward {$/;"	s	namespace:cnn
FHuberBackward	cnn/functors.h	/^  FHuberBackward(cnn::real c, cnn::real dEdf) : c(c), d(dEdf) {}$/;"	f	struct:cnn::FHuberBackward
FHuberBackward	cnn/functors.h	/^struct FHuberBackward {$/;"	s	namespace:cnn
FHuberForward	cnn/functors.h	/^FHuberForward(cnn::real c) : c(c) {}$/;"	f	struct:cnn::FHuberForward
FHuberForward	cnn/functors.h	/^struct FHuberForward {$/;"	s	namespace:cnn
FL1Backward	cnn/functors.h	/^  FL1Backward(cnn::real d) : d(d) {}$/;"	f	struct:cnn::FL1Backward
FL1Backward	cnn/functors.h	/^struct FL1Backward {$/;"	s	namespace:cnn
FL2SGDMomentumUpdate	cnn/functors.h	/^    FL2SGDMomentumUpdate(cnn::real l, cnn::real s, cnn::real m) : lambda(l), scale(-s), momentum(m) {}$/;"	f	struct:cnn::FL2SGDMomentumUpdate
FL2SGDMomentumUpdate	cnn/functors.h	/^struct FL2SGDMomentumUpdate {$/;"	s	namespace:cnn
FL2SGDMomentumWithDenUpdate	cnn/functors.h	/^    FL2SGDMomentumWithDenUpdate(cnn::real *gs, cnn::real l, cnn::real s, cnn::real m, cnn::real eps) : lambda(l), scale(-s), momentum(m), epsilon(eps), gscale(gs) {}$/;"	f	struct:cnn::FL2SGDMomentumWithDenUpdate
FL2SGDMomentumWithDenUpdate	cnn/functors.h	/^struct FL2SGDMomentumWithDenUpdate {$/;"	s	namespace:cnn
FL2SGDUpdate	cnn/functors.h	/^    FL2SGDUpdate(cnn::real l, cnn::real s) : lambda(l), scale(-s) {}$/;"	f	struct:cnn::FL2SGDUpdate
FL2SGDUpdate	cnn/functors.h	/^struct FL2SGDUpdate {$/;"	s	namespace:cnn
FL2SGDUpdatePtrArguments	cnn/functors.h	/^    FL2SGDUpdatePtrArguments(cnn::real *l, cnn::real *s) : lambda(l), scale(s) {}$/;"	f	struct:cnn::FL2SGDUpdatePtrArguments
FL2SGDUpdatePtrArguments	cnn/functors.h	/^struct FL2SGDUpdatePtrArguments {$/;"	s	namespace:cnn
FLog	cnn/functors.h	/^struct FLog {$/;"	s	namespace:cnn
FLogBackward	cnn/functors.h	/^struct FLogBackward {$/;"	s	namespace:cnn
FLogGammaBackward	cnn/functors.h	/^struct FLogGammaBackward {$/;"	s	namespace:cnn
FLogSoftmaxBackward	cnn/functors.h	/^  explicit FLogSoftmaxBackward(cnn::real off_diag_sum) : off_diag_sum(off_diag_sum) {}$/;"	f	struct:cnn::FLogSoftmaxBackward
FLogSoftmaxBackward	cnn/functors.h	/^struct FLogSoftmaxBackward {$/;"	s	namespace:cnn
FLogSoftmaxNormalize	cnn/functors.h	/^  explicit FLogSoftmaxNormalize(cnn::real logz) : logz(logz) {}$/;"	f	struct:cnn::FLogSoftmaxNormalize
FLogSoftmaxNormalize	cnn/functors.h	/^struct FLogSoftmaxNormalize {$/;"	s	namespace:cnn
FLogisticSigmoid	cnn/functors.h	/^struct FLogisticSigmoid {$/;"	s	namespace:cnn
FLogisticSigmoidBackward	cnn/functors.h	/^struct FLogisticSigmoidBackward {$/;"	s	namespace:cnn
FMatrix	cnn/data-util.h	/^typedef vector<FVector>   FMatrix;$/;"	t
FMaxBackwardInv	cnn/functors.h	/^struct FMaxBackwardInv {$/;"	s	namespace:cnn
FNegLogSoftmaxBackward	cnn/functors.h	/^  FNegLogSoftmaxBackward(cnn::real lz, cnn::real err) : logz(lz), d(err) {}$/;"	f	struct:cnn::FNegLogSoftmaxBackward
FNegLogSoftmaxBackward	cnn/functors.h	/^struct FNegLogSoftmaxBackward {$/;"	s	namespace:cnn
FNegate	cnn/functors.h	/^struct FNegate {$/;"	s	namespace:cnn
FPairwiseRankLoss	cnn/functors.h	/^  FPairwiseRankLoss(cnn::real m) : margin(m) {}$/;"	f	struct:cnn::FPairwiseRankLoss
FPairwiseRankLoss	cnn/functors.h	/^struct FPairwiseRankLoss {$/;"	s	namespace:cnn
FProduct	cnn/functors.h	/^struct FProduct {$/;"	s	namespace:cnn
FPtrNegLogSoftmaxBackward	cnn/functors.h	/^  FPtrNegLogSoftmaxBackward(const cnn::real* lz, const cnn::real* err) : logz(lz), d(err) {}$/;"	f	struct:cnn::FPtrNegLogSoftmaxBackward
FPtrNegLogSoftmaxBackward	cnn/functors.h	/^struct FPtrNegLogSoftmaxBackward {$/;"	s	namespace:cnn
FQuotient	cnn/functors.h	/^struct FQuotient {$/;"	s	namespace:cnn
FRectify	cnn/functors.h	/^struct FRectify {$/;"	s	namespace:cnn
FRectifyBackward	cnn/functors.h	/^struct FRectifyBackward {$/;"	s	namespace:cnn
FRectifyNegateBackward	cnn/functors.h	/^struct FRectifyNegateBackward {$/;"	s	namespace:cnn
FSoftSign	cnn/functors.h	/^struct FSoftSign {$/;"	s	namespace:cnn
FSoftSignBackward	cnn/functors.h	/^struct FSoftSignBackward {$/;"	s	namespace:cnn
FSoftmaxBackward	cnn/functors.h	/^  explicit FSoftmaxBackward(cnn::real off_diag_sum) : off_diag_sum(off_diag_sum) {}$/;"	f	struct:cnn::FSoftmaxBackward
FSoftmaxBackward	cnn/functors.h	/^struct FSoftmaxBackward {$/;"	s	namespace:cnn
FSoftmaxNormalize	cnn/functors.h	/^  explicit FSoftmaxNormalize(cnn::real logz) : logz(logz) {}$/;"	f	struct:cnn::FSoftmaxNormalize
FSoftmaxNormalize	cnn/functors.h	/^struct FSoftmaxNormalize {$/;"	s	namespace:cnn
FSqDist	cnn/functors.h	/^struct FSqDist {$/;"	s	namespace:cnn
FSqrtBackward	cnn/functors.h	/^struct FSqrtBackward {$/;"	s	namespace:cnn
FSquare	cnn/functors.h	/^struct FSquare {$/;"	s	namespace:cnn
FSubtract	cnn/functors.h	/^struct FSubtract {$/;"	s	namespace:cnn
FTanh	cnn/functors.h	/^struct FTanh {$/;"	s	namespace:cnn
FTanhBackward	cnn/functors.h	/^struct FTanhBackward {$/;"	s	namespace:cnn
FVector	cnn/data-util.h	/^typedef vector<cnn::real> FVector;$/;"	t
FWeightedError	cnn/functors.h	/^struct FWeightedError {$/;"	s	namespace:cnn
FoldRows	cnn/conv.h	/^  explicit FoldRows(const std::initializer_list<VariableIndex>& a, unsigned nrows) : Node(a), nrows(nrows) {}$/;"	f	struct:cnn::FoldRows
FoldRows	cnn/conv.h	/^struct FoldRows : public Node {$/;"	s	namespace:cnn
Free	cnn/init.cc	/^  void Free() $/;"	f	namespace:cnn
Free_GPU	cnn/cuda.cc	/^void Free_GPU()$/;"	f	namespace:cnn
Freeze	cnn/dict.h	/^    void Freeze() { frozen = true; }$/;"	f	class:cnn::stId2String
Freeze	cnn/dict.h	/^  void Freeze() { frozen = true; }$/;"	f	class:cnn::stDict
GRADIENT_CHECK_DIGIT_SIGNIFICANT_LEVEL	cnn/macros.h	40;"	d
GRADIENT_CHECK_PARAM_DELTA	cnn/macros.h	41;"	d
GRAPH_READY	cnn/rnn-state-machine.h	/^enum RNNState {CREATED, GRAPH_READY, READING_INPUT};$/;"	e	enum:cnn::RNNState
GRUBuilder	cnn/gru.cc	/^GRUBuilder::GRUBuilder(unsigned ilayers,$/;"	f	class:cnn::GRUBuilder
GRUBuilder	cnn/gru.h	/^  GRUBuilder(const GRUBuilder& ref):$/;"	f	struct:cnn::GRUBuilder
GRUBuilder	cnn/gru.h	/^struct GRUBuilder : public RNNBuilder {$/;"	s	namespace:cnn
GatedAttention	ext/dialogue/attention_with_intention.h	/^    GatedAttention(Model& model,$/;"	f	class:cnn::GatedAttention
GatedAttention	ext/dialogue/attention_with_intention.h	/^class GatedAttention : public AttentionWithIntention<Builder, Decoder>{$/;"	c	namespace:cnn
GaussianNoise	cnn/nodes.h	/^  explicit GaussianNoise(const std::initializer_list<VariableIndex>& a, cnn::real stddev) : Node(a), stddev(stddev) {}$/;"	f	struct:cnn::GaussianNoise
GaussianNoise	cnn/nodes.h	/^struct GaussianNoise : public Node {$/;"	s	namespace:cnn
GetNgramCounts	cnn/metric-util.h	/^    std::map<string, int> GetNgramCounts(const vector<string> & tokens, int order)$/;"	f	class:BleuMetric
GetScore	cnn/metric-util.h	/^    string GetScore()$/;"	f	class:BleuMetric
GetSentenceLL	ext/ngram/ngram.h	/^    cnn::real GetSentenceLL(const Sentence & refTokens, cnn::real interpolation_wgt)$/;"	f	class:nGram
GetSentenceLL	ext/ngram/ngram.h	/^    cnn::real GetSentenceLL(const vector<string> & refTokens, Dict& sd)$/;"	f	class:nGram
GetSentenceScore	cnn/metric-util.h	/^    cnn::real GetSentenceScore(const vector<string> & refTokens, const vector<string> & hypTokens)$/;"	f	class:BleuMetric
GetStats	cnn/metric-util.h	/^    LossStats GetStats(const vector<string> & refTokens, const vector<string> & hypTokens)$/;"	f	class:BleuMetric
GetWordList	cnn/dict.h	/^  std::vector<T> GetWordList() { return words_; };$/;"	f	class:cnn::stDict
GraphOptimize	cnn/graph.cc	/^void GraphOptimize(ComputationGraph* cg) {$/;"	f	namespace:cnn
H2C	cnn/deep-lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon2	file:
H2C	cnn/dglstm.cc	/^        X2O, H2O, C2O, BO, X2C, H2C, BC, X2K, C2K, Q2K, BK, STAB, X2K0 };$/;"	e	enum:cnn::__anon3	file:
H2C	cnn/lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon6	file:
H2C	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
H2C	cnn/treelstm.cc	/^enum { H2I, H2F, H2O, H2C };$/;"	e	enum:cnn::__anon17	file:
H2E	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
H2F	cnn/dglstm.cc	/^        X2F, H2F, C2F, BF, $/;"	e	enum:cnn::__anon3	file:
H2F	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
H2F	cnn/treelstm.cc	/^enum { H2I, H2F, H2O, H2C };$/;"	e	enum:cnn::__anon17	file:
H2H	cnn/gru.cc	/^enum { X2Z, H2Z, BZ, X2R, H2R, BR, X2H, H2H, BH };$/;"	e	enum:cnn::__anon5	file:
H2H	cnn/rnn.cc	/^enum { X2H=0, H2H, HB, L2H };$/;"	e	enum:cnn::__anon19	file:
H2I	cnn/deep-lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon2	file:
H2I	cnn/dglstm.cc	/^    enum { X2I, H2I, C2I, BI, $/;"	e	enum:cnn::__anon3	file:
H2I	cnn/lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon6	file:
H2I	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
H2I	cnn/treelstm.cc	/^enum { H2I, H2F, H2O, H2C };$/;"	e	enum:cnn::__anon17	file:
H2O	cnn/deep-lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon2	file:
H2O	cnn/dglstm.cc	/^        X2O, H2O, C2O, BO, X2C, H2C, BC, X2K, C2K, Q2K, BK, STAB, X2K0 };$/;"	e	enum:cnn::__anon3	file:
H2O	cnn/lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon6	file:
H2O	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
H2O	cnn/treelstm.cc	/^enum { H2I, H2F, H2O, H2C };$/;"	e	enum:cnn::__anon17	file:
H2R	cnn/gru.cc	/^enum { X2Z, H2Z, BZ, X2R, H2R, BR, X2H, H2H, BH };$/;"	e	enum:cnn::__anon5	file:
H2Z	cnn/gru.cc	/^enum { X2Z, H2Z, BZ, X2R, H2R, BR, X2H, H2H, BH };$/;"	e	enum:cnn::__anon5	file:
HASHING_LAYER	cnn/macros.h	22;"	d
HB	cnn/rnn.cc	/^enum { X2H=0, H2H, HB, L2H };$/;"	e	enum:cnn::__anon19	file:
HDIM	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set HDIM=%3$/;"	v
HDIM	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set HDIM=%3$/;"	v
HDIM	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set HDIM=%3$/;"	v
HEX	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	336;"	d	file:
HEX	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	323;"	d	file:
HIDDEN_DIM	examples/attentional.cc	/^unsigned HIDDEN_DIM = 64;  \/\/ 1024$/;"	v
HIDDEN_DIM	examples/encdec.cc	/^unsigned HIDDEN_DIM = 150;$/;"	v
HIDDEN_DIM	examples/mem_seq2seq_encdec.cc	/^unsigned HIDDEN_DIM = 500;$/;"	v
HIDDEN_DIM	examples/poisson-regression.cc	/^long HIDDEN_DIM = 32;  \/\/ 1024$/;"	v
HIDDEN_DIM	examples/rnnlm-aevb.cc	/^unsigned HIDDEN_DIM = 128;  \/\/ 1024$/;"	v
HIDDEN_DIM	examples/rnnlm.cc	/^long HIDDEN_DIM = 24;  \/\/ 1024$/;"	v
HIDDEN_DIM	examples/rnnlm2.cc	/^unsigned int HIDDEN_DIM = 24;  \/\/ 1024$/;"	v
HIDDEN_DIM	examples/rnnlm2_cls_based.cc	/^unsigned int HIDDEN_DIM = 24;  \/\/ 1024$/;"	v
HIDDEN_DIM	examples/seq2seq_encdec.cc	/^long HIDDEN_DIM = 500;$/;"	v
HIDDEN_DIM	examples/skiprnnlm.cc	/^unsigned HIDDEN_DIM = 24;  \/\/ 1024$/;"	v
HIDDEN_DIM	examples/tag-bilstm.cc	/^long HIDDEN_DIM = 128;$/;"	v
HIDDEN_DIM	ext/trainer/train_proc.h	/^unsigned HIDDEN_DIM = 50;  \/\/ 1024$/;"	v
HIDDEN_DIM2	examples/rnnlm-aevb.cc	/^unsigned HIDDEN_DIM2 = 32;$/;"	v
HIDDEN_LAYER	cnn/macros.h	26;"	d
HREDModel	ext/dialogue/dialogue_process.h	/^        HREDModel(cnn::Model& model,$/;"	f	class:cnn::HREDModel
HREDModel	ext/dialogue/dialogue_process.h	/^    class HREDModel : public DialogueProcessInfo<DBuilder>{$/;"	c	namespace:cnn
Hinge	cnn/nodes.h	/^  explicit Hinge(const std::initializer_list<VariableIndex>& a, const unsigned* pe, cnn::real m = 1.0) : Node(a), element(), pelement(pe), margin(m) {}$/;"	f	struct:cnn::Hinge
Hinge	cnn/nodes.h	/^  explicit Hinge(const std::initializer_list<VariableIndex>& a, unsigned e, cnn::real m = 1.0) : Node(a), element(e), pelement(&element), margin(m) {}$/;"	f	struct:cnn::Hinge
Hinge	cnn/nodes.h	/^struct Hinge : public Node {$/;"	s	namespace:cnn
HingeLoss	examples/textcat.cc	/^Expression HingeLoss(const Expression& y_pred, int y_true) {$/;"	f
HirearchicalEncDec	ext/dialogue/attention_with_intention.h	/^    HirearchicalEncDec(Model& model,$/;"	f	class:cnn::HirearchicalEncDec
HirearchicalEncDec	ext/dialogue/attention_with_intention.h	/^class HirearchicalEncDec : public AWI_Bilinear_Simpler< Builder, Decoder > {$/;"	c	namespace:cnn
HuberDistance	cnn/nodes.h	/^  explicit HuberDistance(const std::initializer_list<VariableIndex>& a, cnn::real d = 1.345f) : Node(a), d(d) {}$/;"	f	struct:cnn::HuberDistance
HuberDistance	cnn/nodes.h	/^struct HuberDistance : public Node {$/;"	s	namespace:cnn
Hypothesis	cnn/decode.h	/^    Hypothesis(RNNPointer state, int tgt, cnn::real cst, Hypothesis &last)$/;"	f	struct:cnn::Hypothesis
Hypothesis	cnn/decode.h	/^    Hypothesis(RNNPointer state, int tgt, cnn::real cst, int _t)$/;"	f	struct:cnn::Hypothesis
Hypothesis	cnn/decode.h	/^struct Hypothesis {$/;"	s	namespace:cnn
Hypothesis	examples/attentional.h	/^    Hypothesis(RNNPointer state, int tgt, cnn::real cst, Hypothesis &last)$/;"	f	struct:cnn::Hypothesis
Hypothesis	examples/attentional.h	/^    Hypothesis(RNNPointer state, int tgt, cnn::real cst, int _t)$/;"	f	struct:cnn::Hypothesis
Hypothesis	examples/attentional.h	/^struct Hypothesis {$/;"	s	namespace:cnn
Hypothesis	examples/cxtattentional.h	/^    Hypothesis(RNNPointer state, int tgt, cnn::real cst, Hypothesis &last)$/;"	f	struct:cnn::Hypothesis
Hypothesis	examples/cxtattentional.h	/^    Hypothesis(RNNPointer state, int tgt, cnn::real cst, int _t)$/;"	f	struct:cnn::Hypothesis
Hypothesis	examples/cxtattentional.h	/^struct Hypothesis {$/;"	s	namespace:cnn
I2TMap	cnn/dict.h	/^    typedef std::unordered_map<int, T> I2TMap;$/;"	t	class:cnn::stId2String
IDIM	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^REM set IDIM=50$/;"	v
IDIM	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set IDIM=%2$/;"	v
IDIM	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^REM set IDIM=50$/;"	v
IDIM	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set IDIM=%2$/;"	v
IDIM	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^REM set IDIM=50$/;"	v
IDIM	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set IDIM=%2$/;"	v
IDX2C	cnn/macros.h	34;"	d
ID_VOID_MAIN	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	9;"	d	file:
IMPORTB	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
INPUT_DIM	examples/encdec.cc	/^unsigned INPUT_DIM = 150;$/;"	v
INPUT_DIM	examples/mem_seq2seq_encdec.cc	/^unsigned INPUT_DIM = 500;$/;"	v
INPUT_DIM	examples/poisson-regression.cc	/^long INPUT_DIM = 16;  \/\/256$/;"	v
INPUT_DIM	examples/rnnlm-aevb.cc	/^unsigned INPUT_DIM = 32;  \/\/256$/;"	v
INPUT_DIM	examples/rnnlm.cc	/^long INPUT_DIM = 8;  \/\/256$/;"	v
INPUT_DIM	examples/rnnlm2.cc	/^unsigned int INPUT_DIM = 8;  \/\/256$/;"	v
INPUT_DIM	examples/rnnlm2_cls_based.cc	/^unsigned int INPUT_DIM = 8;  \/\/256$/;"	v
INPUT_DIM	examples/seq2seq_encdec.cc	/^long INPUT_DIM = 500;$/;"	v
INPUT_DIM	examples/skiprnnlm.cc	/^unsigned INPUT_DIM = 8;  \/\/256$/;"	v
INPUT_DIM	examples/tag-bilstm.cc	/^long INPUT_DIM = 128;$/;"	v
INPUT_DIM	examples/textcat.cc	/^long INPUT_DIM = 36;$/;"	v
INPUT_LAYER	cnn/macros.h	25;"	d
INPUT_VOCAB_SIZE	examples/embed-cl.cc	/^long  INPUT_VOCAB_SIZE = 0;$/;"	v
INPUT_VOCAB_SIZE	examples/encdec.cc	/^unsigned INPUT_VOCAB_SIZE = 0;$/;"	v
INTENTION_LAYER	cnn/macros.h	18;"	d
INTENTION_LAYER	ext/encdec/encdec.h	25;"	d
INVALID	ext/lda/lda.h	/^		INVALID,					\/\/ ldaModel not initialised$/;"	e	enum:ldaModel::__anon22
Identity	cnn/nodes.h	/^  explicit Identity(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Identity
Identity	cnn/nodes.h	/^struct Identity : public Node {$/;"	s	namespace:cnn
Initialize	cnn/init.cc	/^    void Initialize(int& argc, char**& argv, unsigned random_seed, bool demo) {$/;"	f	namespace:cnn
Initialize	cnn/metric-util.h	/^    void Initialize(const variables_map & vm)$/;"	f	class:BleuMetric
Initialize	cnn/metric-util.h	/^    void Initialize(int ngramorder = 4)$/;"	f	class:BleuMetric
Initialize	cnn/model.cc	/^void LookupParameters::Initialize(unsigned index, const vector<cnn::real>& val) {$/;"	f	class:cnn::LookupParameters
Initialize	ext/ngram/ngram.h	/^    void Initialize(const variables_map & vm)$/;"	f	class:nGram
Initialize_CUDNN	cnn/cuda.cc	/^void Initialize_CUDNN()$/;"	f	namespace:cnn
Initialize_Consts_And_Store_In_GPU	cnn/cuda.cc	/^void Initialize_Consts_And_Store_In_GPU()$/;"	f	namespace:cnn
Initialize_GPU	cnn/cuda.cc	/^void Initialize_GPU(int& argc, char**& argv) {$/;"	f	namespace:cnn
InnerProduct3D_1D	cnn/nodes.h	/^  InnerProduct3D_1D(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::InnerProduct3D_1D
InnerProduct3D_1D	cnn/nodes.h	/^struct InnerProduct3D_1D : public Node {$/;"	s	namespace:cnn
InputNode	cnn/param-nodes.h	/^  explicit InputNode(const Dim& d, const std::vector<cnn::real>& dat) : dim(d), data(dat), pdata(&data) {}$/;"	f	struct:cnn::InputNode
InputNode	cnn/param-nodes.h	/^  explicit InputNode(const Dim& d, const std::vector<cnn::real>* pdat) : dim(d), data(), pdata(pdat) {}$/;"	f	struct:cnn::InputNode
InputNode	cnn/param-nodes.h	/^struct InputNode : public Node {$/;"	s	namespace:cnn
IsCurrentPredictionCorrection	examples/textcat.cc	/^bool IsCurrentPredictionCorrection(ComputationGraph& cg, int y_true) {$/;"	f
K	ext/lda/lda.h	/^	int K; 							\/\/ Number of topics$/;"	m	class:ldaModel
KMHNGram	cnn/nodes.h	/^  explicit KMHNGram(const std::initializer_list<VariableIndex>& a, unsigned n) : Node(a), n(n) {}$/;"	f	struct:cnn::KMHNGram
KMHNGram	cnn/nodes.h	/^struct KMHNGram : public Node {$/;"	s	namespace:cnn
KMaxPooling	cnn/conv.h	/^  explicit KMaxPooling(const std::initializer_list<VariableIndex>& a, unsigned k = 1) : Node(a), k(k) {}$/;"	f	struct:cnn::KMaxPooling
KMaxPooling	cnn/conv.h	/^struct KMaxPooling : public Node {$/;"	s	namespace:cnn
L	examples/rnnlm-aevb.cc	/^unsigned L = 10;$/;"	v
L1Distance	cnn/nodes.h	/^  explicit L1Distance(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::L1Distance
L1Distance	cnn/nodes.h	/^struct L1Distance : public Node {$/;"	s	namespace:cnn
L2H	cnn/rnn.cc	/^enum { X2H=0, H2H, HB, L2H };$/;"	e	enum:cnn::__anon19	file:
LABEL_SIZE	examples/textcat.cc	/^long LABEL_SIZE = 0;$/;"	v
LATENT_DIM	examples/rnnlm-aevb.cc	/^unsigned LATENT_DIM = 2;$/;"	v
LAYERS	examples/attentional.cc	/^unsigned LAYERS = 1; \/\/ 2$/;"	v
LAYERS	examples/encdec.cc	/^unsigned LAYERS = 3;$/;"	v
LAYERS	examples/mem_seq2seq_encdec.cc	/^unsigned LAYERS = 3;$/;"	v
LAYERS	examples/poisson-regression.cc	/^long LAYERS = 2;$/;"	v
LAYERS	examples/rnnlm-aevb.cc	/^unsigned LAYERS = 2;$/;"	v
LAYERS	examples/rnnlm.cc	/^long LAYERS = 2;$/;"	v
LAYERS	examples/rnnlm2.cc	/^unsigned int LAYERS = 2;$/;"	v
LAYERS	examples/rnnlm2_cls_based.cc	/^unsigned int LAYERS = 2;$/;"	v
LAYERS	examples/seq2seq_encdec.cc	/^long LAYERS = 3;$/;"	v
LAYERS	examples/skiprnnlm.cc	/^unsigned LAYERS = 2;$/;"	v
LAYERS	examples/tag-bilstm.cc	/^long LAYERS = 1;$/;"	v
LAYERS	ext/trainer/train_proc.h	/^unsigned LAYERS = 2;$/;"	v
LEVENSHTEIN_THRESHOLD	ext/trainer/train_proc.h	58;"	d
LOLCAT	examples/attentional.cc	39;"	d	file:
LSTMBuilder	cnn/lstm.cc	/^LSTMBuilder::LSTMBuilder(unsigned ilayers,$/;"	f	class:cnn::LSTMBuilder
LSTMBuilder	cnn/lstm.h	/^  LSTMBuilder(const LSTMBuilder& ref)$/;"	f	struct:cnn::LSTMBuilder
LSTMBuilder	cnn/lstm.h	/^struct LSTMBuilder : public RNNBuilder {$/;"	s	namespace:cnn
LZERO	cnn/macros.h	44;"	d
LoadModel	ext/ngram/ngram.h	/^    void LoadModel()$/;"	f	class:nGram
LoadModel	ext/ngram/ngram.h	/^    void LoadModel(const string& ext)$/;"	f	class:nGram
Log	cnn/nodes.h	/^  explicit Log(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Log
Log	cnn/nodes.h	/^struct Log : public Node {$/;"	s	namespace:cnn
LogSoftmax	cnn/nodes.h	/^  explicit LogSoftmax(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::LogSoftmax
LogSoftmax	cnn/nodes.h	/^struct LogSoftmax : public Node {$/;"	s	namespace:cnn
LogSumExp	cnn/nodes.h	/^  template <typename T> explicit LogSumExp(const T& a) : Node(a) {}$/;"	f	struct:cnn::LogSumExp
LogSumExp	cnn/nodes.h	/^struct LogSumExp : public Node {$/;"	s	namespace:cnn
LogisticSigmoid	cnn/nodes.h	/^  explicit LogisticSigmoid(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::LogisticSigmoid
LogisticSigmoid	cnn/nodes.h	/^struct LogisticSigmoid : public Node {$/;"	s	namespace:cnn
LooksLikeMatrix	cnn/nodes-common.cc	/^    inline bool LooksLikeMatrix(const Dim& d) {$/;"	f	namespace:cnn
LooksLikeVector	cnn/nodes-common.cc	/^    inline bool LooksLikeVector(const Dim& d) {$/;"	f	namespace:cnn
LookupNode	cnn/param-nodes.h	/^  LookupNode(LookupParameters* p, const std::vector<unsigned>& indices) : dim(p->dim), index(), pindex(), indices(indices), pindices(&this->indices), params(p) {$/;"	f	struct:cnn::LookupNode
LookupNode	cnn/param-nodes.h	/^  LookupNode(LookupParameters* p, const std::vector<unsigned>* pindices) : dim(p->dim), index(), pindex(), indices(), pindices(pindices), params(p) {$/;"	f	struct:cnn::LookupNode
LookupNode	cnn/param-nodes.h	/^  LookupNode(LookupParameters* p, const unsigned* pind) : dim(p->dim), index(), pindex(pind), indices(), pindices(), params(p) {}$/;"	f	struct:cnn::LookupNode
LookupNode	cnn/param-nodes.h	/^  LookupNode(LookupParameters* p, unsigned ind) : dim(p->dim), index(ind), pindex(&index), indices(), pindices(), params(p) {}$/;"	f	struct:cnn::LookupNode
LookupNode	cnn/param-nodes.h	/^struct LookupNode : public ParameterNodeBase {$/;"	s	namespace:cnn
LookupParameters	cnn/model.cc	/^LookupParameters::LookupParameters(unsigned n, const Dim& d, cnn::real scale, std::string nodename) : dim(d), values(n), grads(n), name(nodename) {$/;"	f	class:cnn::LookupParameters
LookupParameters	cnn/model.h	/^  LookupParameters() { }$/;"	f	struct:cnn::LookupParameters
LookupParameters	cnn/model.h	/^struct LookupParameters : public ParametersBase {$/;"	s	namespace:cnn
LossStats	cnn/metric-util.h	/^typedef vector<cnn::real> LossStats;$/;"	t
LossStats	ext/ngram/ngram.h	/^typedef vector<cnn::real> LossStats;$/;"	t
M	cnn/rnnem.h	/^  std::vector<std::vector<Expression>> M;$/;"	m	struct:cnn::NMNBuilder
M	ext/lda/lda.h	/^	int M;							\/\/ Number of documents$/;"	m	class:ldaModel
M0	cnn/rnnem.h	/^  std::vector<Expression> w0, h0, c0, M0;$/;"	m	struct:cnn::NMNBuilder
MAXEPOCH	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set MAXEPOCH=40$/;"	v
MAXEPOCH	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set MAXEPOCH=40$/;"	v
MAXEPOCH	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set MAXEPOCH=40$/;"	v
MAXTURNS	ext/trainer/train_proc.h	2126;"	d
MAX_LOG_SUM_EXP	cnn/nodes.cc	533;"	d	file:
MAX_NBR_TRUNS	ext/trainer/train_proc.h	88;"	d
MAX_THREADS_PER_BLOCK	cnn/macros.h	37;"	d
MEM_INIT	cnn/rnnem.cc	/^        MEM_INIT$/;"	e	enum:cnn::__anon7	file:
MEM_PRE_ALLOCATED_CONSTS_NUMBERS	cnn/macros.h	48;"	d
MEM_SIZE	ext/dialogue/attention_with_intention.h	36;"	d
MEORDER_LAYER	cnn/macros.h	23;"	d
MIN_OCC_COUNT	cnn/macros.h	31;"	d
Map	cnn/dict.h	/^ typedef std::unordered_map<T, int> Map;$/;"	t	class:cnn::stDict
MatrixMultiply	cnn/nodes.h	/^  explicit MatrixMultiply(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::MatrixMultiply
MatrixMultiply	cnn/nodes.h	/^struct MatrixMultiply : public Node {$/;"	s	namespace:cnn
Max	cnn/nodes.h	/^  template <typename T> explicit Max(const T& a) : Node(a) {}$/;"	f	struct:cnn::Max
Max	cnn/nodes.h	/^struct Max : public Node {$/;"	s	namespace:cnn
MaxPooling1D	cnn/nodes.h	/^  MaxPooling1D(const std::initializer_list<VariableIndex>& a, unsigned w) : Node(a), width(w) {}$/;"	f	struct:cnn::MaxPooling1D
MaxPooling1D	cnn/nodes.h	/^struct MaxPooling1D : public Node {$/;"	s	namespace:cnn
Mean	examples/mp.cc	/^cnn::real Mean(const vector<cnn::real>& values) {$/;"	f
Min	cnn/nodes.h	/^  explicit Min(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Min
Min	cnn/nodes.h	/^struct Min : public Node {$/;"	s	namespace:cnn
Model	cnn/model.h	/^    Model() : gradient_norm_scratch() { $/;"	f	class:cnn::Model
Model	cnn/model.h	/^class Model {$/;"	c	namespace:cnn
ModelParameters	examples/mp.cc	/^struct ModelParameters {$/;"	s	file:
MomentumSGDTrainer	cnn/training.h	/^  explicit MomentumSGDTrainer(Model* m, cnn::real lam = 1e-6, cnn::real e0 = 0.01, cnn::real mom = 0.9) :$/;"	f	struct:cnn::MomentumSGDTrainer
MomentumSGDTrainer	cnn/training.h	/^struct MomentumSGDTrainer : public Trainer {$/;"	s	namespace:cnn
MultiSourceDialogue	ext/dialogue/dialogue_process.h	/^        explicit MultiSourceDialogue(cnn::Model& model,$/;"	f	class:cnn::MultiSourceDialogue
MultiSourceDialogue	ext/dialogue/dialogue_process.h	/^    class MultiSourceDialogue: public DialogueProcessInfo<DBuilder>{$/;"	c	namespace:cnn
MultiSource_LinearEncoder	ext/dialogue/attention_with_intention.h	/^    MultiSource_LinearEncoder(Model& model,$/;"	f	class:cnn::MultiSource_LinearEncoder
MultiSource_LinearEncoder	ext/dialogue/attention_with_intention.h	/^class MultiSource_LinearEncoder : public DialogueBuilder<Builder, Decoder>{$/;"	c	namespace:cnn
MultiTurnsReadSentence	cnn/data-util.cc	/^int MultiTurnsReadSentence(const std::string& line,$/;"	f
MultiTurnsReadSentencePair	cnn/data-util.cc	/^int MultiTurnsReadSentencePair(const std::wstring& line, std::vector<int>* s, WDict* sd, std::vector<int>* t, WDict* td, bool appendSBandSE, int kSRC_SOS, int kSRC_EOS)$/;"	f
MultiTurnsReadSentencePair	cnn/data-util.cc	/^string MultiTurnsReadSentencePair(const std::string& line, std::vector<int>* s, Dict* sd, std::vector<int>* t, Dict* td, bool backofftounk, int kSRC_SOS, int kSRC_EOS, bool bcharacter)$/;"	f
MultiTurnsReadSentencePair	cnn/data-util.cc	/^string MultiTurnsReadSentencePair(const std::string& line, std::vector<int>* s, Dict* sd, std::vector<int>* t, Dict* td, bool backofftounk, int kSRC_SOS, int kSRC_EOS, const pair<int, int>& columnids, const pair<bool, bool>& use_dict)$/;"	f
MultiTurnsReadSentencePairWithClassId	cnn/data-util.cc	/^string MultiTurnsReadSentencePairWithClassId(const std::string& line, std::vector<int>* s, Dict* sd, std::vector<int>* t, Dict* td, std::vector<int>* cls, int kSRC_SOS, int kSRC_EOS)$/;"	f
N	cnn/treelstm.h	/^  unsigned N; \/\/ Max branching factor$/;"	m	struct:cnn::TreeLSTMBuilder
NBR_DEV_PARALLEL_UTTS	ext/trainer/train_proc.h	53;"	d
NBR_SIDES	examples/cxtattentional.h	27;"	d
NLAYER	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set NLAYER=2$/;"	v
NLAYER	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set NLAYER=2$/;"	v
NLAYER	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set NLAYER=2$/;"	v
NMNBuilder	cnn/rnnem.cc	/^    NMNBuilder::NMNBuilder(long layers,$/;"	f	class:cnn::NMNBuilder
NMNBuilder	cnn/rnnem.h	/^struct NMNBuilder : public RNNBuilder{$/;"	s	namespace:cnn
NO_TEST	ext/lda/lda.h	/^		NO_TEST,					\/\/ do not report any likelihood$/;"	e	enum:ldaModel::__anon22
NUTT	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set NUTT=10$/;"	v
NUTT	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set NUTT=10$/;"	v
NUTT	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set NUTT=10$/;"	v
Negate	cnn/nodes.h	/^  explicit Negate(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Negate
Negate	cnn/nodes.h	/^struct Negate : public Node {$/;"	s	namespace:cnn
NeuralBagOfWords	examples/textcat.cc	/^  explicit NeuralBagOfWords(Model& m) :$/;"	f	struct:NeuralBagOfWords
NeuralBagOfWords	examples/textcat.cc	/^struct NeuralBagOfWords {$/;"	s	file:
NgramOrder	cnn/metric-util.h	/^    int NgramOrder;$/;"	m	class:BleuMetric
NgramOrder	ext/ngram/ngram.h	/^    int NgramOrder;$/;"	m	class:nGram
Node	cnn/cnn.h	/^     Node() : args() { aux_mem = nullptr; }$/;"	f	struct:cnn::Node
Node	cnn/cnn.h	/^  explicit Node(const T&c) : args(c.begin(), c.end()) {}$/;"	f	struct:cnn::Node
Node	cnn/cnn.h	/^  explicit Node(const std::initializer_list<VariableIndex>& a) : args(a) {}$/;"	f	struct:cnn::Node
Node	cnn/cnn.h	/^struct Node {$/;"	s	namespace:cnn
NumTurn2DialogId	cnn/data-util.h	/^} NumTurn2DialogId;$/;"	t	typeref:struct:__anon18
OB	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
OUTPUT_DIM	examples/textcat.cc	/^long OUTPUT_DIM = 36;$/;"	v
OUTPUT_LAYER	cnn/macros.h	27;"	d
OUTPUT_VOCAB_SIZE	examples/embed-cl.cc	/^long  OUTPUT_VOCAB_SIZE = 0;$/;"	v
OUTPUT_VOCAB_SIZE	examples/encdec.cc	/^unsigned OUTPUT_VOCAB_SIZE = 0;$/;"	v
OrthonormalRandom	cnn/saxe-init.cc	/^void OrthonormalRandom(unsigned dd, cnn::real g, Tensor& x) {$/;"	f	namespace:cnn
PCorpus	cnn/data-util.h	/^typedef vector<PDialogue> PCorpus; \/\/\/ a parallel corpus consists of many parallel dialogues$/;"	t
PDialogue	cnn/data-util.h	/^typedef vector<PTurn> PDialogue;  \/\/\/ a dialogue consists of many turns$/;"	t
PDialogue	cnn/data-util.h	/^typedef vector<PTurn> PDialogue;  \/\/\/ a parallel dialogue consists of turns from each parallel dialogue [#turns][#sentences]$/;"	t
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	213;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	216;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	219;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	222;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	225;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	228;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	231;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	234;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	237;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	240;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	243;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	246;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	249;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	252;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	255;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	258;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	261;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	264;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	267;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	270;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	273;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	276;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	279;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	282;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	285;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	288;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	200;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	203;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	206;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	209;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	212;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	215;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	218;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	221;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	224;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	227;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	230;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	233;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	236;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	239;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	242;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	245;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	248;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	251;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	254;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	257;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	260;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	263;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	266;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	269;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	272;"	d	file:
PLATFORM_ID	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	275;"	d	file:
PRIMES	cnn/data-util.cc	/^const unsigned int PRIMES[] = { 108641969, 116049371, 125925907, 133333309, 145678979, 175308587, 197530793, 234567803, 251851741, 264197411, 330864029, 399999781,$/;"	v
PRIMES_SIZE	cnn/data-util.cc	/^const unsigned int PRIMES_SIZE = sizeof(PRIMES) \/ sizeof(PRIMES[0]);$/;"	v
PTurn	cnn/data-util.h	/^typedef vector<SentencePair> PTurn;  \/\/\/ a turn consits of sentences pairs from difference utterances [#sentences]$/;"	t
PTurn	cnn/data-util.h	/^typedef vector<SentencePair> PTurn;  \/\/\/ a turn consits of sentences pairs from difference utterances$/;"	t
PacketAccess	cnn/simd-functors.h	/^    PacketAccess = packet_traits<Scalar>::HasAdd && packet_traits<Scalar>::HasDiv &&$/;"	e	enum:Eigen::internal::functor_traits::__anon10
PacketAccess	cnn/simd-functors.h	/^    PacketAccess = packet_traits<Scalar>::HasAdd$/;"	e	enum:Eigen::internal::functor_traits::__anon8
PacketAccess	cnn/simd-functors.h	/^    PacketAccess = packet_traits<Scalar>::HasExp && packet_traits<Scalar>::HasMul && packet_traits<Scalar>::HasNegate$/;"	e	enum:Eigen::internal::functor_traits::__anon11
PacketAccess	cnn/simd-functors.h	/^    PacketAccess = packet_traits<Scalar>::HasSub && packet_traits<Scalar>::HasExp$/;"	e	enum:Eigen::internal::functor_traits::__anon15
PacketAccess	cnn/simd-functors.h	/^    PacketAccess = packet_traits<Scalar>::HasSub && packet_traits<Scalar>::HasMul$/;"	e	enum:Eigen::internal::functor_traits::__anon12
PacketAccess	cnn/simd-functors.h	/^    PacketAccess = packet_traits<Scalar>::HasSub && packet_traits<Scalar>::HasMul$/;"	e	enum:Eigen::internal::functor_traits::__anon14
PacketAccess	cnn/simd-functors.h	/^    PacketAccess = packet_traits<Scalar>::HasSub$/;"	e	enum:Eigen::internal::functor_traits::__anon9
PacketAccess	cnn/simd-functors.h	/^    PacketAccess = packet_traits<Scalar>::HasTanh$/;"	e	enum:Eigen::internal::functor_traits::__anon13
PairwiseRankLoss	cnn/nodes.h	/^  explicit PairwiseRankLoss(const std::initializer_list<VariableIndex>& a, cnn::real m = 1.0) : Node(a), margin(m) {}$/;"	f	struct:cnn::PairwiseRankLoss
PairwiseRankLoss	cnn/nodes.h	/^struct PairwiseRankLoss : public Node {$/;"	s	namespace:cnn
ParameterNode	cnn/param-nodes.h	/^  explicit ParameterNode(Parameters* p) : dim(p->dim), params(p) {}$/;"	f	struct:cnn::ParameterNode
ParameterNode	cnn/param-nodes.h	/^struct ParameterNode : public ParameterNodeBase {$/;"	s	namespace:cnn
ParameterNodeBase	cnn/param-nodes.h	/^struct ParameterNodeBase : public Node {$/;"	s	namespace:cnn
Parameters	cnn/model.cc	/^Parameters::Parameters(const Dim& d, cnn::real scale , std::string nodename) : dim(d), name(nodename) {$/;"	f	class:cnn::Parameters
Parameters	cnn/model.h	/^  Parameters() {}$/;"	f	struct:cnn::Parameters
Parameters	cnn/model.h	/^struct Parameters : public ParametersBase {$/;"	s	namespace:cnn
ParametersBase	cnn/model.h	/^struct ParametersBase {$/;"	s	namespace:cnn
PickElement	cnn/nodes.h	/^  explicit PickElement(const std::initializer_list<VariableIndex>& a, const unsigned* pv) : Node(a), val(), pval(pv) {}$/;"	f	struct:cnn::PickElement
PickElement	cnn/nodes.h	/^  explicit PickElement(const std::initializer_list<VariableIndex>& a, unsigned v) : Node(a), val(v), pval(&val) {}$/;"	f	struct:cnn::PickElement
PickElement	cnn/nodes.h	/^struct PickElement : public Node {$/;"	s	namespace:cnn
PickRange	cnn/nodes.h	/^  explicit PickRange(const std::initializer_list<VariableIndex>& a, unsigned start, unsigned end) : Node(a), start(start), end(end) {}$/;"	f	struct:cnn::PickRange
PickRange	cnn/nodes.h	/^struct PickRange : public Node {$/;"	s	namespace:cnn
PoissonRegressionLoss	cnn/nodes.h	/^  explicit PoissonRegressionLoss(const std::initializer_list<VariableIndex>& a, const unsigned* ptrue_y) : Node(a), ty(), pty(ptrue_y) {}$/;"	f	struct:cnn::PoissonRegressionLoss
PoissonRegressionLoss	cnn/nodes.h	/^  explicit PoissonRegressionLoss(const std::initializer_list<VariableIndex>& a, unsigned true_y) : Node(a), ty(true_y), pty(&ty) {}$/;"	f	struct:cnn::PoissonRegressionLoss
PoissonRegressionLoss	cnn/nodes.h	/^struct PoissonRegressionLoss : public Node {$/;"	s	namespace:cnn
Pow	cnn/nodes.h	/^  explicit Pow(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Pow
Pow	cnn/nodes.h	/^struct Pow : public Node {$/;"	s	namespace:cnn
Precision	cnn/metric-util.h	/^    cnn::real Precision(LossStats stats)$/;"	f	class:BleuMetric
PrintGraphviz	cnn/cnn.cc	/^void ComputationGraph::PrintGraphviz() const {$/;"	f	class:cnn::ComputationGraph
PushElementsToMemory	cnn/tensor.cc	/^    void TensorTools::PushElementsToMemory(int& size, const int buf_size, cnn::real* v, const Tensor& v_src) {$/;"	f	class:cnn::TensorTools
Q2K	cnn/dglstm.cc	/^        X2O, H2O, C2O, BO, X2C, H2C, BC, X2K, C2K, Q2K, BK, STAB, X2K0 };$/;"	e	enum:cnn::__anon3	file:
READING_INPUT	cnn/rnn-state-machine.h	/^enum RNNState {CREATED, GRAPH_READY, READING_INPUT};$/;"	e	enum:cnn::RNNState
REASONING_STEPS	ext/dialogue/attention_with_intention.h	37;"	d
REINFORCE_nosegmental_forward_backward	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::REINFORCE_nosegmental_forward_backward(Model &model, AM_t &am, AM_t &am_mirrow, PDialogue &v_v_dialogues, int nutt,$/;"	f	class:TrainProcess
REINFORCEtrain	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::REINFORCEtrain(Model &model, AM_t &am, AM_t &am_agent_mirrow, Corpus &training, Corpus &devel, Trainer &sgd, string out_file, Dict & td, int max_epochs, int nparallel, cnn::real& largest_cost, cnn::real reward_baseline, cnn::real threshold_prob_for_sampling)$/;"	f	class:TrainProcess
REP_DIM	examples/embed-cl.cc	/^long  REP_DIM = 128;$/;"	v
RLAttentionWithIntentionModel	ext/dialogue/dialogue_process.h	/^        RLAttentionWithIntentionModel(cnn::Model& model,$/;"	f	class:cnn::RLAttentionWithIntentionModel
RLAttentionWithIntentionModel	ext/dialogue/dialogue_process.h	/^    class RLAttentionWithIntentionModel : public AttentionWithIntentionModel<DBuilder>{$/;"	c	namespace:cnn
RM	build/Makefile	/^RM = \/usr\/bin\/cmake -E remove -f$/;"	m
RM	build/cnn/Makefile	/^RM = \/usr\/bin\/cmake -E remove -f$/;"	m
RM	build/conversation/dev/src/Makefile	/^RM = \/usr\/bin\/cmake -E remove -f$/;"	m
RM	build/examples/Makefile	/^RM = \/usr\/bin\/cmake -E remove -f$/;"	m
RNN	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set RNN=gru$/;"	v
RNN	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set RNN=gru$/;"	v
RNN	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set RNN=gru$/;"	v
RNNBuilder	cnn/rnn.h	/^  RNNBuilder() : cur(-1) , dparallel (1) {}$/;"	f	struct:cnn::RNNBuilder
RNNBuilder	cnn/rnn.h	/^  RNNBuilder(const RNNBuilder& ref)$/;"	f	struct:cnn::RNNBuilder
RNNBuilder	cnn/rnn.h	/^struct RNNBuilder {$/;"	s	namespace:cnn
RNNEM_ALIGN_DIM	cnn/rnnem.h	17;"	d
RNNEM_MEM_SIZE	cnn/rnnem.h	16;"	d
RNNLanguageModel	examples/rnnlm-aevb.cc	/^  explicit RNNLanguageModel(Model& model) :$/;"	f	struct:RNNLanguageModel
RNNLanguageModel	examples/rnnlm-aevb.cc	/^struct RNNLanguageModel {$/;"	s	file:
RNNLanguageModel	examples/rnnlm.cc	/^  explicit RNNLanguageModel(Model& model) : builder(LAYERS, INPUT_DIM, HIDDEN_DIM, &model) {$/;"	f	struct:RNNLanguageModel
RNNLanguageModel	examples/rnnlm.cc	/^struct RNNLanguageModel {$/;"	s	file:
RNNLanguageModel	examples/rnnlm2.cc	/^  explicit RNNLanguageModel(Model& model) : builder(LAYERS, vector<unsigned>{INPUT_DIM, HIDDEN_DIM}, &model) {$/;"	f	struct:RNNLanguageModel
RNNLanguageModel	examples/rnnlm2.cc	/^struct RNNLanguageModel {$/;"	s	file:
RNNLanguageModel	examples/rnnlm2_cls_based.cc	/^  explicit RNNLanguageModel(const vector<int>& cls2nbrwords, \/\/\/ #words for each class, class starts from 0$/;"	f	struct:RNNLanguageModel
RNNLanguageModel	examples/rnnlm2_cls_based.cc	/^struct RNNLanguageModel {$/;"	s	file:
RNNLanguageModel	examples/tag-bilstm.cc	/^  explicit RNNLanguageModel(Model& model) :$/;"	f	struct:RNNLanguageModel
RNNLanguageModel	examples/tag-bilstm.cc	/^struct RNNLanguageModel {$/;"	s	file:
RNNLengthPredictor	examples/poisson-regression.cc	/^  explicit RNNLengthPredictor(Model& model) : builder(LAYERS, INPUT_DIM, HIDDEN_DIM, &model) {$/;"	f	struct:RNNLengthPredictor
RNNLengthPredictor	examples/poisson-regression.cc	/^struct RNNLengthPredictor {$/;"	s	file:
RNNOp	cnn/rnn-state-machine.h	/^enum RNNOp {new_graph, start_new_sequence, add_input};$/;"	g	namespace:cnn
RNNSkipLM	examples/skiprnnlm.cc	/^    explicit RNNSkipLM(Model& model) : builder(LAYERS, INPUT_DIM, HIDDEN_DIM, &model, true) {$/;"	f	struct:RNNSkipLM
RNNSkipLM	examples/skiprnnlm.cc	/^struct RNNSkipLM {$/;"	s	file:
RNNState	cnn/rnn-state-machine.h	/^enum RNNState {CREATED, GRAPH_READY, READING_INPUT};$/;"	g	namespace:cnn
RNNStateMachine	cnn/rnn-state-machine.h	/^  RNNStateMachine() : q_(RNNState::CREATED) {}$/;"	f	class:cnn::RNNStateMachine
RNNStateMachine	cnn/rnn-state-machine.h	/^class RNNStateMachine {$/;"	c	namespace:cnn
RandomBernoulli	cnn/tensor.cc	/^    void TensorTools::RandomBernoulli(Tensor& val, cnn::real p, cnn::real scale) {$/;"	f	class:cnn::TensorTools
RandomSample	examples/rnnlm.cc	/^  void RandomSample(int max_len = 150) {$/;"	f	struct:RNNLanguageModel
RandomSample	examples/rnnlm2.cc	/^  void RandomSample(int max_len = 150) {$/;"	f	struct:RNNLanguageModel
Randomize	cnn/tensor.cc	/^    void TensorTools::Randomize(Tensor& d) {$/;"	f	class:cnn::TensorTools
Randomize	cnn/tensor.cc	/^    void TensorTools::Randomize(Tensor& val, cnn::real scale) {$/;"	f	class:cnn::TensorTools
RandomizeNormal	cnn/tensor.cc	/^    void TensorTools::RandomizeNormal(cnn::real mean, cnn::real stddev, Tensor& val) {$/;"	f	class:cnn::TensorTools
ReadData	examples/mp.cc	/^vector<Datum> ReadData(string filename) {$/;"	f
ReadIntVector	examples/mp.cc	/^vector<T> ReadIntVector(int pipe) {$/;"	f
ReadNumberedSentencePair	examples/attentional.cc	/^void ReadNumberedSentencePair(const std::string& line, std::vector<int>* s, Dict* sd, std::vector<int>* t, Dict* td, int &num) $/;"	f
ReadNumberedSentencePair	examples/attentional.cc	/^void ReadNumberedSentencePair(const std::string& line, std::vector<int>* t, Dict* td, int &num)$/;"	f
ReadReal	examples/mp.cc	/^cnn::real ReadReal(int pipe) {$/;"	f
ReadSentence	cnn/dict.cc	/^std::vector<int> ReadSentence(const std::string& line, Dict* sd) {$/;"	f	namespace:cnn
ReadSentence	cnn/dict.cc	/^std::vector<int> ReadSentence(const std::wstring& line, WDict* sd) {$/;"	f	namespace:cnn
ReadSentencePair	cnn/dict.cc	/^void ReadSentencePair(const std::string& line, std::vector<int>* s, Dict* sd, std::vector<int>* t, Dict* td) {$/;"	f	namespace:cnn
ReadSentencePair	cnn/dict.cc	/^void ReadSentencePair(const std::wstring& line, std::vector<int>* s, WDict* sd, std::vector<int>* t, WDict* td) {$/;"	f	namespace:cnn
ReadStringWithItsId	cnn/data-util.cc	/^string ReadStringWithItsId(const std::string& line, std::vector<int>& s, stId2String<string>& sd, const pair<int, int>& columnids)$/;"	f
Rectify	cnn/nodes.h	/^  explicit Rectify(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Rectify
Rectify	cnn/nodes.h	/^struct Rectify : public Node {$/;"	s	namespace:cnn
Reduce	cnn/nodes.h	/^    template <typename T> explicit Reduce(const T& a) : Node(a) {}$/;"	f	struct:cnn::Reduce
Reduce	cnn/nodes.h	/^struct Reduce: public Node {$/;"	s	namespace:cnn
ReferenceNode	cnn/param-nodes.h	/^    explicit ReferenceNode(const Dim& d, const cnn::real* pdat) : dim(d), pdata(pdat) {}$/;"	f	struct:cnn::ReferenceNode
ReferenceNode	cnn/param-nodes.h	/^struct ReferenceNode : public Node {$/;"	s	namespace:cnn
RegAttentionalModel	examples/regattentional.h	/^RegAttentionalModel<Builder>::RegAttentionalModel(cnn::Model& model,$/;"	f	class:cnn::RegAttentionalModel
RegAttentionalModel	examples/regattentional.h	/^struct RegAttentionalModel{$/;"	s	namespace:cnn
ReluDNNBuilder	cnn/dnn.h	/^        ReluDNNBuilder() { dparallel = 1; }$/;"	f	class:cnn::ReluDNNBuilder
ReluDNNBuilder	cnn/dnn.h	/^        explicit ReluDNNBuilder(unsigned layers,$/;"	f	class:cnn::ReluDNNBuilder
ReluDNNBuilder	cnn/dnn.h	/^    class ReluDNNBuilder  : public DNNBuilder{$/;"	c	namespace:cnn
RemoveArgs	cnn/init.cc	/^	static void RemoveArgs(int& argc, char**& argv, int& argi, int n) {$/;"	f	namespace:cnn
Reshape	cnn/nodes.h	/^  explicit Reshape(const std::initializer_list<VariableIndex>& a, const Dim& to) : Node(a), to(to) {}$/;"	f	struct:cnn::Reshape
Reshape	cnn/nodes.h	/^struct Reshape : public Node {$/;"	s	namespace:cnn
RestrictedLogSoftmax	cnn/nodes.h	/^  explicit RestrictedLogSoftmax(const std::initializer_list<VariableIndex>& a, const std::vector<unsigned>& d) : Node(a), denom(d) {}$/;"	f	struct:cnn::RestrictedLogSoftmax
RestrictedLogSoftmax	cnn/nodes.h	/^struct RestrictedLogSoftmax : public Node {$/;"	s	namespace:cnn
RmsPropTrainer	cnn/training.h	/^  explicit RmsPropTrainer(Model* m, cnn::real lam = 1e-6, cnn::real e0 = 0.1, cnn::real eps = 1e-20, cnn::real rho = 0.95) :$/;"	f	struct:cnn::RmsPropTrainer
RmsPropTrainer	cnn/training.h	/^struct RmsPropTrainer : public Trainer {$/;"	s	namespace:cnn
RmsPropWithMomentumTrainer	cnn/training.h	/^    explicit RmsPropWithMomentumTrainer(Model* m, cnn::real lam = 1e-6, cnn::real e0 = 0.1, cnn::real eps = 1e-20, cnn::real rho = 0.95, cnn::real mom = 0.9) :$/;"	f	struct:cnn::RmsPropWithMomentumTrainer
RmsPropWithMomentumTrainer	cnn/training.h	/^struct RmsPropWithMomentumTrainer : public Trainer {$/;"	s	namespace:cnn
RunChild	examples/mp.cc	/^int RunChild(unsigned cid, ComputationGraph& cg, Trainer* trainer, vector<Workload>& workloads,$/;"	f
RunParent	examples/mp.cc	/^void RunParent(vector<Datum>& data, vector<Workload>& workloads, ModelParameters& model_params, Trainer* trainer) {$/;"	f
SCALE	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set SCALE=0.1$/;"	v
SCALE	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set SCALE=0.1$/;"	v
SCALE	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set SCALE=0.1$/;"	v
SELF_TEST	ext/lda/lda.h	/^		SELF_TEST,					\/\/ report training likelihood$/;"	e	enum:ldaModel::__anon22
SEPARATE_TEST	ext/lda/lda.h	/^		SEPARATE_TEST				\/\/ report likelihood on a held-out testing set$/;"	e	enum:ldaModel::__anon22
SHELL	build/Makefile	/^SHELL = \/bin\/sh$/;"	m
SHELL	build/cnn/Makefile	/^SHELL = \/bin\/sh$/;"	m
SHELL	build/conversation/dev/src/Makefile	/^SHELL = \/bin\/sh$/;"	m
SHELL	build/examples/Makefile	/^SHELL = \/bin\/sh$/;"	m
SIDX	examples/skiprnnlm.cc	/^enum { WORD=0, SIDX, WIDX };$/;"	e	enum:__anon20	file:
SRC_VOCAB_SIZE	examples/attentional.cc	/^unsigned SRC_VOCAB_SIZE = 0;$/;"	v
STAB	cnn/dglstm.cc	/^        X2O, H2O, C2O, BO, X2C, H2C, BC, X2K, C2K, Q2K, BK, STAB, X2K0 };$/;"	e	enum:cnn::__anon3	file:
STG	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set STG=s41$/;"	v
STG	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set STG=s41$/;"	v
STG	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set STG=s41_full$/;"	v
SUFFIXES	build/Makefile	/^SUFFIXES =$/;"	m
SUFFIXES	build/cnn/Makefile	/^SUFFIXES =$/;"	m
SUFFIXES	build/conversation/dev/src/Makefile	/^SUFFIXES =$/;"	m
SUFFIXES	build/examples/Makefile	/^SUFFIXES =$/;"	m
SaveModel	ext/ngram/ngram.h	/^    void SaveModel()$/;"	f	class:nGram
SaveModel	ext/ngram/ngram.h	/^    void SaveModel(const string& ext)$/;"	f	class:nGram
ScalarInputNode	cnn/param-nodes.h	/^  explicit ScalarInputNode(cnn::real s) : data(s), pdata(&data) {}$/;"	f	struct:cnn::ScalarInputNode
ScalarInputNode	cnn/param-nodes.h	/^  explicit ScalarInputNode(const cnn::real* ps) : data(), pdata(ps) {}$/;"	f	struct:cnn::ScalarInputNode
ScalarInputNode	cnn/param-nodes.h	/^struct ScalarInputNode : public Node {$/;"	s	namespace:cnn
Sentence	cnn/data-util.h	/^typedef vector<int> Sentence;$/;"	t
Sentence	examples/attentional.cc	/^typedef vector<int> Sentence;$/;"	t	file:
Sentence	examples/mem_seq2seq_encdec.cc	/^typedef vector<int> Sentence;     $/;"	t	file:
Sentence	examples/seq2seq_encdec.cc	/^typedef vector<int> Sentence;     $/;"	t	file:
Sentence	examples/skiprnnlm.cc	/^typedef vector<TokenSkip> Sentence;$/;"	t	file:
SentencePair	cnn/data-util.h	/^typedef pair<Sentence, Sentence> SentencePair;$/;"	t
SentencePair	examples/attentional.cc	/^typedef pair<Sentence, Sentence> SentencePair;$/;"	t	file:
SentencePair	examples/mem_seq2seq_encdec.cc	/^typedef pair<Sentence, Sentence> SentencePair;  $/;"	t	file:
SentencePair	examples/seq2seq_encdec.cc	/^typedef pair<Sentence, Sentence> SentencePair;  $/;"	t	file:
SentencePairAndClassId	cnn/data-util.h	/^typedef pair<Sentence, SentenceWithId> SentencePairAndClassId;$/;"	t
SentenceTuple	cnn/data-util.h	/^typedef triplet<Sentence> SentenceTuple;$/;"	t
SentenceWithId	cnn/data-util.h	/^typedef pair<Sentence, int> SentenceWithId;$/;"	t
Sentences	cnn/data-util.h	/^typedef vector<Sentence> Sentences;$/;"	t
Seq2SeqEncDecModel	ext/dialogue/cxtencdec.h	/^    Seq2SeqEncDecModel(cnn::Model& model, unsigned vocab_size_src, unsigned vocab_size_tgt, const vector<unsigned int>& layers, const vector<unsigned>& hidden_dims, int hidden_replicates, int decoder_use_additional_input = 0, int mem_slots = 0, cnn::real iscale = 1.0) :$/;"	f	class:cnn::Seq2SeqEncDecModel
Seq2SeqEncDecModel	ext/dialogue/cxtencdec.h	/^class Seq2SeqEncDecModel : public DialogueBuilder<Builder, Decoder>{$/;"	c	namespace:cnn
SetElement	cnn/tensor.cc	/^    void TensorTools::SetElement(const Tensor& v, int index, cnn::real value) {$/;"	f	class:cnn::TensorTools
SetElements	cnn/tensor.cc	/^    void TensorTools::SetElements(const Tensor& v, const vector<cnn::real>& vec) {$/;"	f	class:cnn::TensorTools
SetUnk	cnn/dict.h	/^  void SetUnk(const std::string& word) {$/;"	f	class:cnn::stDict
ShadowLookupParameters	cnn/shadow-params.cc	/^ShadowLookupParameters::ShadowLookupParameters(const LookupParameters& lp) : h(lp.values) {$/;"	f	class:cnn::ShadowLookupParameters
ShadowLookupParameters	cnn/shadow-params.h	/^struct ShadowLookupParameters {$/;"	s	namespace:cnn
ShadowParameters	cnn/shadow-params.cc	/^ShadowParameters::ShadowParameters(const Parameters& p) : h(p.values) {$/;"	f	class:cnn::ShadowParameters
ShadowParameters	cnn/shadow-params.h	/^struct ShadowParameters {$/;"	s	namespace:cnn
SharedObject	examples/mp.cc	/^struct SharedObject {$/;"	s	file:
SimpleExecutionEngine	cnn/exec.h	/^  explicit SimpleExecutionEngine(const ComputationGraph& cg) : ExecutionEngine(cg) {}$/;"	f	class:cnn::SimpleExecutionEngine
SimpleExecutionEngine	cnn/exec.h	/^class SimpleExecutionEngine : public ExecutionEngine {$/;"	c	namespace:cnn
SimpleRNNBuilder	cnn/rnn.cc	/^SimpleRNNBuilder::SimpleRNNBuilder(unsigned ilayers,$/;"	f	class:cnn::SimpleRNNBuilder
SimpleRNNBuilder	cnn/rnn.h	/^  SimpleRNNBuilder(const SimpleRNNBuilder& ref) $/;"	f	struct:cnn::SimpleRNNBuilder
SimpleRNNBuilder	cnn/rnn.h	/^struct SimpleRNNBuilder : public RNNBuilder {$/;"	s	namespace:cnn
SimpleRNNBuilderWithELU	cnn/rnn.h	/^    SimpleRNNBuilderWithELU(const SimpleRNNBuilderWithELU& ref)$/;"	f	struct:cnn::SimpleRNNBuilderWithELU
SimpleRNNBuilderWithELU	cnn/rnn.h	/^    explicit SimpleRNNBuilderWithELU(unsigned layers,$/;"	f	struct:cnn::SimpleRNNBuilderWithELU
SimpleRNNBuilderWithELU	cnn/rnn.h	/^struct SimpleRNNBuilderWithELU : public SimpleRNNBuilder {$/;"	s	namespace:cnn
SimpleSGDTrainer	cnn/training.h	/^    explicit SimpleSGDTrainer(Model* m, cnn::real lam = 1e-6, cnn::real e0 = 0.1) : Trainer(m, lam, e0) {}$/;"	f	struct:cnn::SimpleSGDTrainer
SimpleSGDTrainer	cnn/training.h	/^struct SimpleSGDTrainer : public Trainer {$/;"	s	namespace:cnn
SizeToBlockThreadPair	cnn/cuda.h	/^inline std::pair<int,int> SizeToBlockThreadPair(int n) {$/;"	f	namespace:cnn
SoftSign	cnn/nodes.h	/^  explicit SoftSign(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::SoftSign
SoftSign	cnn/nodes.h	/^struct SoftSign : public Node {$/;"	s	namespace:cnn
Softmax	cnn/nodes.h	/^  explicit Softmax(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Softmax
Softmax	cnn/nodes.h	/^struct Softmax : public Node {$/;"	s	namespace:cnn
SpawnChildren	examples/mp.cc	/^unsigned SpawnChildren(vector<Workload>& workloads) {$/;"	f
Sqrt	cnn/nodes.h	/^  explicit Sqrt(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Sqrt
Sqrt	cnn/nodes.h	/^struct Sqrt : public Node {$/;"	s	namespace:cnn
Square	cnn/nodes.h	/^  explicit Square(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Square
Square	cnn/nodes.h	/^struct Square : public Node {$/;"	s	namespace:cnn
SquaredEuclideanDistance	cnn/nodes.h	/^  explicit SquaredEuclideanDistance(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::SquaredEuclideanDistance
SquaredEuclideanDistance	cnn/nodes.h	/^struct SquaredEuclideanDistance : public Node {$/;"	s	namespace:cnn
StatementsQuery	cnn/data-util.h	/^typedef pair<vector<Sentence>, Sentence> StatementsQuery;$/;"	t
Sum	cnn/nodes.h	/^  template <typename T> explicit Sum(const T& a) : Node(a) {}$/;"	f	struct:cnn::Sum
Sum	cnn/nodes.h	/^struct Sum : public Node {$/;"	s	namespace:cnn
SumBatches	cnn/nodes.h	/^  template <typename T> explicit SumBatches(const T& a) : Node(a) {}$/;"	f	struct:cnn::SumBatches
SumBatches	cnn/nodes.h	/^struct SumBatches : public Node {$/;"	s	namespace:cnn
SumColumns	cnn/nodes.h	/^  template <typename T> explicit SumColumns(const T& a) : Node(a) {}$/;"	f	struct:cnn::SumColumns
SumColumns	cnn/nodes.h	/^struct SumColumns : public Node {$/;"	s	namespace:cnn
T2IMap	cnn/dict.h	/^    typedef std::unordered_map<T, int> T2IMap;$/;"	t	class:cnn::stId2String
TAG	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set TAG=%STG%.%CMDT%.nosplitdialogue.%RNN%.e%ETA%.s%SCALE%.%TRAINER%.h%HDIM%.i%IDIM%.l%NLAYER%.clip%CLIP%.bsize%NUTT%.sz10k$/;"	v
TAG	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set TAG=%STG%.%CMDT%.nosplitdialogue.%RNN%.e%ETA%.s%SCALE%.%TRAINER%.h%HDIM%.i%IDIM%.l%NLAYER%.clip%CLIP%.bsize%NUTT%.sz10k$/;"	v
TAG	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set TAG=%STG%.%CMDT%.nosplitdialogue.%RNN%.e%ETA%.s%SCALE%.%TRAINER%.h%HDIM%.i%IDIM%.l%NLAYER%.clip%CLIP%.bsize%NUTT%.sz10k$/;"	v
TAG_DIM	examples/tag-bilstm.cc	/^long TAG_DIM = 32;$/;"	v
TAG_HIDDEN_DIM	examples/tag-bilstm.cc	/^long TAG_HIDDEN_DIM = 32;$/;"	v
TAG_SIZE	examples/tag-bilstm.cc	/^long TAG_SIZE = 0;$/;"	v
TGT_VOCAB_SIZE	examples/attentional.cc	/^unsigned TGT_VOCAB_SIZE = 0;$/;"	v
TRAINER	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^set TRAINER=rmspropwithmomentum$/;"	v
TRAINER	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^set TRAINER=rmspropwithmomentum$/;"	v
TRAINER	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^set TRAINER=rmspropwithmomentum$/;"	v
Tanh	cnn/nodes.h	/^  explicit Tanh(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Tanh
Tanh	cnn/nodes.h	/^struct Tanh : public Node {$/;"	s	namespace:cnn
Tensor	cnn/tensor.h	/^  Tensor(const Dim& d, cnn::real* v, int devid) : d(d), v(v), m_device_id(devid) { }$/;"	f	struct:cnn::Tensor
Tensor	cnn/tensor.h	/^struct Tensor {$/;"	s	namespace:cnn
TensorTools	cnn/tensor.h	/^struct TensorTools {$/;"	s	namespace:cnn
TestTensorSetup	cnn/tests/test_utils.h	/^  TestTensorSetup() {$/;"	f	struct:cnn::TestTensorSetup
TestTensorSetup	cnn/tests/test_utils.h	/^struct TestTensorSetup {$/;"	s	namespace:cnn
Timer	cnn/timing.h	/^  Timer(const std::string& msg) : msg(msg), start(std::chrono::high_resolution_clock::now()) {}$/;"	f	struct:cnn::Timer
Timer	cnn/timing.h	/^struct Timer {$/;"	s	namespace:cnn
TokenSkip	examples/skiprnnlm.cc	/^typedef tuple<int,int,int> TokenSkip;$/;"	t	file:
TraceOfProduct	cnn/nodes.h	/^  explicit TraceOfProduct(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::TraceOfProduct
TraceOfProduct	cnn/nodes.h	/^struct TraceOfProduct : public Node {$/;"	s	namespace:cnn
TrainProcess	ext/trainer/train_proc.h	/^    TrainProcess() {$/;"	f	class:TrainProcess
TrainProcess	ext/trainer/train_proc.h	/^class TrainProcess{$/;"	c
Trainer	cnn/training.h	/^  explicit Trainer(Model* m, cnn::real lam, cnn::real e0) :$/;"	f	struct:cnn::Trainer
Trainer	cnn/training.h	/^struct Trainer {$/;"	s	namespace:cnn
TrainingScores	ext/trainer/train_proc.h	/^    TrainingScores(int bufsize) : training_score_buf_size(bufsize) {$/;"	f	struct:TrainingScores
TrainingScores	ext/trainer/train_proc.h	/^struct TrainingScores{$/;"	s
Transpose	cnn/nodes.h	/^  explicit Transpose(const std::initializer_list<VariableIndex>& a) : Node(a) {}$/;"	f	struct:cnn::Transpose
Transpose	cnn/nodes.h	/^struct Transpose : public Node {$/;"	s	namespace:cnn
TreeLSTMBuilder	cnn/treelstm.cc	/^TreeLSTMBuilder::TreeLSTMBuilder(unsigned N,$/;"	f	class:cnn::TreeLSTMBuilder
TreeLSTMBuilder	cnn/treelstm.h	/^struct TreeLSTMBuilder : public RNNBuilder {$/;"	s	namespace:cnn
TupleCorpus	cnn/data-util.h	/^typedef vector<TupleDialogue> TupleCorpus;$/;"	t
TupleDialogue	cnn/data-util.h	/^typedef vector<SentenceTuple> TupleDialogue;$/;"	t
UNDERSTAND_AWI	ext/dialogue/dialogue.h	14;"	d
UNDERSTAND_AWI_ADD_ATTENTION	ext/dialogue/dialogue.h	15;"	d
USE_FASTEXP	cnn/functors.h	48;"	d
USE_FASTEXP	cnn/functors.h	50;"	d
UnitTest	cnn/grad-check.cc	/^void UnitTest(Expression node, ComputationGraph& g) {$/;"	f	namespace:cnn
UpdateNgramCounts	ext/ngram/ngram.h	/^    void UpdateNgramCounts(const Sentence & tokens, int order, Dict& sd)$/;"	f	class:nGram
UpdateNgramCounts	ext/ngram/ngram.h	/^    void UpdateNgramCounts(const vector<string> & tokens, int order, Dict& sd)$/;"	f	class:nGram
V	ext/lda/lda.h	/^	int V; 							\/\/ Number of words in dictionary$/;"	m	class:ldaModel
VOCAB_SIZE	examples/poisson-regression.cc	/^long VOCAB_SIZE = 0;$/;"	v
VOCAB_SIZE	examples/rnnlm-aevb.cc	/^unsigned VOCAB_SIZE = 0;$/;"	v
VOCAB_SIZE	examples/rnnlm.cc	/^long VOCAB_SIZE = 0;$/;"	v
VOCAB_SIZE	examples/rnnlm2.cc	/^unsigned int VOCAB_SIZE = 0;$/;"	v
VOCAB_SIZE	examples/rnnlm2_cls_based.cc	/^unsigned int VOCAB_SIZE = 0;$/;"	v
VOCAB_SIZE	examples/skiprnnlm.cc	/^unsigned VOCAB_SIZE = 0;$/;"	v
VOCAB_SIZE	examples/tag-bilstm.cc	/^long VOCAB_SIZE = 0;$/;"	v
VOCAB_SIZE	examples/textcat.cc	/^long VOCAB_SIZE = 0;$/;"	v
VOCAB_SIZE_SRC	examples/mem_seq2seq_encdec.cc	/^unsigned VOCAB_SIZE_SRC = 0;$/;"	v
VOCAB_SIZE_SRC	examples/seq2seq_encdec.cc	/^long VOCAB_SIZE_SRC = 0;$/;"	v
VOCAB_SIZE_SRC	ext/trainer/train_proc.h	/^unsigned VOCAB_SIZE_SRC = 0;$/;"	v
VOCAB_SIZE_TGT	examples/mem_seq2seq_encdec.cc	/^unsigned VOCAB_SIZE_TGT = 0;$/;"	v
VOCAB_SIZE_TGT	examples/seq2seq_encdec.cc	/^long VOCAB_SIZE_TGT = 0;$/;"	v
VOCAB_SIZE_TGT	ext/trainer/train_proc.h	/^unsigned VOCAB_SIZE_TGT = 0;$/;"	v
Vbeta	ext/lda/lda.h	/^	double beta, Vbeta;				\/\/ Dirichlet language ldaModel$/;"	m	class:ldaModel
W0	cnn/rnnem.cc	/^        W0,$/;"	e	enum:cnn::__anon7	file:
WA	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
WDict	cnn/dict.h	/^typedef stDict<std::wstring> WDict;$/;"	t	namespace:cnn
WEXI	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
WG	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
WGAMMA	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
WGAMMAWTM1	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
WIDX	examples/skiprnnlm.cc	/^enum { WORD=0, SIDX, WIDX };$/;"	e	enum:__anon20	file:
WITH_EIGEN_BACKEND	build/config.h	6;"	d
WK	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
WKB	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
WO	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
WORD	examples/skiprnnlm.cc	/^enum { WORD=0, SIDX, WIDX };$/;"	e	enum:__anon20	file:
WORKDIR	exp/encdec/encdec.bat	/^set WORKDIR=.$/;"	v
WORKDIR	exp/lm/rnnlm2.bat	/^set WORKDIR=.$/;"	v
WORKDIR	exp/lm/rnnlm2.dglstm.bat	/^set WORKDIR=\\\\gcr\\scratch\\b99\\kaisheny\\exp\\lm$/;"	v
WORKDIR	exp/lm/rnnlm2_cls.bat	/^set WORKDIR=c:\\dev\\mycnn\\exp\\lm$/;"	v
WORKDIR	exp/lm/rnnlm2_cls_tst.bat	/^set WORKDIR=c:\\dev\\mycnn\\exp\\lm$/;"	v
WOXI	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
WV	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
WordsPerSecond	cnn/timing.h	/^  void WordsPerSecond(int nwords)$/;"	f	struct:cnn::Timer
Workload	examples/mp.cc	/^struct Workload {$/;"	s	file:
WriteIntVector	examples/mp.cc	/^void WriteIntVector(int pipe, const vector<T>& vec) {$/;"	f
WriteReal	examples/mp.cc	/^void WriteReal(int pipe, cnn::real v) {$/;"	f
X2C	cnn/approximator.cc	/^    enum { X2C = 0, X2CB};$/;"	e	enum:cnn::__anon1	file:
X2C	cnn/deep-lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon2	file:
X2C	cnn/dglstm.cc	/^        X2O, H2O, C2O, BO, X2C, H2C, BC, X2K, C2K, Q2K, BK, STAB, X2K0 };$/;"	e	enum:cnn::__anon3	file:
X2C	cnn/lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon6	file:
X2C	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
X2C	cnn/treelstm.cc	/^enum { X2I, C2I, BI, X2F, C2F, BF, X2O, C2O, BO, X2C, BC };$/;"	e	enum:cnn::__anon16	file:
X2CB	cnn/approximator.cc	/^    enum { X2C = 0, X2CB};$/;"	e	enum:cnn::__anon1	file:
X2F	cnn/dglstm.cc	/^        X2F, H2F, C2F, BF, $/;"	e	enum:cnn::__anon3	file:
X2F	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
X2F	cnn/treelstm.cc	/^enum { X2I, C2I, BI, X2F, C2F, BF, X2O, C2O, BO, X2C, BC };$/;"	e	enum:cnn::__anon16	file:
X2H	cnn/dnn.cc	/^    enum { X2H = 0, X2HB };$/;"	e	enum:cnn::__anon4	file:
X2H	cnn/gru.cc	/^enum { X2Z, H2Z, BZ, X2R, H2R, BR, X2H, H2H, BH };$/;"	e	enum:cnn::__anon5	file:
X2H	cnn/rnn.cc	/^enum { X2H=0, H2H, HB, L2H };$/;"	e	enum:cnn::__anon19	file:
X2HB	cnn/dnn.cc	/^    enum { X2H = 0, X2HB };$/;"	e	enum:cnn::__anon4	file:
X2I	cnn/deep-lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon2	file:
X2I	cnn/dglstm.cc	/^    enum { X2I, H2I, C2I, BI, $/;"	e	enum:cnn::__anon3	file:
X2I	cnn/lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon6	file:
X2I	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
X2I	cnn/treelstm.cc	/^enum { X2I, C2I, BI, X2F, C2F, BF, X2O, C2O, BO, X2C, BC };$/;"	e	enum:cnn::__anon16	file:
X2K	cnn/dglstm.cc	/^        X2O, H2O, C2O, BO, X2C, H2C, BC, X2K, C2K, Q2K, BK, STAB, X2K0 };$/;"	e	enum:cnn::__anon3	file:
X2K0	cnn/dglstm.cc	/^        X2O, H2O, C2O, BO, X2C, H2C, BC, X2K, C2K, Q2K, BK, STAB, X2K0 };$/;"	e	enum:cnn::__anon3	file:
X2LogVar	ext/encdec/encdec.h	/^enum { X2Mean = 0, X2MeanBias, X2LogVar, X2LogVarBias };$/;"	e	enum:cnn::__anon21
X2LogVarBias	ext/encdec/encdec.h	/^enum { X2Mean = 0, X2MeanBias, X2LogVar, X2LogVarBias };$/;"	e	enum:cnn::__anon21
X2Mean	ext/encdec/encdec.h	/^enum { X2Mean = 0, X2MeanBias, X2LogVar, X2LogVarBias };$/;"	e	enum:cnn::__anon21
X2MeanBias	ext/encdec/encdec.h	/^enum { X2Mean = 0, X2MeanBias, X2LogVar, X2LogVarBias };$/;"	e	enum:cnn::__anon21
X2O	cnn/deep-lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon2	file:
X2O	cnn/dglstm.cc	/^        X2O, H2O, C2O, BO, X2C, H2C, BC, X2K, C2K, Q2K, BK, STAB, X2K0 };$/;"	e	enum:cnn::__anon3	file:
X2O	cnn/lstm.cc	/^enum { X2I, H2I, C2I, BI, X2O, H2O, C2O, BO, X2C, H2C, BC };$/;"	e	enum:cnn::__anon6	file:
X2O	cnn/rnnem.cc	/^    enum { X2I, H2I, C2I, BI, X2F, H2F, C2F, BF, X2O, H2O, C2O, BO, X2C, H2C, BC, WK, WKB, EXTMEM, WG, WA, WV, H2E, BE, WO, OB, WGAMMA, BGAMMA, WGAMMAWTM1, IMPORTB, WOXI, WEXI, BXI, $/;"	e	enum:cnn::__anon7	file:
X2O	cnn/treelstm.cc	/^enum { X2I, C2I, BI, X2F, C2F, BF, X2O, C2O, BO, X2C, BC };$/;"	e	enum:cnn::__anon16	file:
X2R	cnn/gru.cc	/^enum { X2Z, H2Z, BZ, X2R, H2R, BR, X2H, H2H, BH };$/;"	e	enum:cnn::__anon5	file:
X2Z	cnn/gru.cc	/^enum { X2Z, H2Z, BZ, X2R, H2R, BR, X2H, H2H, BH };$/;"	e	enum:cnn::__anon5	file:
Zero	cnn/tensor.cc	/^    void TensorTools::Zero(Tensor& d) {$/;"	f	class:cnn::TensorTools
Zeroes	cnn/nodes.h	/^  explicit Zeroes(const Dim& d) : dim(d) {}$/;"	f	struct:cnn::Zeroes
Zeroes	cnn/nodes.h	/^struct Zeroes : public Node {$/;"	s	namespace:cnn
_APPROXIMATOR_H	cnn/approximator.h	2;"	d
_DNN_H	cnn/dnn.h	2;"	d
_EVAL_PROC_H	ext/trainer/eval_proc.h	2;"	d
_TIMING_H_	cnn/timing.h	2;"	d
_TRAIN_PROC_H	ext/trainer/train_proc.h	2;"	d
_ldaModel_H	ext/lda/lda.h	2;"	d
a	cnn/functors.h	/^    cnn::real a; \/\/\/ scale in the negative input part$/;"	m	struct:cnn::FExponentialLinearUnits
a	cnn/functors.h	/^    cnn::real a; \/\/\/ scale in the negative input part$/;"	m	struct:cnn::FExponentialLinearUnitsBackward
a	cnn/functors.h	/^    const cnn::real a;$/;"	m	struct:cnn::saxpy_functor
a	cnn/functors.h	/^    const cnn::real a;$/;"	m	struct:cnn::scale_functor
abs	cnn/expr-xtra.cc	/^Expression abs(const Expression &expr) $/;"	f
accBinaryExprKernel	cnn/gpu-kernels.h	/^__global__ void accBinaryExprKernel(int n, const cnn::real* x0, const cnn::real* x1, cnn::real* y, Func func) {$/;"	f	namespace:cnn::gpu
accTripletExprKernel	cnn/gpu-kernels.h	/^__global__ void accTripletExprKernel(int n, const cnn::real* x0, const cnn::real* x1, cnn::real *x2, cnn::real* y, Func func) {$/;"	f	namespace:cnn::gpu
accTripletWithOneGlbVariableExprKernel	cnn/gpu-kernels.h	/^__global__ void accTripletWithOneGlbVariableExprKernel(int n, const cnn::real* r, const cnn::real* x, const cnn::real* g, cnn::real *v, cnn::real* y, Func func) {$/;"	f	namespace:cnn::gpu
accUnaryExprKernel	cnn/gpu-kernels.h	/^__global__ void accUnaryExprKernel(int n, const cnn::real* x, cnn::real* y, Func func) {$/;"	f	namespace:cnn::gpu
acc_cls2size	examples/rnnlm2_cls_based.cc	/^  vector<long> acc_cls2size;$/;"	m	struct:RNNLanguageModel	file:
acc_col_size	cnn/nodes.h	/^  mutable std::vector<unsigned> acc_col_size; \/\/\/ accumulated column number of each concatenated columns$/;"	m	struct:cnn::ConcatenateColumns
accumulate_grad	cnn/model.cc	/^void LookupParameters::accumulate_grad(unsigned index, const Tensor& d) {$/;"	f	class:cnn::LookupParameters
accumulate_grad	cnn/model.cc	/^void Parameters::accumulate_grad(const Tensor& d) {$/;"	f	class:cnn::Parameters
accumulate_grad	cnn/param-nodes.cc	/^void LookupNode::accumulate_grad(const Tensor& g) {$/;"	f	class:cnn::LookupNode
accumulate_grad	cnn/param-nodes.cc	/^void ParameterNode::accumulate_grad(const Tensor& g) {$/;"	f	class:cnn::ParameterNode
add_auxiliary_input	cnn/rnn.cc	/^Expression SimpleRNNBuilder::add_auxiliary_input(const Expression &in, const Expression &aux) {$/;"	f	class:cnn::SimpleRNNBuilder
add_auxiliary_input	cnn/rnn.cc	/^Expression SimpleRNNBuilderWithELU::add_auxiliary_input(const Expression &in, const Expression &aux) {$/;"	f	class:cnn::SimpleRNNBuilderWithELU
add_const_lookup	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_const_lookup(LookupParameters* p, const std::vector<unsigned>& indices) {$/;"	f	class:cnn::ComputationGraph
add_const_lookup	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_const_lookup(LookupParameters* p, const std::vector<unsigned>* indices) {$/;"	f	class:cnn::ComputationGraph
add_const_lookup	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_const_lookup(LookupParameters* p, const unsigned* pindex) {$/;"	f	class:cnn::ComputationGraph
add_const_lookup	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_const_lookup(LookupParameters* p, unsigned index) {$/;"	f	class:cnn::ComputationGraph
add_const_parameters	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_const_parameters(Parameters* p) {$/;"	f	class:cnn::ComputationGraph
add_function	cnn/cnn.h	/^inline VariableIndex ComputationGraph::add_function(const T& arguments) {$/;"	f	class:cnn::ComputationGraph
add_function	cnn/cnn.h	/^inline VariableIndex ComputationGraph::add_function(const std::initializer_list<VariableIndex>& arguments) {$/;"	f	class:cnn::ComputationGraph
add_function	cnn/cnn.h	/^inline VariableIndex ComputationGraph::add_function(const std::initializer_list<VariableIndex>& arguments,$/;"	f	class:cnn::ComputationGraph
add_input	cnn/approximator.h	/^        vector<Expression> add_input(const Expression& x, vector<long> targetid) {$/;"	f	class:cnn::ClsBasedBuilder
add_input	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_input(const Dim& d, const vector<cnn::real>& pm) {$/;"	f	class:cnn::ComputationGraph
add_input	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_input(const Dim& d, const vector<cnn::real>* pm) {$/;"	f	class:cnn::ComputationGraph
add_input	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_input(const real* ps) {$/;"	f	class:cnn::ComputationGraph
add_input	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_input(real s) {$/;"	f	class:cnn::ComputationGraph
add_input	cnn/dnn.h	/^        Expression add_input(const Expression& x) {$/;"	f	class:cnn::DNNBuilder
add_input	cnn/rnn-state-machine.h	/^enum RNNOp {new_graph, start_new_sequence, add_input};$/;"	e	enum:cnn::RNNOp
add_input	cnn/rnn.h	/^  Expression add_input(const Expression& x) {$/;"	f	struct:cnn::RNNBuilder
add_input	cnn/rnn.h	/^  Expression add_input(const RNNPointer& prev, const Expression& x) {$/;"	f	struct:cnn::RNNBuilder
add_input	cnn/rnn.h	/^  Expression add_input(const std::vector<Expression>& prv_history, const Expression& x) {$/;"	f	struct:cnn::RNNBuilder
add_input	cnn/rnn.h	/^  Expression add_input(const vector<Expression>& x) {$/;"	f	struct:cnn::RNNBuilder
add_input	cnn/treelstm.cc	/^Expression TreeLSTMBuilder::add_input(vector<int> children, const Expression& x) {$/;"	f	class:cnn::TreeLSTMBuilder
add_input	examples/attentional.h	/^Expression AttentionalModel<Builder>::add_input(int trg_tok, int t, ComputationGraph &cg, RNNPointer *prev_state)$/;"	f	class:cnn::AttentionalModel
add_input	examples/cxtattentional.h	/^Expression CxtAttentionalModel<Builder>::add_input(int trg_tok, ComputationGraph &cg)$/;"	f	class:cnn::CxtAttentionalModel
add_input_impl	cnn/approximator.cc	/^    Expression ClsBasedBuilder::add_input_impl(const Expression &in, long target_wordid, unsigned uttid) {$/;"	f	class:cnn::ClsBasedBuilder
add_input_impl	cnn/deep-lstm.cc	/^Expression DeepLSTMBuilder::add_input_impl(int prev, const Expression& x) {$/;"	f	class:cnn::DeepLSTMBuilder
add_input_impl	cnn/dglstm.cc	/^Expression DGLSTMBuilder::add_input_impl(const std::vector<Expression>& prev_history, const Expression& x) {$/;"	f	class:cnn::DGLSTMBuilder
add_input_impl	cnn/dglstm.cc	/^Expression DGLSTMBuilder::add_input_impl(int prev, const Expression& x) {$/;"	f	class:cnn::DGLSTMBuilder
add_input_impl	cnn/dglstm.cc	/^Expression DGLSTMBuilder::add_input_impl(int prev, const vector<Expression>& x) {$/;"	f	class:cnn::DGLSTMBuilder
add_input_impl	cnn/dnn.cc	/^    Expression DNNBuilder::add_input_impl(const Expression &in) {$/;"	f	class:cnn::DNNBuilder
add_input_impl	cnn/dnn.cc	/^    Expression ReluDNNBuilder::add_input_impl(const Expression &in)  {$/;"	f	class:cnn::ReluDNNBuilder
add_input_impl	cnn/gru.cc	/^Expression GRUBuilder::add_input_impl(const std::vector<Expression> & prev_history, const Expression& x) {$/;"	f	class:cnn::GRUBuilder
add_input_impl	cnn/gru.cc	/^Expression GRUBuilder::add_input_impl(int prev, const Expression& x) {$/;"	f	class:cnn::GRUBuilder
add_input_impl	cnn/gru.cc	/^Expression GRUBuilder::add_input_impl(int prev, const vector<Expression>& x) {$/;"	f	class:cnn::GRUBuilder
add_input_impl	cnn/lstm.cc	/^Expression LSTMBuilder::add_input_impl(const vector<Expression>& prev_history, const Expression &x)$/;"	f	class:cnn::LSTMBuilder
add_input_impl	cnn/lstm.cc	/^Expression LSTMBuilder::add_input_impl(int prev, const Expression& x)$/;"	f	class:cnn::LSTMBuilder
add_input_impl	cnn/lstm.cc	/^Expression LSTMBuilder::add_input_impl(int prev, const vector<Expression>& x)$/;"	f	class:cnn::LSTMBuilder
add_input_impl	cnn/rnn.cc	/^Expression SimpleRNNBuilder::add_input_impl(const vector<Expression>& prev_history, const Expression &in) {$/;"	f	class:cnn::SimpleRNNBuilder
add_input_impl	cnn/rnn.cc	/^Expression SimpleRNNBuilder::add_input_impl(int prev, const Expression &in) {$/;"	f	class:cnn::SimpleRNNBuilder
add_input_impl	cnn/rnn.cc	/^Expression SimpleRNNBuilder::add_input_impl(int prev, const std::vector<Expression> &in) {$/;"	f	class:cnn::SimpleRNNBuilder
add_input_impl	cnn/rnn.cc	/^Expression SimpleRNNBuilderWithELU::add_input_impl(const vector<Expression>& prev_history, const Expression &in) {$/;"	f	class:cnn::SimpleRNNBuilderWithELU
add_input_impl	cnn/rnn.cc	/^Expression SimpleRNNBuilderWithELU::add_input_impl(int prev, const Expression &in) {$/;"	f	class:cnn::SimpleRNNBuilderWithELU
add_input_impl	cnn/rnn.cc	/^Expression SimpleRNNBuilderWithELU::add_input_impl(int prev, const std::vector<Expression> &in) {$/;"	f	class:cnn::SimpleRNNBuilderWithELU
add_input_impl	cnn/rnnem.cc	/^    Expression NMNBuilder::add_input_impl(int prev, const Expression& x) {$/;"	f	class:cnn::NMNBuilder
add_input_impl	cnn/treelstm.cc	/^Expression TreeLSTMBuilder::add_input_impl(int prev, const Expression& x) {$/;"	f	class:cnn::TreeLSTMBuilder
add_lookup	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_lookup(LookupParameters* p, const std::vector<unsigned>& indices) {$/;"	f	class:cnn::ComputationGraph
add_lookup	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_lookup(LookupParameters* p, const std::vector<unsigned>* indices) {$/;"	f	class:cnn::ComputationGraph
add_lookup	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_lookup(LookupParameters* p, const unsigned* pindex) {$/;"	f	class:cnn::ComputationGraph
add_lookup	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_lookup(LookupParameters* p, unsigned index) {$/;"	f	class:cnn::ComputationGraph
add_lookup_parameters	cnn/model.cc	/^LookupParameters* Model::add_lookup_parameters(unsigned n, const Dim& d, cnn::real scale, ::string nodename) {$/;"	f	class:cnn::Model
add_parameters	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_parameters(Parameters* p) {$/;"	f	class:cnn::ComputationGraph
add_parameters	cnn/model.cc	/^Parameters* Model::add_parameters(const Dim& d, cnn::real scale, std::string nodename) {$/;"	f	class:cnn::Model
add_reference	cnn/cnn.cc	/^VariableIndex ComputationGraph::add_reference(const Dim& d, const cnn::real* pm) {$/;"	f	class:cnn::ComputationGraph
add_to_topic	ext/lda/lda.h	/^	inline int add_to_topic(int w, int m, int topic, int old_topic)$/;"	f	class:ldaModel
add_word	cnn/c2w.h	/^  VariableIndex add_word(int word_id, const std::vector<int>& chars, ComputationGraph* cg) {$/;"	f	struct:cnn::C2WBuilder
affine_transform	cnn/expr.h	/^inline Expression affine_transform(const T& xs) { return detail::f<AffineTransform>(xs); }$/;"	f	namespace:cnn::expr
affine_transform	cnn/expr.h	/^inline Expression affine_transform(const std::initializer_list<Expression>& xs) { return detail::f<AffineTransform>(xs); }$/;"	f	namespace:cnn::expr
align_dim	ext/dialogue/dialogue_process.h	/^        size_t align_dim;$/;"	m	class:cnn::AttentionWithIntentionModel
align_dim	ext/dialogue/dialogue_process.h	/^        size_t align_dim;$/;"	m	class:cnn::AttentionalConversation
alignmatrix_to_source	cnn/expr-xtra.cc	/^vector<Expression> alignmatrix_to_source(vector<Expression> & v_src, const vector<unsigned>& v_slen,$/;"	f
aligns	examples/attentional.h	/^    std::vector<Expression> aligns;$/;"	m	struct:cnn::AttentionalModel
all_parameters_list	cnn/model.h	/^    const std::vector<ParametersBase*>& all_parameters_list() const { return all_params; }$/;"	f	class:cnn::Model
all_params	cnn/model.h	/^    std::vector<ParametersBase*> all_params;$/;"	m	class:cnn::Model
allocate	cnn/aligned-mem-pool.h	/^  void* allocate(unsigned long n) {$/;"	f	class:cnn::AlignedMemoryPool
alpha	cnn/nodes.h	/^  cnn::real alpha;$/;"	m	struct:cnn::ConstScalarMultiply
alpha	ext/lda/lda.h	/^	double alpha;					\/\/ per document Topic proportions dirichlet prior$/;"	m	class:ldaModel
apply	examples/convmodel.h	/^        vector<Expression> apply(ComputationGraph& cg, const vector<Expression>& inlayer, int k_out) const {$/;"	f	struct:cnn::ConvLayer
apply	examples/textcat.cc	/^  vector<Expression> apply(ComputationGraph& cg, const vector<Expression>& inlayer, int k_out) const {$/;"	f	struct:ConvLayer
arange	cnn/expr-xtra.cc	/^Expression arange(ComputationGraph &cg, unsigned begin, unsigned end, bool log_transform, std::vector<cnn::real> *aux_mem) $/;"	f
args	cnn/cnn.h	/^  std::vector<VariableIndex> args;$/;"	m	struct:cnn::Node
arity	cnn/cnn.h	/^  inline unsigned arity() const { return args.size(); }$/;"	f	struct:cnn::Node
as_scalar	cnn/tensor.cc	/^    cnn::real as_scalar(const Tensor& t) {$/;"	f	namespace:cnn
as_string	cnn/conv.cc	/^string AddVectorToAllColumns::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::AddVectorToAllColumns
as_string	cnn/conv.cc	/^string Conv1DNarrow::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Conv1DNarrow
as_string	cnn/conv.cc	/^string Conv1DWide::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Conv1DWide
as_string	cnn/conv.cc	/^string FoldRows::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::FoldRows
as_string	cnn/conv.cc	/^string KMaxPooling::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::KMaxPooling
as_string	cnn/nodes-common.cc	/^string AffineTransform::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::AffineTransform
as_string	cnn/nodes-common.cc	/^string Average::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Average
as_string	cnn/nodes-common.cc	/^string BinaryLogLoss::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::BinaryLogLoss
as_string	cnn/nodes-common.cc	/^string BlockDropout::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::BlockDropout
as_string	cnn/nodes-common.cc	/^string ColumnSlices::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::ColumnSlices
as_string	cnn/nodes-common.cc	/^string Concatenate::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Concatenate
as_string	cnn/nodes-common.cc	/^string ConcatenateColumns::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::ConcatenateColumns
as_string	cnn/nodes-common.cc	/^string ConstScalarMultiply::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::ConstScalarMultiply
as_string	cnn/nodes-common.cc	/^string ConstantMinusX::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::ConstantMinusX
as_string	cnn/nodes-common.cc	/^string ConstantPlusX::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::ConstantPlusX
as_string	cnn/nodes-common.cc	/^string Cube::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Cube
as_string	cnn/nodes-common.cc	/^string CwiseMultiply::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::CwiseMultiply
as_string	cnn/nodes-common.cc	/^string CwiseQuotient::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::CwiseQuotient
as_string	cnn/nodes-common.cc	/^string DotProduct::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::DotProduct
as_string	cnn/nodes-common.cc	/^string Dropout::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Dropout
as_string	cnn/nodes-common.cc	/^string Exp::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Exp
as_string	cnn/nodes-common.cc	/^string ExponentialLinearUnits::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::ExponentialLinearUnits
as_string	cnn/nodes-common.cc	/^string GaussianNoise::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::GaussianNoise
as_string	cnn/nodes-common.cc	/^string Hinge::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Hinge
as_string	cnn/nodes-common.cc	/^string HuberDistance::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::HuberDistance
as_string	cnn/nodes-common.cc	/^string Identity::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Identity
as_string	cnn/nodes-common.cc	/^string InnerProduct3D_1D::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::InnerProduct3D_1D
as_string	cnn/nodes-common.cc	/^string KMHNGram::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::KMHNGram
as_string	cnn/nodes-common.cc	/^string L1Distance::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::L1Distance
as_string	cnn/nodes-common.cc	/^string Log::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Log
as_string	cnn/nodes-common.cc	/^string LogSoftmax::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::LogSoftmax
as_string	cnn/nodes-common.cc	/^string LogSumExp::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::LogSumExp
as_string	cnn/nodes-common.cc	/^string LogisticSigmoid::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::LogisticSigmoid
as_string	cnn/nodes-common.cc	/^string MatrixMultiply::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::MatrixMultiply
as_string	cnn/nodes-common.cc	/^string Max::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Max
as_string	cnn/nodes-common.cc	/^string Min::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Min
as_string	cnn/nodes-common.cc	/^string Negate::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Negate
as_string	cnn/nodes-common.cc	/^string PairwiseRankLoss::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::PairwiseRankLoss
as_string	cnn/nodes-common.cc	/^string PickElement::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::PickElement
as_string	cnn/nodes-common.cc	/^string PickRange::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::PickRange
as_string	cnn/nodes-common.cc	/^string PoissonRegressionLoss::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::PoissonRegressionLoss
as_string	cnn/nodes-common.cc	/^string Pow::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Pow
as_string	cnn/nodes-common.cc	/^string Rectify::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Rectify
as_string	cnn/nodes-common.cc	/^string Reduce::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Reduce
as_string	cnn/nodes-common.cc	/^string Reshape::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Reshape
as_string	cnn/nodes-common.cc	/^string RestrictedLogSoftmax::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::RestrictedLogSoftmax
as_string	cnn/nodes-common.cc	/^string SoftSign::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::SoftSign
as_string	cnn/nodes-common.cc	/^string Softmax::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Softmax
as_string	cnn/nodes-common.cc	/^string Sqrt::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Sqrt
as_string	cnn/nodes-common.cc	/^string Square::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Square
as_string	cnn/nodes-common.cc	/^string SquaredEuclideanDistance::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::SquaredEuclideanDistance
as_string	cnn/nodes-common.cc	/^string Sum::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Sum
as_string	cnn/nodes-common.cc	/^string SumBatches::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::SumBatches
as_string	cnn/nodes-common.cc	/^string SumColumns::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::SumColumns
as_string	cnn/nodes-common.cc	/^string Tanh::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Tanh
as_string	cnn/nodes-common.cc	/^string TraceOfProduct::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::TraceOfProduct
as_string	cnn/nodes-common.cc	/^string Transpose::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Transpose
as_string	cnn/nodes.cc	/^string Zeroes::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::Zeroes
as_string	cnn/param-nodes.cc	/^string ConstParameterNode::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::ConstParameterNode
as_string	cnn/param-nodes.cc	/^string InputNode::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::InputNode
as_string	cnn/param-nodes.cc	/^string LookupNode::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::LookupNode
as_string	cnn/param-nodes.cc	/^string ParameterNode::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::ParameterNode
as_string	cnn/param-nodes.cc	/^string ReferenceNode::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::ReferenceNode
as_string	cnn/param-nodes.cc	/^string ScalarInputNode::as_string(const vector<string>& arg_names) const {$/;"	f	class:cnn::ScalarInputNode
as_vector	cnn/tensor.cc	/^    vector<cnn::real> as_vector(const Tensor& v) {$/;"	f	namespace:cnn
as_vector	cnn/tensor.cc	/^    vector<cnn::real> as_vector(int nsize, const cnn::real* v) {$/;"	f	namespace:cnn
assign_cxt	ext/dialogue/attention_with_intention.h	/^    void assign_cxt(ComputationGraph &cg, const vector<vector<int>>&) {$/;"	f	class:cnn::AttentionWithIntention
assign_cxt	ext/dialogue/attention_with_intention.h	/^    void assign_cxt(ComputationGraph &cg,$/;"	f	class:cnn::DynamicMemoryNetDialogue
assign_cxt	ext/dialogue/attention_with_intention.h	/^    void assign_cxt(ComputationGraph& cg, unsigned int nutt)$/;"	f	class:cnn::DynamicMemoryNetDialogue
assign_cxt	ext/dialogue/attention_with_intention.h	/^void AttentionWithIntention<Builder, Decoder>::assign_cxt(ComputationGraph &cg, unsigned int nutt){$/;"	f	class:cnn::AttentionWithIntention
assign_cxt	ext/dialogue/cxtencdec.h	/^    void assign_cxt(ComputationGraph &cg, unsigned int nutt)$/;"	f	class:cnn::CxtEncDecModel
assign_cxt	ext/dialogue/cxtencdec.h	/^    void assign_cxt(ComputationGraph &cg, unsigned int nutt)$/;"	f	class:cnn::Seq2SeqEncDecModel
assign_cxt	ext/dialogue/dialogue.h	/^    void assign_cxt(ComputationGraph &cg, unsigned int nutt)$/;"	f	class:cnn::DialogueBuilder
assign_cxt	ext/dialogue/dialogue.h	/^    void assign_cxt(ComputationGraph &cg, unsigned int nutt,$/;"	f	class:cnn::DialogueBuilder
assign_cxt	ext/dialogue/dialogue.h	/^    void assign_cxt(ComputationGraph &cg,$/;"	f	class:cnn::DialogueBuilder
assign_cxt	ext/dialogue/dialogue_process.h	/^        void assign_cxt(ComputationGraph& cg, size_t nutt)$/;"	f	class:cnn::DialogueProcessInfo
assign_cxt	ext/encdec/encdec.h	/^    virtual void assign_cxt(ComputationGraph &cg, size_t nutt)$/;"	f	class:cnn::EncModel
assign_cxt	ext/encdec/encdec.h	/^    virtual void assign_cxt(ComputationGraph &cg, size_t nutt,$/;"	f	class:cnn::EncModel
assign_cxt	ext/ir/ir.h	/^        void assign_cxt(ComputationGraph &cg, unsigned int nutt)$/;"	f	class:cnn::ClassificationEncoderDecoder
assign_cxt	ext/ir/ir.h	/^        void assign_cxt(ComputationGraph &cg, unsigned int nutt,$/;"	f	class:cnn::ClassificationEncoderDecoder
attention	ext/dialogue/attention_with_intention.h	/^Expression AttentionWithIntention<Builder, Decoder>::attention(int trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::AttentionWithIntention
attention_gate	ext/dialogue/attention_with_intention.h	/^Expression GatedAttention<Builder, Decoder>::attention_gate(Expression i_h_tm1)$/;"	f	class:cnn::GatedAttention
attention_layer	ext/dialogue/attention_with_intention.h	/^    DNNBuilder attention_layer;$/;"	m	class:cnn::AWI_GeneralInputFeeding
attention_layer	ext/dialogue/attention_with_intention.h	/^    DNNBuilder attention_layer;$/;"	m	class:cnn::AWI_LocalGeneralInputFeeding
attention_layer	ext/dialogue/attention_with_intention.h	/^    DNNBuilder attention_layer;$/;"	m	class:cnn::AttMultiSource_LinearEncoder
attention_output_for_this_turn	ext/dialogue/attention_with_intention.h	/^    vector<Expression> attention_output_for_this_turn; \/\/\/ [number of turn]$/;"	m	class:cnn::AWI_GeneralInputFeeding
attention_output_for_this_turn	ext/dialogue/attention_with_intention.h	/^    vector<Expression> attention_output_for_this_turn; \/\/\/ [number of turn]$/;"	m	class:cnn::AWI_LocalGeneralInputFeeding
attention_output_for_this_turn	ext/dialogue/attention_with_intention.h	/^    vector<Expression> attention_output_for_this_turn; \/\/\/ [number of turn]$/;"	m	class:cnn::AttMultiSource_LinearEncoder
attention_to_key_and_retreive_value	cnn/expr-xtra.cc	/^vector<Expression> attention_to_key_and_retreive_value(const Expression& M_t, const vector<unsigned>& v_slen,$/;"	f
attention_to_source	cnn/expr-xtra.cc	/^vector<Expression> attention_to_source(vector<Expression> & v_src, const vector<unsigned>& v_slen,$/;"	f
attention_to_source_batch	cnn/expr-xtra.cc	/^vector<Expression> attention_to_source_batch(vector<Expression> & v_src, const vector<unsigned>& v_slen,$/;"	f
attention_to_source_bilinear	cnn/expr-xtra.cc	/^vector<Expression> attention_to_source_bilinear(vector<Expression> & v_src, const vector<unsigned>& v_slen,$/;"	f
attention_to_source_using_nn	ext/dialogue/attention_with_intention.h	/^    vector<Expression> attention_to_source_using_nn(vector<Expression> & v_src, const vector<unsigned>& v_slen, $/;"	f	class:cnn::AWI_InputFeedingWithNNAttention
attention_using_bilinear	cnn/expr-xtra.cc	/^vector<Expression> attention_using_bilinear(vector<Expression> & v_src, const vector<unsigned>& v_slen,$/;"	f
attention_using_bilinear_with_local_attention	cnn/expr-xtra.cc	/^vector<Expression> attention_using_bilinear_with_local_attention(vector<Expression> & v_src, const vector<unsigned>& v_slen,$/;"	f
attention_weight	cnn/expr-xtra.cc	/^vector<Expression> attention_weight(const vector<unsigned>& v_slen, const Expression& src_key, Expression i_va, Expression i_Wa,$/;"	f
aux_mem	cnn/cnn.h	/^  mutable void* aux_mem; \/\/ this will usually be null. but, if your node needs to store intermediate values$/;"	m	struct:cnn::Node
aux_storage_size	cnn/cnn.cc	/^size_t Node::aux_storage_size() const { return 0; }$/;"	f	class:cnn::Node
aux_storage_size	cnn/conv.cc	/^size_t KMaxPooling::aux_storage_size() const {$/;"	f	class:cnn::KMaxPooling
aux_storage_size	cnn/nodes.cc	/^size_t Average::aux_storage_size() const {$/;"	f	class:cnn::Average
aux_storage_size	cnn/nodes.cc	/^size_t BlockDropout::aux_storage_size() const {$/;"	f	class:cnn::BlockDropout
aux_storage_size	cnn/nodes.cc	/^size_t Dropout::aux_storage_size() const {$/;"	f	class:cnn::Dropout
aux_storage_size	cnn/nodes.cc	/^size_t GaussianNoise::aux_storage_size() const {$/;"	f	class:cnn::GaussianNoise
aux_storage_size	cnn/nodes.cc	/^size_t Hinge::aux_storage_size() const {$/;"	f	class:cnn::Hinge
aux_storage_size	cnn/nodes.cc	/^size_t LogSoftmax::aux_storage_size() const {$/;"	f	class:cnn::LogSoftmax
aux_storage_size	cnn/nodes.cc	/^size_t LogSumExp::aux_storage_size() const {$/;"	f	class:cnn::LogSumExp
aux_storage_size	cnn/nodes.cc	/^size_t Max::aux_storage_size() const {$/;"	f	class:cnn::Max
aux_storage_size	cnn/nodes.cc	/^size_t Min::aux_storage_size() const {$/;"	f	class:cnn::Min
aux_vecs	examples/attentional.h	/^    std::vector<std::vector<cnn::real>*> aux_vecs; \/\/ special storage for constant vectors$/;"	m	struct:cnn::AttentionalModel
auxiliary_vector	examples/attentional.h	/^std::vector<cnn::real>* AttentionalModel<Builder>::auxiliary_vector()$/;"	f	class:cnn::AttentionalModel
auxiliary_vector	examples/cxtattentional.h	/^std::vector<cnn::real>* CxtAttentionalModel<Builder>::auxiliary_vector()$/;"	f	class:cnn::CxtAttentionalModel
average	cnn/expr.h	/^inline Expression average(const T& xs) { return detail::f<Average>(xs); }$/;"	f	namespace:cnn::expr
average	cnn/expr.h	/^inline Expression average(const std::initializer_list<Expression>& xs) { return detail::f<Average>(xs); }$/;"	f	namespace:cnn::expr
average_embedding	cnn/expr-xtra.cc	/^vector<Expression> average_embedding(const vector<unsigned>& slen, int featdim, const vector<Expression>& vsrc)$/;"	f
average_embedding	cnn/expr-xtra.cc	/^vector<Expression> average_embedding(unsigned & slen, const vector<vector<int>>& source, ComputationGraph& cg, LookupParameters* p_cs)$/;"	f
b	examples/mp.cc	/^  Parameters* b;$/;"	m	struct:ModelParameters	file:
b	examples/mp.cc	/^  cnn::real b;$/;"	m	struct:SharedObject	file:
back	cnn/approximator.h	/^        vector<Expression> back() const { return errors.back(); }$/;"	f	class:cnn::ClsBasedBuilder
back	cnn/deep-lstm.h	/^  Expression back() const { return h.back().back(); }$/;"	f	struct:cnn::DeepLSTMBuilder
back	cnn/dglstm.h	/^  Expression back() const { return h.back().back(); }$/;"	f	struct:cnn::DGLSTMBuilder
back	cnn/dnn.h	/^        Expression back() const { return h.back(); }$/;"	f	class:cnn::DNNBuilder
back	cnn/gru.h	/^  Expression back() const { return h.back().back(); }$/;"	f	struct:cnn::GRUBuilder
back	cnn/lstm.h	/^  Expression back() const { return h.back().back(); }$/;"	f	struct:cnn::LSTMBuilder
back	cnn/rnn.h	/^  Expression back() const { return h.back().back(); }$/;"	f	struct:cnn::SimpleRNNBuilder
back	cnn/rnnem.h	/^  Expression back() const { return h.back().back(); }$/;"	f	struct:cnn::NMNBuilder
back	cnn/treelstm.h	/^  Expression back() const { return h.back().back(); }$/;"	f	struct:cnn::TreeLSTMBuilder
backward	cnn/cnn.cc	/^void ComputationGraph::backward(VariableIndex i) { ee->backward(i); }$/;"	f	class:cnn::ComputationGraph
backward	cnn/cnn.cc	/^void ComputationGraph::backward(cnn::real * kInitError){ ee->backward(kInitError); }$/;"	f	class:cnn::ComputationGraph
backward	cnn/cnn.cc	/^void Node::backward(const std::vector<const Tensor*>& xs,$/;"	f	class:cnn::Node
backward	cnn/exec.cc	/^void SimpleExecutionEngine::backward(VariableIndex from_where, cnn::real * kScalarInit) {$/;"	f	class:cnn::SimpleExecutionEngine
backward	cnn/exec.cc	/^void SimpleExecutionEngine::backward(cnn::real * kScalarInit) {$/;"	f	class:cnn::SimpleExecutionEngine
backward_directional	cnn/expr-xtra.h	/^vector<Expression> backward_directional(const vector<Expression>& source, ComputationGraph& cg, LookupParameters* p_cs, Builder& encoder_bwd)$/;"	f
backward_directional	cnn/expr-xtra.h	/^vector<Expression> backward_directional(unsigned & slen, const vector<vector<int>>& source, ComputationGraph& cg, LookupParameters* p_cs, vector<cnn::real>& zero,$/;"	f
backward_impl	cnn/conv.cc	/^void AddVectorToAllColumns::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::AddVectorToAllColumns
backward_impl	cnn/conv.cc	/^void Conv1DNarrow::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Conv1DNarrow
backward_impl	cnn/conv.cc	/^void Conv1DWide::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Conv1DWide
backward_impl	cnn/conv.cc	/^void FoldRows::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::FoldRows
backward_impl	cnn/conv.cc	/^void KMaxPooling::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::KMaxPooling
backward_impl	cnn/nodes.cc	/^void AffineTransform::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::AffineTransform
backward_impl	cnn/nodes.cc	/^void Average::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Average
backward_impl	cnn/nodes.cc	/^void BinaryLogLoss::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::BinaryLogLoss
backward_impl	cnn/nodes.cc	/^void BlockDropout::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::BlockDropout
backward_impl	cnn/nodes.cc	/^void ColumnSlices::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::ColumnSlices
backward_impl	cnn/nodes.cc	/^void Concatenate::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Concatenate
backward_impl	cnn/nodes.cc	/^void ConcatenateColumns::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::ConcatenateColumns
backward_impl	cnn/nodes.cc	/^void ConstScalarMultiply::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::ConstScalarMultiply
backward_impl	cnn/nodes.cc	/^void ConstantMinusX::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::ConstantMinusX
backward_impl	cnn/nodes.cc	/^void ConstantPlusX::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::ConstantPlusX
backward_impl	cnn/nodes.cc	/^void Cube::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Cube
backward_impl	cnn/nodes.cc	/^void CwiseMultiply::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::CwiseMultiply
backward_impl	cnn/nodes.cc	/^void CwiseQuotient::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::CwiseQuotient
backward_impl	cnn/nodes.cc	/^void DotProduct::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::DotProduct
backward_impl	cnn/nodes.cc	/^void Dropout::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Dropout
backward_impl	cnn/nodes.cc	/^void Exp::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Exp
backward_impl	cnn/nodes.cc	/^void ExponentialLinearUnits::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::ExponentialLinearUnits
backward_impl	cnn/nodes.cc	/^void GaussianNoise::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::GaussianNoise
backward_impl	cnn/nodes.cc	/^void Hinge::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Hinge
backward_impl	cnn/nodes.cc	/^void HuberDistance::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::HuberDistance
backward_impl	cnn/nodes.cc	/^void Identity::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Identity
backward_impl	cnn/nodes.cc	/^void InnerProduct3D_1D::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::InnerProduct3D_1D
backward_impl	cnn/nodes.cc	/^void KMHNGram::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::KMHNGram
backward_impl	cnn/nodes.cc	/^void L1Distance::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::L1Distance
backward_impl	cnn/nodes.cc	/^void Log::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Log
backward_impl	cnn/nodes.cc	/^void LogSoftmax::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::LogSoftmax
backward_impl	cnn/nodes.cc	/^void LogSumExp::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::LogSumExp
backward_impl	cnn/nodes.cc	/^void LogisticSigmoid::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::LogisticSigmoid
backward_impl	cnn/nodes.cc	/^void MatrixMultiply::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::MatrixMultiply
backward_impl	cnn/nodes.cc	/^void Max::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Max
backward_impl	cnn/nodes.cc	/^void MaxPooling1D::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::MaxPooling1D
backward_impl	cnn/nodes.cc	/^void Min::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Min
backward_impl	cnn/nodes.cc	/^void Negate::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Negate
backward_impl	cnn/nodes.cc	/^void PairwiseRankLoss::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::PairwiseRankLoss
backward_impl	cnn/nodes.cc	/^void PickElement::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::PickElement
backward_impl	cnn/nodes.cc	/^void PickRange::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::PickRange
backward_impl	cnn/nodes.cc	/^void PoissonRegressionLoss::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::PoissonRegressionLoss
backward_impl	cnn/nodes.cc	/^void Pow::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Pow
backward_impl	cnn/nodes.cc	/^void Rectify::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Rectify
backward_impl	cnn/nodes.cc	/^void Reduce::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Reduce
backward_impl	cnn/nodes.cc	/^void Reshape::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Reshape
backward_impl	cnn/nodes.cc	/^void RestrictedLogSoftmax::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::RestrictedLogSoftmax
backward_impl	cnn/nodes.cc	/^void SoftSign::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::SoftSign
backward_impl	cnn/nodes.cc	/^void Softmax::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Softmax
backward_impl	cnn/nodes.cc	/^void Sqrt::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Sqrt
backward_impl	cnn/nodes.cc	/^void Square::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Square
backward_impl	cnn/nodes.cc	/^void SquaredEuclideanDistance::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::SquaredEuclideanDistance
backward_impl	cnn/nodes.cc	/^void Sum::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Sum
backward_impl	cnn/nodes.cc	/^void SumBatches::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::SumBatches
backward_impl	cnn/nodes.cc	/^void SumColumns::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::SumColumns
backward_impl	cnn/nodes.cc	/^void Tanh::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Tanh
backward_impl	cnn/nodes.cc	/^void TraceOfProduct::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::TraceOfProduct
backward_impl	cnn/nodes.cc	/^void Transpose::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Transpose
backward_impl	cnn/nodes.cc	/^void Zeroes::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::Zeroes
backward_impl	cnn/param-nodes.cc	/^void ConstParameterNode::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::ConstParameterNode
backward_impl	cnn/param-nodes.cc	/^void InputNode::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::InputNode
backward_impl	cnn/param-nodes.cc	/^void LookupNode::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::LookupNode
backward_impl	cnn/param-nodes.cc	/^void ParameterNode::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::ParameterNode
backward_impl	cnn/param-nodes.cc	/^void ReferenceNode::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::ReferenceNode
backward_impl	cnn/param-nodes.cc	/^void ScalarInputNode::backward_impl(const vector<const Tensor*>& xs,$/;"	f	class:cnn::ScalarInputNode
batch_decode	ext/dialogue/attention_with_intention.h	/^    std::vector<Sentence> batch_decode(const vector<Sentence>&source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::DynamicMemoryNetDialogue
batch_decode	ext/dialogue/dialogue.h	/^    std::vector<Sentence> batch_decode(const std::vector<Sentence> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::DialogueBuilder
batch_decode	ext/dialogue/dialogue_process.h	/^        vector<Sentence> batch_decode(const vector<Sentence>& prv_sentence, const vector<Sentence>& cur_sentence, ComputationGraph& cg, cnn::Dict& tdict)$/;"	f	class:cnn::DialogueSeq2SeqModel
batch_decode	ext/dialogue/dialogue_process.h	/^        vector<Sentence>batch_decode(const vector<Sentence>& cur_sentence, ComputationGraph& cg, cnn::Dict & tdict)$/;"	f	class:cnn::DialogueSeq2SeqModel
batch_decode	ext/dialogue/dialogue_process.h	/^        virtual vector<Sentence> batch_decode(const vector<Sentence>& prv_sentence, const vector<Sentence>& cur_sentence, ComputationGraph& cg, cnn::Dict& tdict)$/;"	f	class:cnn::DialogueProcessInfo
batch_decode	ext/dialogue/dialogue_process.h	/^        virtual vector<Sentence>batch_decode(const vector<Sentence>& cur_sentence, ComputationGraph& cg, cnn::Dict & tdict)$/;"	f	class:cnn::DialogueProcessInfo
batch_elem	cnn/tensor.h	/^  Tensor batch_elem(unsigned b) const {$/;"	f	struct:cnn::Tensor
batch_elems	cnn/dim.h	/^  inline unsigned int batch_elems() const { return bd; }$/;"	f	struct:cnn::Dim
batch_elems	cnn/tensor.h	/^  std::vector<Tensor> batch_elems() const {$/;"	f	struct:cnn::Tensor
batch_matrix	cnn/tensor.h	/^  Eigen::Map<EMatrix, Eigen::Unaligned> batch_matrix(unsigned bid) {$/;"	f	struct:cnn::Tensor
batch_matrix	cnn/tensor.h	/^  const Eigen::Map<EMatrix, Eigen::Unaligned> batch_matrix(unsigned bid) const {$/;"	f	struct:cnn::Tensor
batch_ptr	cnn/tensor.h	/^  cnn::real* batch_ptr(unsigned bid) {$/;"	f	struct:cnn::Tensor
batch_ptr	cnn/tensor.h	/^  const cnn::real* batch_ptr(unsigned bid) const {$/;"	f	struct:cnn::Tensor
batch_size	cnn/dim.h	/^  inline unsigned int batch_size() const {$/;"	f	struct:cnn::Dim
batch_train	ext/trainer/train_proc.h	/^void ClassificationTrainProcess<AM_t>::batch_train(Model &model, AM_t &am, Corpus &training, Corpus &devel,$/;"	f	class:ClassificationTrainProcess
batch_train	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::batch_train(Model &model, AM_t &am, Corpus &training, Corpus &devel,$/;"	f	class:TrainProcess
bd	cnn/dim.h	/^  unsigned int bd;$/;"	m	struct:cnn::Dim
beam_decode	examples/attentional.h	/^AttentionalModel<Builder>::beam_decode(const std::vector<int> &source, ComputationGraph& cg, int beam_width, $/;"	f	class:cnn::AttentionalModel
beam_decode	examples/cxtattentional.h	/^CxtAttentionalModel<Builder>::beam_decode(const std::vector<int> &source, ComputationGraph& cg, int beam_width, $/;"	f	class:cnn::CxtAttentionalModel
beam_decode	ext/dialogue/attention_with_intention.h	/^std::vector<int> AttentionWithIntention<Builder, Decoder>::beam_decode(const std::vector<int> &source, ComputationGraph& cg, int beam_width,$/;"	f	class:cnn::AttentionWithIntention
beam_search_decode	examples/attentional.cc	/^int beam_search_decode = -1; \/\/\/ -1 is the beam width$/;"	v
beam_search_decode	ext/trainer/train_proc.h	/^int beam_search_decode;$/;"	v
beta	ext/lda/lda.h	/^	double beta, Vbeta;				\/\/ Dirichlet language ldaModel$/;"	m	class:ldaModel
beta_1	cnn/training.h	/^  cnn::real beta_1;$/;"	m	struct:cnn::AdamTrainer
beta_2	cnn/training.h	/^  cnn::real beta_2;$/;"	m	struct:cnn::AdamTrainer
biases	cnn/dglstm.h	/^  std::vector<std::vector<Expression>> biases;$/;"	m	struct:cnn::DGLSTMBuilder
biases	cnn/dnn.h	/^        std::vector<std::vector<Expression>> biases;$/;"	m	class:cnn::DNNBuilder
biases	cnn/gru.h	/^  std::vector<std::vector<Expression>> biases;$/;"	m	struct:cnn::GRUBuilder
biases	cnn/lstm.h	/^  std::vector<std::vector<Expression>> biases;$/;"	m	struct:cnn::LSTMBuilder
biases	cnn/rnn.h	/^  std::vector<std::vector<Expression>> biases;$/;"	m	struct:cnn::SimpleRNNBuilder
bicnt	ext/ngram/ngram.h	/^    tBiCount  bicnt;$/;"	m	class:nGram
bidirectional	cnn/expr-xtra.cc	/^Expression bidirectional(int slen, const vector<vector<cnn::real>>& source, ComputationGraph& cg, std::vector<Expression>& src_fwd, std::vector<Expression>& src_bwd)$/;"	f
bidirectional	cnn/expr-xtra.h	/^Expression bidirectional(const vector<Expression>& source, ComputationGraph& cg, LookupParameters* p_cs, Builder & encoder_fwd, Builder &encoder_bwd)$/;"	f
bidirectional	cnn/expr-xtra.h	/^Expression bidirectional(unsigned & slen, const vector<int>& source, ComputationGraph& cg, LookupParameters* p_cs, Builder & encoder_fwd, Builder &encoder_bwd)$/;"	f
bidirectional	cnn/expr-xtra.h	/^Expression bidirectional(unsigned & slen, const vector<vector<int>>& source, ComputationGraph& cg, LookupParameters* p_cs, vector<cnn::real>& zero, Builder * encoder_fwd, Builder* encoder_bwd, unsigned int feat_dim)$/;"	f
bidirectional	cnn/expr-xtra.h	/^Expression bidirectional(unsigned & slen, const vector<vector<int>>& source, ComputationGraph& cg, LookupParameters* p_cs, vector<cnn::real>& zero,$/;"	f
binaryExprKernel	cnn/gpu-kernels.h	/^__global__ void binaryExprKernel(int n, const cnn::real* x0, const cnn::real* x1, cnn::real* y, Func func) {$/;"	f	namespace:cnn::gpu
binary_log_loss	cnn/expr.cc	/^Expression binary_log_loss(const Expression& x, const Expression& y) { return Expression(x.pg, x.pg->add_function<BinaryLogLoss>({x.i,y.i})); }$/;"	f	namespace:cnn::expr
block_dropout	cnn/expr.cc	/^Expression block_dropout(const Expression& x, cnn::real p) { return Expression(x.pg, x.pg->add_function<BlockDropout>({x.i}, p)); }$/;"	f	namespace:cnn::expr
boost	cnn/dim.h	/^namespace boost { namespace serialization { class access; } }$/;"	n
bs	cnn/tensor.h	/^  std::vector<Tensor> bs;$/;"	m	struct:cnn::Tensor
build_comp_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_comp_graph(const std::vector<std::vector<int>> &source,$/;"	f	class:cnn::DynamicMemoryNetDialogue
build_comp_graph	ext/dialogue/dialogue.h	/^     vector<Expression> build_comp_graph(const std::vector<std::vector<int>> &source,$/;"	f	class:cnn::DialogueBuilder
build_graph	examples/cxtattentional.h	/^Expression CxtAttentionalModel<Builder>::build_graph(const std::vector<int> &source, const std::vector<int>& osent, ComputationGraph &cg)$/;"	f	class:cnn::CxtAttentionalModel
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph($/;"	f	class:cnn::ClsBasedMultiSource_LinearEncoder
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph($/;"	f	class:cnn::MultiSource_LinearEncoder
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &current_user_input,$/;"	f	class:cnn::AttMultiSource_LinearEncoder
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &current_user_input,$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &current_user_input,$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &current_user_input,$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::AttMultiSource_LinearEncoder
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::ClsBasedMultiSource_LinearEncoder
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::MultiSource_LinearEncoder
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &source, const std::vector<std::vector<int>>& osent, ComputationGraph &cg)$/;"	f	class:cnn::AWI
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &source, const std::vector<std::vector<int>>& osent, ComputationGraph &cg)$/;"	f	class:cnn::AWI_Bilinear_Simpler_AE
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &source, const std::vector<std::vector<int>>& osent, ComputationGraph &cg)$/;"	f	class:cnn::AWI_GeneralInputFeeding
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &source, const std::vector<std::vector<int>>& osent, ComputationGraph &cg)$/;"	f	class:cnn::AWI_LocalGeneralInputFeeding
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &source, const std::vector<std::vector<int>>& osent, ComputationGraph &cg)$/;"	f	class:cnn::DynamicMemoryNetDialogue
build_graph	ext/dialogue/attention_with_intention.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &source, const std::vector<std::vector<int>>& osent, ComputationGraph &cg){$/;"	f	class:cnn::AttentionWithIntention
build_graph	ext/dialogue/attention_with_intention.h	/^Expression AttentionWithIntention<Builder, Decoder>::build_graph(const std::vector<int> &source, const std::vector<int>& osent, ComputationGraph &cg)$/;"	f	class:cnn::AttentionWithIntention
build_graph	ext/dialogue/cxtencdec.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &source, const std::vector<std::vector<int>>& osent, ComputationGraph &cg){$/;"	f	class:cnn::CxtEncDecModel
build_graph	ext/dialogue/cxtencdec.h	/^    vector<Expression> build_graph(const std::vector<std::vector<int>> &source, const std::vector<std::vector<int>>& osent, ComputationGraph &cg){$/;"	f	class:cnn::Seq2SeqEncDecModel
build_graph	ext/dialogue/dialogue.h	/^     vector<Expression> build_graph(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::DialogueBuilder
build_graph	ext/dialogue/dialogue.h	/^     vector<Expression> build_graph(const std::vector<std::vector<int>> &source, const std::vector<std::vector<int>>& osent, ComputationGraph &cg){$/;"	f	class:cnn::DialogueBuilder
build_graph	ext/dialogue/dialogue_process.h	/^        Expression build_graph(const TupleDialogue & prv_sentence, const TupleDialogue & cur_sentence, ComputationGraph& cg)$/;"	f	class:cnn::ClassificationBasedMultiSourceDialogue
build_graph	ext/dialogue/dialogue_process.h	/^        Expression build_graph(const TupleDialogue & prv_sentence, const TupleDialogue & cur_sentence, ComputationGraph& cg)$/;"	f	class:cnn::MultiSourceDialogue
build_graph	ext/encdec/encdec.h	/^    std::vector<Expression> build_graph(const std::vector<std::vector<int>> &source, ComputationGraph &cg)$/;"	f	class:cnn::EncModel
build_graph	ext/encdec/encdec.h	/^    std::vector<Expression> build_graph(const std::vector<std::vector<int>> &source1, const std::vector<std::vector<int>> &source2, ComputationGraph &cg){$/;"	f	class:cnn::EncModel
build_graph	ext/ir/ir.h	/^        vector<Expression> build_graph($/;"	f	class:cnn::ClassificationEncoderDecoder
build_graph	ext/ir/ir.h	/^        vector<Expression> build_graph(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::ClassificationEncoderDecoder
builder	examples/attentional.h	/^    Builder builder;$/;"	m	struct:cnn::AttentionalModel
builder	examples/poisson-regression.cc	/^  Builder builder;$/;"	m	struct:RNNLengthPredictor	file:
builder	examples/regattentional.h	/^    Builder builder;$/;"	m	struct:cnn::RegAttentionalModel
builder	examples/rnnlm.cc	/^  Builder builder;$/;"	m	struct:RNNLanguageModel	file:
builder	examples/rnnlm2.cc	/^  Builder builder;$/;"	m	struct:RNNLanguageModel	file:
builder	examples/rnnlm2_cls_based.cc	/^  Builder builder;$/;"	m	struct:RNNLanguageModel	file:
builder	examples/skiprnnlm.cc	/^    SimpleRNNBuilder builder;$/;"	m	struct:RNNSkipLM	file:
builder_flavour	cnn/data-util.cc	/^string builder_flavour(variables_map vm)$/;"	f
builder_src_bwd	examples/attentional.h	/^    Builder builder_src_bwd;$/;"	m	struct:cnn::AttentionalModel
builder_src_bwd	examples/regattentional.h	/^    Builder builder_src_bwd;$/;"	m	struct:cnn::RegAttentionalModel
builder_src_fwd	examples/attentional.h	/^    Builder builder_src_fwd;$/;"	m	struct:cnn::AttentionalModel
builder_src_fwd	examples/regattentional.h	/^    Builder builder_src_fwd;$/;"	m	struct:cnn::RegAttentionalModel
builder_state	cnn/decode.h	/^    RNNPointer builder_state;$/;"	m	struct:cnn::Hypothesis
builder_state	examples/attentional.h	/^    RNNPointer builder_state;$/;"	m	struct:cnn::Hypothesis
builder_state	examples/cxtattentional.h	/^    RNNPointer builder_state;$/;"	m	struct:cnn::Hypothesis
c	cnn/deep-lstm.h	/^  std::vector<std::vector<Expression>> h, c;$/;"	m	struct:cnn::DeepLSTMBuilder
c	cnn/dglstm.h	/^  std::vector<std::vector<Expression>> h, c;$/;"	m	struct:cnn::DGLSTMBuilder
c	cnn/functors.h	/^    cnn::real c;$/;"	m	struct:cnn::FConstantMultiply
c	cnn/functors.h	/^    const cnn::real c;$/;"	m	struct:cnn::FHuberForward
c	cnn/functors.h	/^  cnn::real c;$/;"	m	struct:cnn::FConstantMinus
c	cnn/functors.h	/^  cnn::real c;$/;"	m	struct:cnn::FConstantPlus
c	cnn/functors.h	/^  const cnn::real c;$/;"	m	struct:cnn::FHuberBackward
c	cnn/lstm.h	/^  std::vector<std::vector<Expression>> h, c;$/;"	m	struct:cnn::LSTMBuilder
c	cnn/nodes.h	/^  cnn::real c;$/;"	m	struct:cnn::ConstantMinusX
c	cnn/nodes.h	/^  cnn::real c;$/;"	m	struct:cnn::ConstantPlusX
c	cnn/rnnem.h	/^  std::vector<std::vector<Expression>> h, c, w;$/;"	m	struct:cnn::NMNBuilder
c	cnn/simd-functors.h	/^  Scalar c;$/;"	m	struct:cnn::const_add_op
c	cnn/simd-functors.h	/^  Scalar c;$/;"	m	struct:cnn::const_minus_op
c	cnn/treelstm.h	/^  std::vector<std::vector<Expression>> h, c;$/;"	m	struct:cnn::TreeLSTMBuilder
c0	cnn/deep-lstm.h	/^  std::vector<Expression> c0;$/;"	m	struct:cnn::DeepLSTMBuilder
c0	cnn/dglstm.h	/^  std::vector<Expression> c0;$/;"	m	struct:cnn::DGLSTMBuilder
c0	cnn/lstm.h	/^  std::vector<Expression> c0;$/;"	m	struct:cnn::LSTMBuilder
c0	cnn/rnnem.h	/^  std::vector<Expression> w0, h0, c0, M0;$/;"	m	struct:cnn::NMNBuilder
c0	cnn/treelstm.h	/^  std::vector<Expression> c0;$/;"	m	struct:cnn::TreeLSTMBuilder
c2p	examples/mp.cc	/^  int c2p[2]; \/\/ Child to parent pipe$/;"	m	struct:Workload	file:
capacity	cnn/aligned-mem-pool.h	/^  unsigned long capacity;$/;"	m	class:cnn::AlignedMemoryPool
cast_uint32_t	cnn/functors.h	26;"	d
cdiv	cnn/expr.cc	/^Expression cdiv(const Expression& x, const Expression& y) { return Expression(x.pg, x.pg->add_function<CwiseQuotient>({x.i, y.i})); }$/;"	f	namespace:cnn::expr
cg	cnn/exec.h	/^  const ComputationGraph& cg;$/;"	m	class:cnn::ExecutionEngine
check_info_correct	examples/rnnlm2_cls_based.cc	/^bool check_info_correct(Dict& sd, const std::vector<long>& wrd2cls, const std::vector<long>& dict_wrd_id2within_class_id, const std::vector<int> & cls2size, const std::vector<long>& acc_cls2size)$/;"	f
check_value	cnn/data-util.cc	/^void check_value(int n, const cnn::real* val, string str)$/;"	f
cl1	examples/convmodel.h	/^        TConvLayer cl1;$/;"	m	struct:cnn::ConvNet
cl1	examples/textcat.cc	/^  ConvLayer cl1;$/;"	m	struct:ConvNet	file:
cl2	examples/convmodel.h	/^        TConvLayer cl2;$/;"	m	struct:cnn::ConvNet
cl2	examples/textcat.cc	/^  ConvLayer cl2;$/;"	m	struct:ConvNet	file:
classification_main_body	ext/trainer/train_proc_wrapper.h	/^int classification_main_body(variables_map vm, size_t nreplicate = 0, size_t decoder_additiona_input_to = 0)$/;"	f
clear	cnn/cnn.cc	/^void ComputationGraph::clear() {$/;"	f	class:cnn::ComputationGraph
clear	cnn/model.cc	/^void LookupParameters::clear() {$/;"	f	class:cnn::LookupParameters
clear	cnn/model.cc	/^void Parameters::clear() {$/;"	f	class:cnn::Parameters
clear	ext/dialogue/dialogue_process.h	/^        void clear()$/;"	f	class:cnn::AttentionWithIntentionModel
clear	ext/dialogue/dialogue_process.h	/^        void clear()$/;"	f	class:cnn::AttentionalConversation
clear_candidates	ext/dialogue/dialogue_process.h	/^        void clear_candidates()$/;"	f	class:cnn::DialogueProcessInfo
clip_gradients	cnn/training.cc	/^cnn::real Trainer::clip_gradients(cnn::real samples) {$/;"	f	class:cnn::Trainer
clip_gradients	cnn/training.cc	/^cnn::real Trainer::clip_gradients(cnn::real samples, cnn::real pre_compued_grd_norm) {$/;"	f	class:cnn::Trainer
clip_threshold	cnn/training.h	/^  cnn::real clip_threshold;$/;"	m	struct:cnn::Trainer
clipping_enabled	cnn/training.h	/^  cnn::real clipping_enabled;$/;"	m	struct:cnn::Trainer
clips	cnn/training.h	/^  cnn::real clips;$/;"	m	struct:cnn::Trainer
closest_class_id	ext/trainer/train_proc.h	/^int TrainProcess<AM_t>::closest_class_id(vector<nGram>& pnGram, int this_cls, int nclsInEachCluster , const Sentence& obs,$/;"	f	class:TrainProcess
cls_size	ext/ir/ir.h	/^        int cls_size; \/\/\/ number of classes for output$/;"	m	class:cnn::ClassificationEncoderDecoder
clssize	cnn/approximator.h	/^        vector<int> clssize;$/;"	m	class:cnn::ClsBasedBuilder
clssize	examples/rnnlm2_cls_based.cc	/^  vector<int> clssize;$/;"	m	struct:RNNLanguageModel	file:
clustering_main_body	ext/trainer/train_proc_wrapper.h	/^int clustering_main_body(variables_map vm)$/;"	f
cmdOptionExists	cnn/init.cc	/^    bool cmdOptionExists(char** begin, char** end, const std::string& option)$/;"	f	namespace:cnn
cnn	cnn/aligned-mem-pool.h	/^namespace cnn {$/;"	n
cnn	cnn/approximator.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/approximator.h	/^namespace cnn {$/;"	n
cnn	cnn/c2w.h	/^namespace cnn {$/;"	n
cnn	cnn/cnn-helper.h	/^namespace cnn {$/;"	n
cnn	cnn/cnn.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/cnn.h	/^namespace cnn {$/;"	n
cnn	cnn/conv.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/conv.h	/^namespace cnn {$/;"	n
cnn	cnn/cuda.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/cuda.h	/^namespace cnn {$/;"	n
cnn	cnn/decode.h	/^namespace cnn {$/;"	n
cnn	cnn/deep-lstm.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/deep-lstm.h	/^namespace cnn {$/;"	n
cnn	cnn/dglstm.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/dglstm.h	/^namespace cnn {$/;"	n
cnn	cnn/dict.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/dict.h	/^namespace cnn {$/;"	n
cnn	cnn/dim.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/dim.h	/^namespace cnn {$/;"	n
cnn	cnn/dnn.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/dnn.h	/^namespace cnn {$/;"	n
cnn	cnn/except.h	/^namespace cnn {$/;"	n
cnn	cnn/exec.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/exec.h	/^namespace cnn {$/;"	n
cnn	cnn/expr.cc	/^namespace cnn { namespace expr {$/;"	n	file:
cnn	cnn/expr.h	/^namespace cnn { namespace expr {$/;"	n
cnn	cnn/functors.h	/^namespace cnn {$/;"	n
cnn	cnn/gpu-kernels.h	/^namespace cnn {$/;"	n
cnn	cnn/gpu-ops.h	/^namespace cnn {$/;"	n
cnn	cnn/grad-check.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/grad-check.h	/^namespace cnn {$/;"	n
cnn	cnn/graph.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/graph.h	/^namespace cnn {$/;"	n
cnn	cnn/gru.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/gru.h	/^namespace cnn {$/;"	n
cnn	cnn/init.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/init.h	/^namespace cnn {$/;"	n
cnn	cnn/lstm.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/lstm.h	/^namespace cnn {$/;"	n
cnn	cnn/macros.h	/^namespace cnn {$/;"	n
cnn	cnn/math.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/math.h	/^namespace cnn {$/;"	n
cnn	cnn/metric-util.cc	/^namespace cnn { namespace metric {$/;"	n	file:
cnn	cnn/metric-util.h	/^namespace cnn {$/;"	n
cnn	cnn/model.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/model.h	/^namespace cnn {$/;"	n
cnn	cnn/nodes-common.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/nodes.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/nodes.h	/^namespace cnn {$/;"	n
cnn	cnn/param-nodes.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/param-nodes.h	/^namespace cnn {$/;"	n
cnn	cnn/random.h	/^namespace cnn {$/;"	n
cnn	cnn/rnn-state-machine.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/rnn-state-machine.h	/^namespace cnn {$/;"	n
cnn	cnn/rnn.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/rnn.h	/^namespace cnn {$/;"	n
cnn	cnn/rnnem.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/rnnem.h	/^namespace cnn {$/;"	n
cnn	cnn/saxe-init.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/saxe-init.h	/^namespace cnn {$/;"	n
cnn	cnn/shadow-params.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/shadow-params.h	/^namespace cnn {$/;"	n
cnn	cnn/simd-functors.h	/^namespace cnn {$/;"	n
cnn	cnn/tensor.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/tensor.h	/^namespace cnn {$/;"	n
cnn	cnn/tests/test_utils.h	/^namespace cnn {$/;"	n
cnn	cnn/timing.h	/^namespace cnn {$/;"	n
cnn	cnn/training.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/training.h	/^namespace cnn {$/;"	n
cnn	cnn/treelstm.cc	/^namespace cnn {$/;"	n	file:
cnn	cnn/treelstm.h	/^namespace cnn {$/;"	n
cnn	examples/attentional.h	/^namespace cnn {$/;"	n
cnn	examples/convmodel.h	/^namespace cnn {$/;"	n
cnn	examples/cxtattentional.h	/^namespace cnn {$/;"	n
cnn	examples/regattentional.h	/^namespace cnn {$/;"	n
cnn	ext/dialogue/attention_with_intention.h	/^namespace cnn {$/;"	n
cnn	ext/dialogue/cxtencdec.h	/^namespace cnn {$/;"	n
cnn	ext/dialogue/dialogue.h	/^namespace cnn {$/;"	n
cnn	ext/dialogue/dialogue_process.h	/^namespace cnn {$/;"	n
cnn	ext/encdec/encdec.h	/^namespace cnn {$/;"	n
cnn	ext/ir/ir.h	/^namespace cnn {$/;"	n
cnn_mm_free	cnn/aligned-mem-pool.h	/^inline void cnn_mm_free(void* mem, bool on_cpu_only = false) {$/;"	f	namespace:cnn
cnn_mm_free_host	cnn/aligned-mem-pool.h	/^inline void cnn_mm_free_host(void* mem) {$/;"	f	namespace:cnn
cnn_mm_malloc	cnn/aligned-mem-pool.h	/^inline void* cnn_mm_malloc(size_t n, size_t align, bool on_cpu_only = false) {$/;"	f	namespace:cnn
cnn_mm_malloc_host	cnn/aligned-mem-pool.h	/^inline void* cnn_mm_malloc_host(size_t n, size_t align) {$/;"	f	namespace:cnn
colbatch_matrix	cnn/tensor.h	/^  Eigen::Map<EMatrix, Eigen::Unaligned> colbatch_matrix() {$/;"	f	struct:cnn::Tensor
colbatch_matrix	cnn/tensor.h	/^  const Eigen::Map<EMatrix, Eigen::Unaligned> colbatch_matrix() const {$/;"	f	struct:cnn::Tensor
collect_candidates	ext/dialogue/dialogue_process.h	/^        void collect_candidates(const std::vector<int>& response)$/;"	f	class:cnn::DialogueProcessInfo
collect_sample_responses	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::collect_sample_responses(AM_t& am, Corpus &training)$/;"	f	class:TrainProcess
cols	cnn/dim.h	/^  inline unsigned int cols() const { return nd > 1 ? d[1] : 1; }$/;"	f	struct:cnn::Dim
columnslices	cnn/expr.cc	/^Expression columnslices(const Expression& x, unsigned row, unsigned start_column, unsigned exclusive_end_column) { return Expression(x.pg, x.pg->add_function<ColumnSlices>({ x.i }, row, start_column, exclusive_end_column)); }$/;"	f	namespace:cnn::expr
colwise_add	cnn/expr.cc	/^Expression colwise_add(const Expression& x, const Expression& bias) { return Expression(x.pg, x.pg->add_function<AddVectorToAllColumns>({x.i, bias.i})); }$/;"	f	namespace:cnn::expr
combiner	ext/dialogue/attention_with_intention.h	/^    Builder combiner; \/\/\/ the combiner that combines the multipe sources of inputs, and possibly its history$/;"	m	class:cnn::MultiSource_LinearEncoder
combiner	ext/ir/ir.h	/^        Builder combiner; \/\/\/ the combiner that combines the multipe sources of inputs, and possibly its history$/;"	m	class:cnn::ClassificationEncoderDecoder
compute_gradient_norm	cnn/training.cc	/^void RmsPropWithMomentumTrainer::compute_gradient_norm($/;"	f	class:cnn::RmsPropWithMomentumTrainer
compute_importance_factor	cnn/rnnem.cc	/^    Expression NMNBuilder::compute_importance_factor(const Expression & r_t, \/\/\/ retrieved memory content $/;"	f	class:cnn::NMNBuilder
compute_score	ext/trainer/train_proc.h	/^    cnn::real compute_score()$/;"	f	struct:TrainingScores
concatenate	cnn/expr.h	/^inline Expression concatenate(const T& xs) { return detail::f<Concatenate>(xs); }$/;"	f	namespace:cnn::expr
concatenate	cnn/expr.h	/^inline Expression concatenate(const std::initializer_list<Expression>& xs) { return detail::f<Concatenate>(xs); }$/;"	f	namespace:cnn::expr
concatenate_cols	cnn/expr.h	/^inline Expression concatenate_cols(const T& xs) { return detail::f<ConcatenateColumns>(xs); }$/;"	f	namespace:cnn::expr
concatenate_cols	cnn/expr.h	/^inline Expression concatenate_cols(const std::initializer_list<Expression>& xs) { return detail::f<ConcatenateColumns>(xs); }$/;"	f	namespace:cnn::expr
const_add_op	cnn/simd-functors.h	/^  const_add_op(const Scalar& c) : c(c) {}$/;"	f	struct:cnn::const_add_op
const_add_op	cnn/simd-functors.h	/^template<typename Scalar> struct const_add_op {$/;"	s	namespace:cnn
const_lookup	cnn/expr.cc	/^Expression const_lookup(ComputationGraph& g, LookupParameters* p, const std::vector<unsigned>& indices) { return Expression(&g, g.add_const_lookup(p, indices)); }$/;"	f	namespace:cnn::expr
const_lookup	cnn/expr.cc	/^Expression const_lookup(ComputationGraph& g, LookupParameters* p, const std::vector<unsigned>* pindices) { return Expression(&g, g.add_const_lookup(p, pindices)); }$/;"	f	namespace:cnn::expr
const_lookup	cnn/expr.cc	/^Expression const_lookup(ComputationGraph& g, LookupParameters* p, const unsigned* pindex) { return Expression(&g, g.add_const_lookup(p, pindex)); }$/;"	f	namespace:cnn::expr
const_lookup	cnn/expr.cc	/^Expression const_lookup(ComputationGraph& g, LookupParameters* p, unsigned index) { return Expression(&g, g.add_const_lookup(p, index)); }$/;"	f	namespace:cnn::expr
const_minus_op	cnn/simd-functors.h	/^  const_minus_op(const Scalar& c) : c(c) {}$/;"	f	struct:cnn::const_minus_op
const_minus_op	cnn/simd-functors.h	/^template<typename Scalar> struct const_minus_op {$/;"	s	namespace:cnn
const_parameter	cnn/expr.cc	/^Expression const_parameter(ComputationGraph& g, Parameters* p) { return Expression(&g, g.add_const_parameters(p)); }$/;"	f	namespace:cnn::expr
construct_word_class	exp/lm/lm.py	/^def construct_word_class(lmfn, nbr_cls, output_word2cls_fn, output_cls2nbrwords_fn):$/;"	f
context	examples/cxtattentional.h	/^    Builder context; \/\/ for contexter$/;"	m	struct:cnn::CxtAttentionalModel
context	ext/dialogue/attention_with_intention.h	/^    Builder context; \/\/ for contexter$/;"	m	class:cnn::DynamicMemoryNetDialogue
context	ext/dialogue/dialogue.h	/^    Builder context; \/\/ for contexter$/;"	m	class:cnn::DialogueBuilder
contract3d_1d	cnn/expr.cc	/^Expression contract3d_1d(const Expression& x, const Expression& y) { return Expression(x.pg, x.pg->add_function<InnerProduct3D_1D>({x.i, y.i})); }$/;"	f	namespace:cnn::expr
contract3d_1d	cnn/expr.cc	/^Expression contract3d_1d(const Expression& x, const Expression& y, const Expression& b) { return Expression(x.pg, x.pg->add_function<InnerProduct3D_1D>({x.i, y.i, b.i})); }$/;"	f	namespace:cnn::expr
conv1d_narrow	cnn/expr.cc	/^Expression conv1d_narrow(const Expression& x, const Expression& f) { return Expression(x.pg, x.pg->add_function<Conv1DNarrow>({x.i, f.i})); }$/;"	f	namespace:cnn::expr
conv1d_wide	cnn/expr.cc	/^Expression conv1d_wide(const Expression& x, const Expression& f) { return Expression(x.pg, x.pg->add_function<Conv1DWide>({x.i, f.i})); }$/;"	f	namespace:cnn::expr
convertHumanQuery	cnn/data-util.cc	/^void convertHumanQuery(const std::string& line, std::vector<int>& t, Dict& td)$/;"	f
convertHumanQuery	cnn/data-util.cc	/^void convertHumanQuery(const std::wstring& line, std::vector<int>& t, WDict& td)$/;"	f
convert_to_vector	cnn/expr-xtra.cc	/^vector<Expression> convert_to_vector(Expression & in, unsigned dim, unsigned nutt)$/;"	f
copy	cnn/approximator.cc	/^    void ClsBasedBuilder::copy(const ClsBasedBuilder& othercls) {$/;"	f	class:cnn::ClsBasedBuilder
copy	cnn/dglstm.cc	/^void DGLSTMBuilder::copy(const RNNBuilder & rnn) {$/;"	f	class:cnn::DGLSTMBuilder
copy	cnn/dnn.cc	/^    void DNNBuilder::copy(const DNNBuilder & rnn) {$/;"	f	class:cnn::DNNBuilder
copy	cnn/gru.cc	/^void GRUBuilder::copy(const RNNBuilder & rnn) {$/;"	f	class:cnn::GRUBuilder
copy	cnn/lstm.cc	/^void LSTMBuilder::copy(const RNNBuilder & rnn) {$/;"	f	class:cnn::LSTMBuilder
copy	cnn/model.cc	/^void LookupParameters::copy(const LookupParameters & param) {$/;"	f	class:cnn::LookupParameters
copy	cnn/model.cc	/^void LookupParameters::copy(const std::map<int, std::vector<cnn::real>> & param) {$/;"	f	class:cnn::LookupParameters
copy	cnn/model.cc	/^void Parameters::copy(const Parameters & param) {$/;"	f	class:cnn::Parameters
copy	cnn/rnn.cc	/^void SimpleRNNBuilder::copy(const RNNBuilder & rnn) {$/;"	f	class:cnn::SimpleRNNBuilder
copy	cnn/treelstm.cc	/^void TreeLSTMBuilder::copy(const RNNBuilder & rnn) {$/;"	f	class:cnn::TreeLSTMBuilder
corpus	cnn/data-util.h	/^    Corpus corpus()$/;"	f	class:DataReader
cost	cnn/decode.h	/^    cnn::real cost;$/;"	m	struct:cnn::Hypothesis
cost	examples/attentional.h	/^    cnn::real cost;$/;"	m	struct:cnn::Hypothesis
cost	examples/cxtattentional.h	/^    cnn::real cost;$/;"	m	struct:cnn::Hypothesis
counts	exp/lm/lm.py	/^def counts(ifile, norder):$/;"	f
cube	cnn/expr.cc	/^Expression cube(const Expression& x) { return Expression(x.pg, x.pg->add_function<Cube>({x.i})); }$/;"	f	namespace:cnn::expr
cublas_handle	cnn/cuda.cc	/^cublasHandle_t cublas_handle;$/;"	m	namespace:cnn	file:
cuda_exception	cnn/except.h	/^  cuda_exception(const std::string& what_arg) : runtime_error(what_arg) {}$/;"	f	class:cnn::cuda_exception
cuda_exception	cnn/except.h	/^class cuda_exception : public std::runtime_error {$/;"	c	namespace:cnn
cuda_not_implemented	cnn/except.h	/^  cuda_not_implemented(const std::string& what_arg) : logic_error(what_arg) {}$/;"	f	class:cnn::cuda_not_implemented
cuda_not_implemented	cnn/except.h	/^class cuda_not_implemented : public std::logic_error {$/;"	c	namespace:cnn
cudnnDataType	cnn/cuda.cc	/^cudnnDataType_t cudnnDataType;$/;"	m	namespace:cnn	file:
cudnn_handle	cnn/cuda.cc	/^cudnnHandle_t cudnn_handle;$/;"	m	namespace:cnn	file:
cur	cnn/rnn.h	/^  RNNPointer cur;$/;"	m	struct:cnn::RNNBuilder
cwise_multiply	cnn/expr.cc	/^Expression cwise_multiply(const Expression& x, const Expression& y) {return Expression(x.pg, x.pg->add_function<CwiseMultiply>({x.i, y.i}));}$/;"	f	namespace:cnn::expr
d	cnn/dim.h	/^  unsigned int d[CNN_MAX_TENSOR_DIM];$/;"	m	struct:cnn::Dim
d	cnn/functors.h	/^  cnn::real d;$/;"	m	struct:cnn::FBinaryLogLossBackward
d	cnn/functors.h	/^  cnn::real d;$/;"	m	struct:cnn::FNegLogSoftmaxBackward
d	cnn/functors.h	/^  const cnn::real d;$/;"	m	struct:cnn::FHuberBackward
d	cnn/functors.h	/^  const cnn::real d;$/;"	m	struct:cnn::FL1Backward
d	cnn/functors.h	/^  const cnn::real* d;$/;"	m	struct:cnn::FPtrNegLogSoftmaxBackward
d	cnn/nodes.h	/^  cnn::real d;$/;"	m	struct:cnn::HuberDistance
d	cnn/simd-functors.h	/^  Scalar d;$/;"	m	struct:cnn::scalar_nlsoftmax_backward_op
d	cnn/tensor.h	/^  Dim d;$/;"	m	struct:cnn::Tensor
d	examples/encdec.cc	/^cnn::Dict d, devd;$/;"	v
d	examples/poisson-regression.cc	/^cnn::Dict d;$/;"	v
d	examples/rnnlm-aevb.cc	/^cnn::Dict d;$/;"	v
d	examples/rnnlm.cc	/^cnn::Dict d;$/;"	v
d	examples/rnnlm2.cc	/^cnn::Dict d;$/;"	v
d	examples/rnnlm2_cls_based.cc	/^cnn::Dict d;$/;"	v
d	examples/skiprnnlm.cc	/^cnn::Dict d;$/;"	v
d	examples/tag-bilstm.cc	/^cnn::Dict d;$/;"	v
d	examples/textcat.cc	/^cnn::Dict d;$/;"	v
dEdfs	cnn/init.cc	/^    AlignedMemoryPool<ALIGN>* dEdfs = nullptr;$/;"	m	namespace:cnn	file:
d_	cnn/dict.h	/^    I2TMap d_;$/;"	m	class:cnn::stId2String
d_	cnn/dict.h	/^  Map d_;$/;"	m	class:cnn::stDict
data	cnn/param-nodes.h	/^  const cnn::real data;$/;"	m	struct:cnn::ScalarInputNode
data	cnn/param-nodes.h	/^  const std::vector<cnn::real> data;$/;"	m	struct:cnn::InputNode
data_in_parallel	cnn/approximator.h	/^        int data_in_parallel() const { return dparallel; }$/;"	f	class:cnn::ClsBasedBuilder
data_in_parallel	cnn/dnn.h	/^        int data_in_parallel() const { return dparallel; }$/;"	f	class:cnn::DNNBuilder
data_in_parallel	cnn/rnn.h	/^  int data_in_parallel() const { return dparallel;  }$/;"	f	struct:cnn::RNNBuilder
dbuilder	examples/rnnlm-aevb.cc	/^  Builder dbuilder;$/;"	m	struct:RNNLanguageModel	file:
ddir	ext/lda/lda.h	/^	std::string ddir;				\/\/ data directory$/;"	m	class:ldaModel
dec_builder	examples/encdec.cc	/^    Builder dec_builder;$/;"	m	struct:EncoderDecoder	file:
dec_builder	examples/mem_seq2seq_encdec.cc	/^  Builder dec_builder;$/;"	m	struct:EncoderDecoder	file:
dec_builder	examples/seq2seq_encdec.cc	/^  Builder dec_builder;$/;"	m	struct:EncoderDecoder	file:
decode	examples/attentional.h	/^AttentionalModel<Builder>::decode(const std::vector<int> &source, ComputationGraph& cg, int beam_width, cnn::Dict &tdict)$/;"	f	class:cnn::AttentionalModel
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const Sentence&source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::DynamicMemoryNetDialogue
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &prv_response, const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::AttMultiSource_LinearEncoder
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &prv_response, const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &prv_response, const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &prv_response, const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &prv_response, const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::ClsBasedMultiSource_LinearEncoder
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &prv_response, const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::MultiSource_LinearEncoder
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::AWI_GeneralInputFeeding
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::AWI_LocalGeneralInputFeeding
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::AttMultiSource_LinearEncoder
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::ClsBasedMultiSource_LinearEncoder
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::MultiSource_LinearEncoder
decode	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict<std::wstring> &tdict)$/;"	f	class:cnn::AWI
decode	ext/dialogue/cxtencdec.h	/^    std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::CxtEncDecModel
decode	ext/dialogue/cxtencdec.h	/^    std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::Seq2SeqEncDecModel
decode	ext/dialogue/dialogue.h	/^    std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::DialogueBuilder
decode	ext/dialogue/dialogue_process.h	/^        vector<int> decode(const Sentence& prv_response, const Sentence& cur_source, ComputationGraph& cg, Dict<std::wstring>&  td)$/;"	f	class:cnn::AttentionWithIntentionModel
decode	ext/dialogue/dialogue_process.h	/^        vector<int> decode(const Sentence& prv_response, const Sentence& cur_source, ComputationGraph& cg, Dict<std::wstring>&  td)$/;"	f	class:cnn::AttentionalConversation
decode	ext/dialogue/dialogue_process.h	/^        vector<int> decode(const Sentence& source, ComputationGraph& cg, Dict<std::wstring>&  td)$/;"	f	class:cnn::AttentionWithIntentionModel
decode	ext/dialogue/dialogue_process.h	/^        vector<int> decode(const Sentence& source, ComputationGraph& cg, Dict<std::wstring>&  td)$/;"	f	class:cnn::AttentionalConversation
decode	ext/dialogue/dialogue_process.h	/^        virtual std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::ClassificationBasedMultiSourceDialogue
decode	ext/dialogue/dialogue_process.h	/^        virtual std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::DialogueProcessInfo
decode	ext/dialogue/dialogue_process.h	/^        virtual std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::MultiSourceDialogue
decode	ext/dialogue/dialogue_process.h	/^        virtual std::vector<int> decode(const std::vector<int> &source, const std::vector<int>& cur, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::ClassificationBasedMultiSourceDialogue
decode	ext/dialogue/dialogue_process.h	/^        virtual std::vector<int> decode(const std::vector<int> &source, const std::vector<int>& cur, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::DialogueProcessInfo
decode	ext/dialogue/dialogue_process.h	/^        virtual std::vector<int> decode(const std::vector<int> &source, const std::vector<int>& cur, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::MultiSourceDialogue
decode	ext/ir/ir.h	/^        std::vector<int> decode(const std::vector<int> &prv_response, const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::ClassificationEncoderDecoder
decode	ext/ir/ir.h	/^        std::vector<int> decode(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict  &tdict)$/;"	f	class:cnn::ClassificationEncoderDecoder
decode_tuple	ext/dialogue/attention_with_intention.h	/^    std::vector<int> decode_tuple(const SentenceTuple&source, ComputationGraph& cg, cnn::Dict  &sdict, cnn::Dict  &tdict)$/;"	f	class:cnn::DynamicMemoryNetDialogue
decode_tuple	ext/dialogue/dialogue.h	/^    std::vector<int> decode_tuple(const SentenceTuple&source, ComputationGraph& cg, cnn::Dict  &sdict, cnn::Dict  &tdict)$/;"	f	class:cnn::DialogueBuilder
decode_tuple	ext/dialogue/dialogue_process.h	/^        std::vector<int> decode_tuple(const SentenceTuple &source, ComputationGraph& cg, cnn::Dict  &sdict, cnn::Dict  &tdict)$/;"	f	class:cnn::DialogueProcessInfo
decode_tuple	ext/dialogue/dialogue_process.h	/^        std::vector<int> decode_tuple(const SentenceTuple &source, const SentenceTuple &cursource, ComputationGraph& cg, cnn::Dict  &sdict, cnn::Dict  &tdict)$/;"	f	class:cnn::DialogueProcessInfo
decoder	examples/cxtattentional.h	/^    Builder decoder;  \/\/ for decoder$/;"	m	struct:cnn::CxtAttentionalModel
decoder	ext/dialogue/attention_with_intention.h	/^    Decoder decoder;  \/\/ for decoder at each turn$/;"	m	class:cnn::DynamicMemoryNetDialogue
decoder	ext/dialogue/dialogue.h	/^    Decoder decoder;  \/\/ for decoder at each turn$/;"	m	class:cnn::DialogueBuilder
decoder_greedy_search	examples/cxtattentional.h	/^CxtAttentionalModel<Builder>::decoder_greedy_search(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict &tdict)$/;"	f	class:cnn::CxtAttentionalModel
decoder_single_instance_step	ext/dialogue/dialogue.h	/^    Expression decoder_single_instance_step(int trg_tok, ComputationGraph& cg) $/;"	f	class:cnn::DialogueBuilder
decoder_step	ext/dialogue/attention_with_intention.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::AWI
decoder_step	ext/dialogue/attention_with_intention.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::AWI_GeneralInputFeeding
decoder_step	ext/dialogue/attention_with_intention.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::AWI_GeneralInputFeedingWDropout
decoder_step	ext/dialogue/attention_with_intention.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::AWI_InputFeedingWithNNAttention
decoder_step	ext/dialogue/attention_with_intention.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::AWI_LocalGeneralInputFeeding
decoder_step	ext/dialogue/attention_with_intention.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::AttMultiSource_LinearEncoder
decoder_step	ext/dialogue/attention_with_intention.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
decoder_step	ext/dialogue/attention_with_intention.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
decoder_step	ext/dialogue/attention_with_intention.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch
decoder_step	ext/dialogue/attention_with_intention.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::HirearchicalEncDec
decoder_step	ext/dialogue/attention_with_intention.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::MultiSource_LinearEncoder
decoder_step	ext/dialogue/attention_with_intention.h	/^Expression AWI_Bilinear<Builder, Decoder>::decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::AWI_Bilinear
decoder_step	ext/dialogue/attention_with_intention.h	/^Expression AttentionWithIntention<Builder, Decoder>::decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::AttentionWithIntention
decoder_step	ext/dialogue/attention_with_intention.h	/^Expression GatedAttention<Builder, Decoder>::decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::GatedAttention
decoder_step	ext/dialogue/cxtencdec.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::CxtEncDecModel
decoder_step	ext/dialogue/cxtencdec.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::Seq2SeqEncDecModel
decoder_step	ext/ir/ir.h	/^        Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg)$/;"	f	class:cnn::ClassificationEncoderDecoder
decoder_use_additional_input	ext/dialogue/attention_with_intention.h	/^    int decoder_use_additional_input;$/;"	m	class:cnn::DynamicMemoryNetDialogue
decoder_use_additional_input	ext/dialogue/dialogue.h	/^    int decoder_use_additional_input;$/;"	m	class:cnn::DialogueBuilder
decoder_use_additional_input	ext/encdec/encdec.h	/^    int decoder_use_additional_input;$/;"	m	class:cnn::EncModel
denom	cnn/nodes.h	/^  std::vector<unsigned> denom;$/;"	m	struct:cnn::RestrictedLogSoftmax
detach	cnn/data-util.h	/^    void detach() { m_Thread.detach();  }$/;"	f	class:DataReader
detail	cnn/expr.h	/^namespace detail {$/;"	n	namespace:cnn::expr
dev_set_scores	ext/trainer/train_proc.h	/^    TrainingScores* dev_set_scores;$/;"	m	class:TrainProcess
devd	examples/encdec.cc	/^cnn::Dict d, devd;$/;"	v
devel_numturn2did	ext/trainer/train_proc.h	/^NumTurn2DialogId devel_numturn2did;$/;"	v
device_id	cnn/cnn.cc	/^int device_id = CPUDEVICE;$/;"	m	namespace:cnn	file:
dfile	ext/lda/lda.h	/^    const Corpus& dfile;              \/\/ train data corpus$/;"	m	class:ldaModel
dialogue	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::dialogue(Model &model, AM_t &am, string out_file, Dict & td)$/;"	f	class:TrainProcess
dict_wrd_id2within_class_id	cnn/approximator.h	/^        vector<long> dict_wrd_id2within_class_id;$/;"	m	class:cnn::ClsBasedBuilder
dict_wrd_id2within_class_id	examples/rnnlm2_cls_based.cc	/^  vector<long> dict_wrd_id2within_class_id;$/;"	m	struct:RNNLanguageModel	file:
dim	cnn/cnn.h	/^  Dim dim;  \/\/ will be .size() = 0 initially filled in by forward() -- TODO fix this$/;"	m	struct:cnn::Node
dim	cnn/model.h	/^  Dim dim;$/;"	m	struct:cnn::LookupParameters
dim	cnn/model.h	/^  Dim dim;$/;"	m	struct:cnn::Parameters
dim	cnn/nodes.h	/^  Dim dim;$/;"	m	struct:cnn::Zeroes
dim	cnn/param-nodes.h	/^    Dim dim;$/;"	m	struct:cnn::ReferenceNode
dim	cnn/param-nodes.h	/^  Dim dim;$/;"	m	struct:cnn::ConstParameterNode
dim	cnn/param-nodes.h	/^  Dim dim;$/;"	m	struct:cnn::InputNode
dim	cnn/param-nodes.h	/^  Dim dim;$/;"	m	struct:cnn::LookupNode
dim	cnn/param-nodes.h	/^  Dim dim;$/;"	m	struct:cnn::ParameterNode
dim_forward	cnn/conv.cc	/^Dim AddVectorToAllColumns::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::AddVectorToAllColumns
dim_forward	cnn/conv.cc	/^Dim Conv1DNarrow::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Conv1DNarrow
dim_forward	cnn/conv.cc	/^Dim Conv1DWide::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Conv1DWide
dim_forward	cnn/conv.cc	/^Dim FoldRows::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::FoldRows
dim_forward	cnn/conv.cc	/^Dim KMaxPooling::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::KMaxPooling
dim_forward	cnn/nodes-common.cc	/^Dim AffineTransform::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::AffineTransform
dim_forward	cnn/nodes-common.cc	/^Dim Average::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Average
dim_forward	cnn/nodes-common.cc	/^Dim BinaryLogLoss::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::BinaryLogLoss
dim_forward	cnn/nodes-common.cc	/^Dim BlockDropout::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::BlockDropout
dim_forward	cnn/nodes-common.cc	/^Dim ColumnSlices::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::ColumnSlices
dim_forward	cnn/nodes-common.cc	/^Dim Concatenate::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Concatenate
dim_forward	cnn/nodes-common.cc	/^Dim ConcatenateColumns::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::ConcatenateColumns
dim_forward	cnn/nodes-common.cc	/^Dim ConstScalarMultiply::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::ConstScalarMultiply
dim_forward	cnn/nodes-common.cc	/^Dim ConstantMinusX::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::ConstantMinusX
dim_forward	cnn/nodes-common.cc	/^Dim ConstantPlusX::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::ConstantPlusX
dim_forward	cnn/nodes-common.cc	/^Dim Cube::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Cube
dim_forward	cnn/nodes-common.cc	/^Dim CwiseMultiply::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::CwiseMultiply
dim_forward	cnn/nodes-common.cc	/^Dim CwiseQuotient::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::CwiseQuotient
dim_forward	cnn/nodes-common.cc	/^Dim DotProduct::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::DotProduct
dim_forward	cnn/nodes-common.cc	/^Dim Dropout::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Dropout
dim_forward	cnn/nodes-common.cc	/^Dim Exp::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Exp
dim_forward	cnn/nodes-common.cc	/^Dim ExponentialLinearUnits::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::ExponentialLinearUnits
dim_forward	cnn/nodes-common.cc	/^Dim GaussianNoise::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::GaussianNoise
dim_forward	cnn/nodes-common.cc	/^Dim Hinge::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Hinge
dim_forward	cnn/nodes-common.cc	/^Dim HuberDistance::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::HuberDistance
dim_forward	cnn/nodes-common.cc	/^Dim Identity::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Identity
dim_forward	cnn/nodes-common.cc	/^Dim InnerProduct3D_1D::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::InnerProduct3D_1D
dim_forward	cnn/nodes-common.cc	/^Dim KMHNGram::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::KMHNGram
dim_forward	cnn/nodes-common.cc	/^Dim L1Distance::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::L1Distance
dim_forward	cnn/nodes-common.cc	/^Dim Log::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Log
dim_forward	cnn/nodes-common.cc	/^Dim LogSoftmax::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::LogSoftmax
dim_forward	cnn/nodes-common.cc	/^Dim LogSumExp::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::LogSumExp
dim_forward	cnn/nodes-common.cc	/^Dim LogisticSigmoid::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::LogisticSigmoid
dim_forward	cnn/nodes-common.cc	/^Dim MatrixMultiply::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::MatrixMultiply
dim_forward	cnn/nodes-common.cc	/^Dim Max::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Max
dim_forward	cnn/nodes-common.cc	/^Dim Min::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Min
dim_forward	cnn/nodes-common.cc	/^Dim Negate::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Negate
dim_forward	cnn/nodes-common.cc	/^Dim PairwiseRankLoss::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::PairwiseRankLoss
dim_forward	cnn/nodes-common.cc	/^Dim PickElement::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::PickElement
dim_forward	cnn/nodes-common.cc	/^Dim PickRange::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::PickRange
dim_forward	cnn/nodes-common.cc	/^Dim PoissonRegressionLoss::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::PoissonRegressionLoss
dim_forward	cnn/nodes-common.cc	/^Dim Pow::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Pow
dim_forward	cnn/nodes-common.cc	/^Dim Rectify::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Rectify
dim_forward	cnn/nodes-common.cc	/^Dim Reduce::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Reduce
dim_forward	cnn/nodes-common.cc	/^Dim Reshape::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Reshape
dim_forward	cnn/nodes-common.cc	/^Dim RestrictedLogSoftmax::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::RestrictedLogSoftmax
dim_forward	cnn/nodes-common.cc	/^Dim SoftSign::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::SoftSign
dim_forward	cnn/nodes-common.cc	/^Dim Softmax::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Softmax
dim_forward	cnn/nodes-common.cc	/^Dim Sqrt::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Sqrt
dim_forward	cnn/nodes-common.cc	/^Dim Square::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Square
dim_forward	cnn/nodes-common.cc	/^Dim SquaredEuclideanDistance::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::SquaredEuclideanDistance
dim_forward	cnn/nodes-common.cc	/^Dim Sum::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Sum
dim_forward	cnn/nodes-common.cc	/^Dim SumBatches::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::SumBatches
dim_forward	cnn/nodes-common.cc	/^Dim SumColumns::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::SumColumns
dim_forward	cnn/nodes-common.cc	/^Dim Tanh::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Tanh
dim_forward	cnn/nodes-common.cc	/^Dim TraceOfProduct::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::TraceOfProduct
dim_forward	cnn/nodes-common.cc	/^Dim Transpose::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Transpose
dim_forward	cnn/nodes.cc	/^Dim Zeroes::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::Zeroes
dim_forward	cnn/param-nodes.cc	/^Dim ConstParameterNode::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::ConstParameterNode
dim_forward	cnn/param-nodes.cc	/^Dim InputNode::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::InputNode
dim_forward	cnn/param-nodes.cc	/^Dim LookupNode::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::LookupNode
dim_forward	cnn/param-nodes.cc	/^Dim ParameterNode::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::ParameterNode
dim_forward	cnn/param-nodes.cc	/^Dim ReferenceNode::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::ReferenceNode
dim_forward	cnn/param-nodes.cc	/^Dim ScalarInputNode::dim_forward(const vector<Dim>& xs) const {$/;"	f	class:cnn::ScalarInputNode
display	cnn/approximator.cc	/^    void ClsBasedBuilder::display(ComputationGraph& cg) {$/;"	f	class:cnn::ClsBasedBuilder
display	cnn/dnn.cc	/^    void DNNBuilder::display(ComputationGraph& cg) {$/;"	f	class:cnn::DNNBuilder
display	cnn/rnn.cc	/^void RNNBuilder::display(ComputationGraph& cg) {$/;"	f	class:cnn::RNNBuilder
display	examples/attentional.h	/^AttentionalModel<Builder>::display(const std::vector<int> &source, const std::vector<int>& target, $/;"	f	class:cnn::AttentionalModel
display_value	cnn/data-util.cc	/^void display_value(int n, const cnn::real* val, string str)$/;"	f
display_value	cnn/expr-xtra.cc	/^void display_value(const Expression &source, ComputationGraph &cg, string what_to_say)$/;"	f
dither	cnn/expr-xtra.cc	/^Expression dither(ComputationGraph &cg, const Expression &expr, cnn::real pad_value, std::vector<cnn::real> *aux_mem)$/;"	f
dloss	ext/trainer/train_proc.h	/^    cnn::real dloss; $/;"	m	struct:TrainingScores
dot_product	cnn/expr.cc	/^Expression dot_product(const Expression& x, const Expression& y) { return Expression(x.pg, x.pg->add_function<DotProduct>({x.i, y.i})); }$/;"	f	namespace:cnn::expr
dparallel	cnn/approximator.h	/^        int dparallel;$/;"	m	class:cnn::ClsBasedBuilder
dparallel	cnn/dnn.h	/^        int dparallel;$/;"	m	class:cnn::DNNBuilder
dparallel	cnn/rnn.h	/^  int dparallel; \/\/\/ the number of data points to process in parallel. this is used in the case of loading multiple sentences and process them at the same time$/;"	m	struct:cnn::RNNBuilder
dropout	cnn/expr.cc	/^Expression dropout(const Expression& x, cnn::real p) { return Expression(x.pg, x.pg->add_function<Dropout>({x.i}, p)); }$/;"	f	namespace:cnn::expr
dropout_probability	cnn/nodes.h	/^  cnn::real dropout_probability;$/;"	m	struct:cnn::BlockDropout
dropout_rate	ext/dialogue/attention_with_intention.h	/^    cnn::real dropout_rate; $/;"	m	class:cnn::AWI_GeneralInputFeedingWDropout
dump_word_embedding	ext/dialogue/dialogue.h	/^    void dump_word_embedding(const map<int, vector<cnn::real>>& vWordEmbedding, Dict& td, string ofn)$/;"	f	class:cnn::DialogueBuilder
dump_word_embedding	ext/dialogue/dialogue_process.h	/^        void dump_word_embedding(const map<int, vector<cnn::real>>& vWordEmbedding, Dict& td, string ofn)$/;"	f	class:cnn::DialogueProcessInfo
eWordEmbedding	ext/trainer/eval_proc.h	/^    map<int, Expression> eWordEmbedding;$/;"	m	class:EvaluateProcess
each_sentence_length	cnn/expr-xtra.cc	/^vector<unsigned> each_sentence_length(const vector<vector<int>>& source)$/;"	f
ebuilder	examples/rnnlm-aevb.cc	/^  Builder ebuilder;$/;"	m	struct:RNNLanguageModel	file:
ee	cnn/cnn.h	/^  ExecutionEngine* ee;  \/\/ handles the execution$/;"	m	struct:cnn::ComputationGraph
element	cnn/nodes.h	/^  unsigned element;$/;"	m	struct:cnn::Hinge
emb2expression	ext/trainer/eval_proc.h	/^void EvaluateProcess<Proc>::emb2expression(ComputationGraph& cg)$/;"	f	class:EvaluateProcess
embedding	cnn/expr-xtra.cc	/^vector<Expression> embedding(unsigned & slen, const vector<vector<int>>& source, ComputationGraph& cg, LookupParameters* p_cs)$/;"	f
embedding	cnn/expr-xtra.cc	/^vector<Expression> embedding(unsigned & slen, const vector<vector<int>>& source, ComputationGraph& cg, LookupParameters* p_cs, vector<cnn::real>& zero, unsigned feat_dim)$/;"	f
embedding_spkfirst	cnn/expr-xtra.cc	/^vector<Expression> embedding_spkfirst(const vector<vector<int>>& source, ComputationGraph& cg, LookupParameters* p_cs)$/;"	f
enc_builder	examples/mem_seq2seq_encdec.cc	/^  Builder enc_builder;$/;"	m	struct:EncoderDecoder	file:
encoder_bwd	examples/cxtattentional.h	/^    Builder encoder_fwd, encoder_bwd; \/\/\/ for encoder$/;"	m	struct:cnn::CxtAttentionalModel
encoder_bwd	ext/dialogue/attention_with_intention.h	/^    Builder encoder_fwd, encoder_bwd; \/\/\/ for encoder at each turn$/;"	m	class:cnn::DynamicMemoryNetDialogue
encoder_bwd	ext/dialogue/dialogue.h	/^    Builder encoder_fwd, encoder_bwd; \/\/\/ for encoder at each turn$/;"	m	class:cnn::DialogueBuilder
encoder_bwd	ext/encdec/encdec.h	/^    Builder encoder_fwd, encoder_bwd; \/\/\/ for encoder at each turn$/;"	m	class:cnn::EncModel
encoder_fwd	examples/cxtattentional.h	/^    Builder encoder_fwd, encoder_bwd; \/\/\/ for encoder$/;"	m	struct:cnn::CxtAttentionalModel
encoder_fwd	ext/dialogue/attention_with_intention.h	/^    Builder encoder_fwd, encoder_bwd; \/\/\/ for encoder at each turn$/;"	m	class:cnn::DynamicMemoryNetDialogue
encoder_fwd	ext/dialogue/dialogue.h	/^    Builder encoder_fwd, encoder_bwd; \/\/\/ for encoder at each turn$/;"	m	class:cnn::DialogueBuilder
encoder_fwd	ext/encdec/encdec.h	/^    Builder encoder_fwd, encoder_bwd; \/\/\/ for encoder at each turn$/;"	m	class:cnn::EncModel
end	cnn/nodes.h	/^  unsigned end;$/;"	m	struct:cnn::PickRange
end_column	cnn/nodes.h	/^    unsigned end_column;$/;"	m	struct:cnn::ColumnSlices
epoch	cnn/training.h	/^  cnn::real epoch;$/;"	m	struct:cnn::Trainer
eps	cnn/training.h	/^  cnn::real eps;$/;"	m	struct:cnn::AdamTrainer
epsilon	cnn/functors.h	/^    cnn::real epsilon;$/;"	m	struct:cnn::FL2SGDMomentumWithDenUpdate
epsilon	cnn/training.h	/^    cnn::real epsilon;$/;"	m	struct:cnn::RmsPropWithMomentumTrainer
epsilon	cnn/training.h	/^  cnn::real epsilon;$/;"	m	struct:cnn::AdadeltaTrainer
epsilon	cnn/training.h	/^  cnn::real epsilon;$/;"	m	struct:cnn::AdagradTrainer
epsilon	cnn/training.h	/^  cnn::real epsilon;$/;"	m	struct:cnn::RmsPropTrainer
eq	cnn/expr-xtra.cc	/^Expression eq(const Expression &expr, cnn::real value, cnn::real epsilon) $/;"	f
errors	cnn/approximator.h	/^        vector<vector<Expression>> errors; \/\/\/ [nutt][vector<error>] $/;"	m	class:cnn::ClsBasedBuilder
eta	cnn/training.h	/^  cnn::real eta;$/;"	m	struct:cnn::Trainer
eta0	cnn/training.h	/^  cnn::real eta0;$/;"	m	struct:cnn::Trainer
eta_decay	cnn/training.h	/^  cnn::real eta_decay;$/;"	m	struct:cnn::Trainer
eval	examples/tag-bilstm.cc	/^bool eval = false;$/;"	v
exit	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^:exit$/;"	l
exit	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^:exit$/;"	l
exit	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^:exit$/;"	l
exit	exp/encdec/encdec.bat	/^:exit$/;"	l
exit	exp/lm/rnnlm2.bat	/^:exit$/;"	l
exit	exp/lm/rnnlm2.dglstm.bat	/^:exit$/;"	l
exit	exp/lm/rnnlm2_cls.bat	/^:exit$/;"	l
exit	exp/lm/rnnlm2_cls_tst.bat	/^:exit$/;"	l
exp	cnn/expr.cc	/^Expression exp(const Expression& x) { return Expression(x.pg, x.pg->add_function<Exp>({x.i})); }$/;"	f	namespace:cnn::expr
exponential_linear_units	cnn/expr.cc	/^Expression exponential_linear_units(const Expression& x, cnn::real scale) { return Expression(x.pg, x.pg->add_function<ExponentialLinearUnits>({ x.i }, scale)); }$/;"	f	namespace:cnn::expr
expr	cnn/cnn.h	/^namespace expr { struct Expression; }$/;"	n	namespace:cnn
expr	cnn/expr.cc	/^namespace cnn { namespace expr {$/;"	n	namespace:cnn	file:
expr	cnn/expr.h	/^namespace cnn { namespace expr {$/;"	n	namespace:cnn
f	cnn/expr.h	/^  Expression f(const T& xs) {$/;"	f	namespace:cnn::expr::detail
fact_encoder_state	ext/dialogue/attention_with_intention.h	/^    vector<vector<Expression>> fact_encoder_state;  \/\/\/ [number_of_facts][number_of_hidden_states]$/;"	m	class:cnn::DynamicMemoryNetDialogue
failure	cnn/rnn-state-machine.cc	/^void RNNStateMachine::failure(RNNOp op) {$/;"	f	class:cnn::RNNStateMachine
fastexp	cnn/functors.h	/^static CNN_DEVICE_FUNC inline cnn::real fastexp(cnn::real p) {$/;"	f
fastpow2	cnn/functors.h	/^static inline ElemType fastpow2 (ElemType p) {$/;"	f
fc2w	cnn/c2w.h	/^  LSTMBuilder fc2w;$/;"	m	struct:cnn::C2WBuilder
feat_dim	examples/regattentional.h	/^    int feat_dim;$/;"	m	struct:cnn::RegAttentionalModel
final	cnn/cnn.h	/^                        Tensor& dEdxi) const final;$/;"	m	struct:cnn::Node
final	cnn/cnn.h	/^                       Tensor& fx) const final;$/;"	m	struct:cnn::Node
final_M	cnn/rnnem.h	/^  std::vector<Expression> final_M() const { return (M.size() == 0 ? M0 : M.back()); }$/;"	f	struct:cnn::NMNBuilder
final_c	cnn/rnnem.h	/^  std::vector<Expression> final_c() const { return (c.size() == 0 ? c0 : c.back()); }$/;"	f	struct:cnn::NMNBuilder
final_h	cnn/deep-lstm.h	/^  std::vector<Expression> final_h() const { return (h.size() == 0 ? h0 : h.back()); }$/;"	f	struct:cnn::DeepLSTMBuilder
final_h	cnn/dglstm.h	/^  std::vector<Expression> final_h() const { return (h.size() == 0 ? h0 : h.back()); }$/;"	f	struct:cnn::DGLSTMBuilder
final_h	cnn/dnn.h	/^        std::vector<Expression> final_h() const { return h; }$/;"	f	class:cnn::DNNBuilder
final_h	cnn/gru.h	/^  std::vector<Expression> final_h() const { return (h.size() == 0 ? h0 : h.back()); }$/;"	f	struct:cnn::GRUBuilder
final_h	cnn/lstm.h	/^  std::vector<Expression> final_h() const { return (h.size() == 0 ? h0 : h.back()); }$/;"	f	struct:cnn::LSTMBuilder
final_h	cnn/rnn.h	/^  std::vector<Expression> final_h() const { return (h.size() == 0 ? h0 : h.back()); }$/;"	f	struct:cnn::SimpleRNNBuilder
final_h	cnn/rnnem.h	/^  std::vector<Expression> final_h() const {$/;"	f	struct:cnn::NMNBuilder
final_h	cnn/treelstm.h	/^  std::vector<Expression> final_h() const { return (h.size() == 0 ? h0 : h.back()); }$/;"	f	struct:cnn::TreeLSTMBuilder
final_s	cnn/deep-lstm.h	/^  std::vector<Expression> final_s() const {$/;"	f	struct:cnn::DeepLSTMBuilder
final_s	cnn/dglstm.h	/^  std::vector<Expression> final_s() const { $/;"	f	struct:cnn::DGLSTMBuilder
final_s	cnn/dnn.h	/^        std::vector<Expression> final_s() const { return final_h(); }$/;"	f	class:cnn::DNNBuilder
final_s	cnn/gru.h	/^  std::vector<Expression> final_s() const { return final_h(); }$/;"	f	struct:cnn::GRUBuilder
final_s	cnn/lstm.h	/^  std::vector<Expression> final_s() const {$/;"	f	struct:cnn::LSTMBuilder
final_s	cnn/rnn.h	/^  std::vector<Expression> final_s() const { return final_h(); }$/;"	f	struct:cnn::SimpleRNNBuilder
final_s	cnn/rnnem.h	/^  std::vector<Expression> final_s() const {$/;"	f	struct:cnn::NMNBuilder
final_s	cnn/treelstm.h	/^  std::vector<Expression> final_s() const {$/;"	f	struct:cnn::TreeLSTMBuilder
final_w	cnn/rnnem.h	/^  std::vector<Expression> final_w() const { return (w.size() == 0 ? w0 : w.back()); }$/;"	f	struct:cnn::NMNBuilder
first	cnn/data-util.h	/^    T first;$/;"	m	struct:triplet
flatten_corpus	cnn/data-util.cc	/^void flatten_corpus(const Corpus& corpus, vector<Sentence>& sentences, vector<Sentence>& response)$/;"	f
flatten_corpus	cnn/data-util.cc	/^void flatten_corpus(const CorpusWithClassId& corpus, vector<Sentence>& sentences, vector<SentenceWithId>& response)$/;"	f
fold_rows	cnn/expr.cc	/^Expression fold_rows(const Expression& x, unsigned nrows) { return Expression(x.pg, x.pg->add_function<FoldRows>({x.i}, nrows)); }$/;"	f	namespace:cnn::expr
forward	cnn/cnn.cc	/^const Tensor& ComputationGraph::forward() { return ee->forward(); }$/;"	f	class:cnn::ComputationGraph
forward	cnn/cnn.cc	/^void Node::forward(const std::vector<const Tensor*>& xs,$/;"	f	class:cnn::Node
forward	cnn/exec.cc	/^const Tensor& SimpleExecutionEngine::forward() { $/;"	f	class:cnn::SimpleExecutionEngine
forward	cnn/exec.cc	/^const Tensor& SimpleExecutionEngine::forward(VariableIndex i) {$/;"	f	class:cnn::SimpleExecutionEngine
forward_directional	cnn/expr-xtra.h	/^std::vector<Expression> forward_directional(unsigned & slen, const std::vector<std::vector<int>>& source, ComputationGraph& cg, LookupParameters* p_cs, std::vector<cnn::real>& zero,$/;"	f
forward_impl	cnn/conv.cc	/^void AddVectorToAllColumns::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::AddVectorToAllColumns
forward_impl	cnn/conv.cc	/^void Conv1DNarrow::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Conv1DNarrow
forward_impl	cnn/conv.cc	/^void Conv1DWide::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Conv1DWide
forward_impl	cnn/conv.cc	/^void FoldRows::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::FoldRows
forward_impl	cnn/conv.cc	/^void KMaxPooling::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::KMaxPooling
forward_impl	cnn/nodes.cc	/^void AffineTransform::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::AffineTransform
forward_impl	cnn/nodes.cc	/^void Average::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Average
forward_impl	cnn/nodes.cc	/^void BinaryLogLoss::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::BinaryLogLoss
forward_impl	cnn/nodes.cc	/^void BlockDropout::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::BlockDropout
forward_impl	cnn/nodes.cc	/^void ColumnSlices::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::ColumnSlices
forward_impl	cnn/nodes.cc	/^void Concatenate::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Concatenate
forward_impl	cnn/nodes.cc	/^void ConcatenateColumns::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::ConcatenateColumns
forward_impl	cnn/nodes.cc	/^void ConstScalarMultiply::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::ConstScalarMultiply
forward_impl	cnn/nodes.cc	/^void ConstantMinusX::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::ConstantMinusX
forward_impl	cnn/nodes.cc	/^void ConstantPlusX::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::ConstantPlusX
forward_impl	cnn/nodes.cc	/^void Cube::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Cube
forward_impl	cnn/nodes.cc	/^void CwiseMultiply::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::CwiseMultiply
forward_impl	cnn/nodes.cc	/^void CwiseQuotient::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::CwiseQuotient
forward_impl	cnn/nodes.cc	/^void DotProduct::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::DotProduct
forward_impl	cnn/nodes.cc	/^void Dropout::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Dropout
forward_impl	cnn/nodes.cc	/^void Exp::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Exp
forward_impl	cnn/nodes.cc	/^void ExponentialLinearUnits::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::ExponentialLinearUnits
forward_impl	cnn/nodes.cc	/^void GaussianNoise::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::GaussianNoise
forward_impl	cnn/nodes.cc	/^void Hinge::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Hinge
forward_impl	cnn/nodes.cc	/^void HuberDistance::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::HuberDistance
forward_impl	cnn/nodes.cc	/^void Identity::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Identity
forward_impl	cnn/nodes.cc	/^void InnerProduct3D_1D::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::InnerProduct3D_1D
forward_impl	cnn/nodes.cc	/^void KMHNGram::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::KMHNGram
forward_impl	cnn/nodes.cc	/^void L1Distance::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::L1Distance
forward_impl	cnn/nodes.cc	/^void Log::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Log
forward_impl	cnn/nodes.cc	/^void LogSoftmax::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::LogSoftmax
forward_impl	cnn/nodes.cc	/^void LogSumExp::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::LogSumExp
forward_impl	cnn/nodes.cc	/^void LogisticSigmoid::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::LogisticSigmoid
forward_impl	cnn/nodes.cc	/^void MatrixMultiply::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::MatrixMultiply
forward_impl	cnn/nodes.cc	/^void Max::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Max
forward_impl	cnn/nodes.cc	/^void MaxPooling1D::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::MaxPooling1D
forward_impl	cnn/nodes.cc	/^void Min::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Min
forward_impl	cnn/nodes.cc	/^void Negate::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Negate
forward_impl	cnn/nodes.cc	/^void PairwiseRankLoss::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::PairwiseRankLoss
forward_impl	cnn/nodes.cc	/^void PickElement::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::PickElement
forward_impl	cnn/nodes.cc	/^void PickRange::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::PickRange
forward_impl	cnn/nodes.cc	/^void PoissonRegressionLoss::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::PoissonRegressionLoss
forward_impl	cnn/nodes.cc	/^void Pow::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Pow
forward_impl	cnn/nodes.cc	/^void Rectify::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Rectify
forward_impl	cnn/nodes.cc	/^void Reduce::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Reduce
forward_impl	cnn/nodes.cc	/^void Reshape::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Reshape
forward_impl	cnn/nodes.cc	/^void RestrictedLogSoftmax::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::RestrictedLogSoftmax
forward_impl	cnn/nodes.cc	/^void SoftSign::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::SoftSign
forward_impl	cnn/nodes.cc	/^void Softmax::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Softmax
forward_impl	cnn/nodes.cc	/^void Sqrt::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Sqrt
forward_impl	cnn/nodes.cc	/^void Square::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Square
forward_impl	cnn/nodes.cc	/^void SquaredEuclideanDistance::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::SquaredEuclideanDistance
forward_impl	cnn/nodes.cc	/^void Sum::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Sum
forward_impl	cnn/nodes.cc	/^void SumBatches::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::SumBatches
forward_impl	cnn/nodes.cc	/^void SumColumns::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::SumColumns
forward_impl	cnn/nodes.cc	/^void Tanh::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Tanh
forward_impl	cnn/nodes.cc	/^void TraceOfProduct::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::TraceOfProduct
forward_impl	cnn/nodes.cc	/^void Transpose::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Transpose
forward_impl	cnn/nodes.cc	/^void Zeroes::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::Zeroes
forward_impl	cnn/param-nodes.cc	/^void ConstParameterNode::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::ConstParameterNode
forward_impl	cnn/param-nodes.cc	/^void InputNode::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::InputNode
forward_impl	cnn/param-nodes.cc	/^void LookupNode::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::LookupNode
forward_impl	cnn/param-nodes.cc	/^void ParameterNode::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::ParameterNode
forward_impl	cnn/param-nodes.cc	/^void ReferenceNode::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::ReferenceNode
forward_impl	cnn/param-nodes.cc	/^void ScalarInputNode::forward_impl(const vector<const Tensor*>& xs, Tensor& fx) const {$/;"	f	class:cnn::ScalarInputNode
free	cnn/aligned-mem-pool.h	/^  void free() {$/;"	f	class:cnn::AlignedMemoryPool
free_and_grow_capacity	cnn/aligned-mem-pool.h	/^  void free_and_grow_capacity(unsigned long new_cap = 0) {$/;"	f	class:cnn::AlignedMemoryPool
free_working_copies	cnn/model.cc	/^void LookupParameters::free_working_copies()$/;"	f	class:cnn::LookupParameters
frozen	cnn/dict.h	/^    bool frozen;$/;"	m	class:cnn::stId2String
frozen	cnn/dict.h	/^  bool frozen;$/;"	m	class:cnn::stDict
functor_traits	cnn/simd-functors.h	/^struct functor_traits<cnn::const_add_op<Scalar> > {$/;"	s	namespace:Eigen::internal
functor_traits	cnn/simd-functors.h	/^struct functor_traits<cnn::const_minus_op<Scalar> > {$/;"	s	namespace:Eigen::internal
functor_traits	cnn/simd-functors.h	/^struct functor_traits<cnn::scalar_erf_backward_op<Scalar> > {$/;"	s	namespace:Eigen::internal
functor_traits	cnn/simd-functors.h	/^struct functor_traits<cnn::scalar_logistic_sigmoid_backward_op<Scalar> > {$/;"	s	namespace:Eigen::internal
functor_traits	cnn/simd-functors.h	/^struct functor_traits<cnn::scalar_logistic_sigmoid_op<Scalar> > {$/;"	s	namespace:Eigen::internal
functor_traits	cnn/simd-functors.h	/^struct functor_traits<cnn::scalar_nlsoftmax_backward_op<Scalar> > {$/;"	s	namespace:Eigen::internal
functor_traits	cnn/simd-functors.h	/^struct functor_traits<cnn::scalar_tanh_backward_op<Scalar> > {$/;"	s	namespace:Eigen::internal
functor_traits	cnn/simd-functors.h	/^struct functor_traits<cnn::scalar_tanh_op<Scalar> > {$/;"	s	namespace:Eigen::internal
fwd_enc_builder	examples/encdec.cc	/^    Builder fwd_enc_builder;$/;"	m	struct:EncoderDecoder	file:
fwd_enc_builder	examples/seq2seq_encdec.cc	/^  Builder fwd_enc_builder;$/;"	m	struct:EncoderDecoder	file:
fxs	cnn/init.cc	/^    AlignedMemoryPool<ALIGN>* fxs = nullptr;$/;"	m	namespace:cnn	file:
g	cnn/model.h	/^  Tensor g;$/;"	m	struct:cnn::Parameters
g_squared_l2norm	cnn/model.cc	/^void LookupParameters::g_squared_l2norm(cnn::real* sqnorm) const {$/;"	f	class:cnn::LookupParameters
g_squared_l2norm	cnn/model.cc	/^void Parameters::g_squared_l2norm(cnn::real* sqnorm) const {$/;"	f	class:cnn::Parameters
g_train_on_turns	ext/trainer/train_proc.h	/^size_t g_train_on_turns = 1; $/;"	v
geq	cnn/expr-xtra.cc	/^Expression geq(const Expression &expr, cnn::real value, Expression &one, cnn::real epsilon) $/;"	f
getCmdOption	cnn/init.cc	/^    char* getCmdOption(char ** begin, char ** end, const std::string & option)$/;"	f	namespace:cnn
get_error	cnn/cnn.cc	/^const Tensor& ComputationGraph::get_error(VariableIndex i) { return ee->get_error(i); }$/;"	f	class:cnn::ComputationGraph
get_error	cnn/exec.cc	/^const Tensor& SimpleExecutionEngine::get_error(VariableIndex i) $/;"	f	class:cnn::SimpleExecutionEngine
get_error	cnn/expr-xtra.cc	/^vector<cnn::real> get_error(Expression nd, ComputationGraph& cg)$/;"	f
get_idf	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::get_idf(variables_map vm, const Corpus &training, Dict& sd)$/;"	f	class:TrainProcess
get_numturn2dialid	cnn/data-util.cc	/^NumTurn2DialogId get_numturn2dialid(Corpus corp)$/;"	f
get_numturn2dialid	cnn/data-util.cc	/^NumTurn2DialogId get_numturn2dialid(TupleCorpus corp)$/;"	f
get_same_length_dialogues	cnn/data-util.cc	/^vector<int> get_same_length_dialogues(Corpus corp, int nbr_dialogues, size_t &min_nbr_turns, vector<bool>& used, PDialogue& selected, NumTurn2DialogId& info)$/;"	f
get_string_and_its_id	cnn/data-util.cc	/^void get_string_and_its_id(const string &filename, const pair<int, int>& columids, const string& save_to_filename)$/;"	f
get_value	cnn/cnn.cc	/^const Tensor& ComputationGraph::get_value(VariableIndex i) { return ee->get_value(i); }$/;"	f	class:cnn::ComputationGraph
get_value	cnn/cnn.cc	/^const Tensor& ComputationGraph::get_value(const expr::Expression& e) { return this->get_value(e.i); }$/;"	f	class:cnn::ComputationGraph
get_value	cnn/exec.cc	/^const Tensor& SimpleExecutionEngine::get_value(VariableIndex i) {$/;"	f	class:cnn::SimpleExecutionEngine
get_value	cnn/expr-xtra.cc	/^vector<cnn::real> get_value(Expression nd, ComputationGraph& cg)$/;"	f
giza_extensions	examples/attentional.h	/^    bool giza_extensions;$/;"	m	struct:cnn::AttentionalModel
glb_temp_cpu_mem	cnn/init.cc	/^    AlignedMemoryPool<ALIGN>* glb_temp_cpu_mem = nullptr;$/;"	m	namespace:cnn	file:
glb_temp_gpu_mem	cnn/init.cc	/^    AlignedMemoryPool<ALIGN>* glb_temp_gpu_mem = nullptr;$/;"	m	namespace:cnn	file:
glb_temp_working_mem	cnn/init.cc	/^    AlignedMemoryPool<ALIGN>* glb_temp_working_mem = nullptr;$/;"	m	namespace:cnn	file:
gpu	cnn/gpu-kernels.h	/^    namespace gpu {$/;"	n	namespace:cnn
gpu	cnn/gpu-ops.h	/^namespace gpu {$/;"	n	namespace:cnn
gradient_l2_norm	cnn/model.cc	/^cnn::real Model::gradient_l2_norm() const {$/;"	f	class:cnn::Model
gradient_norm_scratch	cnn/model.h	/^    mutable cnn::real* gradient_norm_scratch;$/;"	m	class:cnn::Model
gradientcheck	exp/encdec/encdec.bat	/^:gradientcheck$/;"	l
grads	cnn/model.h	/^  std::vector<Tensor> grads;$/;"	m	struct:cnn::LookupParameters
grads_for_non_zero_grads	cnn/model.h	/^  std::unordered_map<unsigned, Tensor> grads_for_non_zero_grads;$/;"	m	struct:cnn::LookupParameters
gscale	cnn/functors.h	/^    cnn::real* gscale;$/;"	m	struct:cnn::FL2SGDMomentumWithDenUpdate
gscale	cnn/model.h	/^    mutable cnn::real *gscale; \/\/\/ gradient scale, memory to be allocated by GPU if HAVE_CUDA$/;"	m	class:cnn::Model
h	cnn/deep-lstm.h	/^  std::vector<std::vector<Expression>> h, c;$/;"	m	struct:cnn::DeepLSTMBuilder
h	cnn/dglstm.h	/^  std::vector<std::vector<Expression>> h, c;$/;"	m	struct:cnn::DGLSTMBuilder
h	cnn/dnn.h	/^        std::vector<Expression> h;$/;"	m	class:cnn::DNNBuilder
h	cnn/gru.h	/^  std::vector<std::vector<Expression>> h;$/;"	m	struct:cnn::GRUBuilder
h	cnn/lstm.h	/^  std::vector<std::vector<Expression>> h, c;$/;"	m	struct:cnn::LSTMBuilder
h	cnn/rnn.h	/^  std::vector<std::vector<Expression>> h;$/;"	m	struct:cnn::SimpleRNNBuilder
h	cnn/rnnem.h	/^  std::vector<std::vector<Expression>> h, c, w;$/;"	m	struct:cnn::NMNBuilder
h	cnn/shadow-params.h	/^  Tensor h;$/;"	m	struct:cnn::ShadowParameters
h	cnn/shadow-params.h	/^  std::vector<Tensor> h;$/;"	m	struct:cnn::ShadowLookupParameters
h	cnn/treelstm.h	/^  std::vector<std::vector<Expression>> h, c;$/;"	m	struct:cnn::TreeLSTMBuilder
h0	cnn/deep-lstm.h	/^  std::vector<Expression> h0;$/;"	m	struct:cnn::DeepLSTMBuilder
h0	cnn/dglstm.h	/^  std::vector<Expression> h0;$/;"	m	struct:cnn::DGLSTMBuilder
h0	cnn/gru.h	/^  std::vector<Expression> h0;$/;"	m	struct:cnn::GRUBuilder
h0	cnn/lstm.h	/^  std::vector<Expression> h0;$/;"	m	struct:cnn::LSTMBuilder
h0	cnn/rnn.h	/^  std::vector<Expression> h0;$/;"	m	struct:cnn::SimpleRNNBuilder
h0	cnn/rnnem.h	/^  std::vector<Expression> w0, h0, c0, M0;$/;"	m	struct:cnn::NMNBuilder
h0	cnn/treelstm.h	/^  std::vector<Expression> h0;$/;"	m	struct:cnn::TreeLSTMBuilder
has_initial_state	cnn/deep-lstm.h	/^  bool has_initial_state; \/\/ if this is false, treat h0 and c0 as 0$/;"	m	struct:cnn::DeepLSTMBuilder
has_initial_state	cnn/dglstm.h	/^  bool has_initial_state; \/\/ if this is false, treat h0 and c0 as 0$/;"	m	struct:cnn::DGLSTMBuilder
has_initial_state	cnn/lstm.h	/^  bool has_initial_state; \/\/ if this is false, treat h0 and c0 as 0$/;"	m	struct:cnn::LSTMBuilder
has_initial_state	cnn/rnnem.h	/^  bool has_initial_state; \/\/ if this is false, treat h0 and c0 as 0$/;"	m	struct:cnn::NMNBuilder
has_initial_state	cnn/treelstm.h	/^  bool has_initial_state; \/\/ if this is false, treat h0 and c0 as 0$/;"	m	struct:cnn::TreeLSTMBuilder
hash	ext/dialogue/attention_with_intention.h	/^    vector<int> hash; $/;"	m	class:cnn::ClsBasedMultiSource_LinearEncoder
hash_embedding_spkfirst	cnn/expr-xtra.cc	/^vector<Expression> hash_embedding_spkfirst(const vector<vector<int>>& source, ComputationGraph& cg, LookupParameters* p_cs, int direct_order, int hash_size)$/;"	f
hashing	cnn/data-util.cc	/^vector<unsigned int> hashing(const vector<int>& obs, int direct_order, int hash_size)$/;"	f
hd	cnn/training.h	/^  std::vector<ShadowParameters> hd; \/\/ History of deltas$/;"	m	struct:cnn::AdadeltaTrainer
head	cnn/rnn.h	/^  std::vector<RNNPointer> head; \/\/ head[i] returns the head position$/;"	m	struct:cnn::RNNBuilder
hg	cnn/training.h	/^    cnn::real* hg; \/\/ History of gradients$/;"	m	struct:cnn::RmsPropWithMomentumTrainer
hg	cnn/training.h	/^  std::vector<ShadowParameters> hg; \/\/ History of gradients$/;"	m	struct:cnn::AdadeltaTrainer
hg	cnn/training.h	/^  std::vector<cnn::real> hg; \/\/ History of gradients$/;"	m	struct:cnn::RmsPropTrainer
hidden_dim	cnn/gru.h	/^  unsigned hidden_dim;$/;"	m	struct:cnn::GRUBuilder
hidden_dim	ext/dialogue/attention_with_intention.h	/^    vector<unsigned> hidden_dim;$/;"	m	class:cnn::DynamicMemoryNetDialogue
hidden_dim	ext/dialogue/dialogue.h	/^    vector<unsigned int> hidden_dim;$/;"	m	class:cnn::DialogueBuilder
hidden_dim	ext/encdec/encdec.h	/^    vector<unsigned> hidden_dim;$/;"	m	class:cnn::EncModel
hierarchical_ngram_clustering	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::hierarchical_ngram_clustering(variables_map vm, const CorpusWithClassId& test, Dict& sd)$/;"	f	class:TrainProcess
hinge	cnn/expr.cc	/^Expression hinge(const Expression& x, const unsigned* pindex, cnn::real m) { return Expression(x.pg, x.pg->add_function<Hinge>({x.i}, pindex, m)); }$/;"	f	namespace:cnn::expr
hinge	cnn/expr.cc	/^Expression hinge(const Expression& x, unsigned index, cnn::real m) { return Expression(x.pg, x.pg->add_function<Hinge>({ x.i }, index, m)); }$/;"	f	namespace:cnn::expr
hirearchical_clustering_main_body	ext/trainer/train_proc_wrapper.h	/^int hirearchical_clustering_main_body(variables_map vm)$/;"	f
history	examples/cxtattentional.h	/^    Expression history;$/;"	m	struct:cnn::CxtAttentionalModel
hld	cnn/training.h	/^  std::vector<ShadowLookupParameters> hld;$/;"	m	struct:cnn::AdadeltaTrainer
hlg	cnn/training.h	/^    std::vector<cnn::real* > hlg;$/;"	m	struct:cnn::RmsPropWithMomentumTrainer
hlg	cnn/training.h	/^  std::vector<ShadowLookupParameters> hlg;$/;"	m	struct:cnn::AdadeltaTrainer
hlg	cnn/training.h	/^  std::vector<std::vector<cnn::real> > hlg;$/;"	m	struct:cnn::RmsPropTrainer
huber_distance	cnn/expr.cc	/^Expression huber_distance(const Expression& x, const Expression& y, cnn::real c) { return Expression(x.pg, x.pg->add_function<HuberDistance>({x.i, y.i}, c)); }$/;"	f	namespace:cnn::expr
i	cnn/expr.h	/^  VariableIndex i;$/;"	m	struct:cnn::expr::Expression
i	cnn/functors.h	/^  int i;$/;"	m	struct:cnn::FEuclideanBackward
i_P	examples/attentional.h	/^    Expression i_P;$/;"	m	struct:cnn::AttentionalModel
i_P	examples/regattentional.h	/^    Expression i_P;$/;"	m	struct:cnn::RegAttentionalModel
i_Q	examples/attentional.h	/^    Expression i_Q;$/;"	m	struct:cnn::AttentionalModel
i_Q	examples/regattentional.h	/^    Expression i_Q, i_Qa;$/;"	m	struct:cnn::RegAttentionalModel
i_Q	ext/dialogue/attention_with_intention.h	/^    Expression i_Wa, i_va, i_Q;$/;"	m	class:cnn::AttentionWithIntention
i_Q	ext/dialogue/attention_with_intention.h	/^    Expression i_Wa, i_va, i_Q;$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_Qa	examples/regattentional.h	/^    Expression i_Q, i_Qa;$/;"	m	struct:cnn::RegAttentionalModel
i_R	examples/attentional.h	/^    Expression i_R;$/;"	m	struct:cnn::AttentionalModel
i_R	examples/cxtattentional.h	/^    Expression i_R;$/;"	m	struct:cnn::CxtAttentionalModel
i_R	examples/regattentional.h	/^    Expression i_R;$/;"	m	struct:cnn::RegAttentionalModel
i_R	ext/dialogue/attention_with_intention.h	/^    Expression i_R, i_bias;$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_R	ext/dialogue/cxtencdec.h	/^    Expression i_R;$/;"	m	class:cnn::CxtEncDecModel
i_R	ext/dialogue/cxtencdec.h	/^    Expression i_R;$/;"	m	class:cnn::Seq2SeqEncDecModel
i_R	ext/dialogue/dialogue.h	/^    Expression i_bias, i_R;$/;"	m	class:cnn::DialogueBuilder
i_Ta	examples/attentional.h	/^    Expression i_Ta;$/;"	m	struct:cnn::AttentionalModel
i_Ta	examples/regattentional.h	/^    Expression i_Ta;$/;"	m	struct:cnn::RegAttentionalModel
i_U	ext/dialogue/attention_with_intention.h	/^    Expression i_U;$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_U	ext/dialogue/dialogue.h	/^    Expression i_U;$/;"	m	class:cnn::DialogueBuilder
i_U	ext/encdec/encdec.h	/^    Expression i_U;$/;"	m	class:cnn::EncModel
i_Ua	examples/attentional.h	/^    Expression i_Ua;$/;"	m	struct:cnn::AttentionalModel
i_Ua	examples/regattentional.h	/^    Expression i_Ua;$/;"	m	struct:cnn::RegAttentionalModel
i_Wa	examples/attentional.h	/^    Expression i_Wa;$/;"	m	struct:cnn::AttentionalModel
i_Wa	examples/regattentional.h	/^    Expression i_Wa;$/;"	m	struct:cnn::RegAttentionalModel
i_Wa	ext/dialogue/attention_with_intention.h	/^    Expression i_Wa, i_va, i_Q;$/;"	m	class:cnn::AttentionWithIntention
i_Wa	ext/dialogue/attention_with_intention.h	/^    Expression i_Wa, i_va, i_Q;$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_Wa	ext/dialogue/attention_with_intention.h	/^    Expression i_Wa, i_va;$/;"	m	class:cnn::AttMultiSource_LinearEncoder
i_Wa_local	ext/dialogue/attention_with_intention.h	/^    Expression i_va_local, i_Wa_local, i_ba_local;$/;"	m	class:cnn::AWI_LocalGeneralInputFeeding
i_Wa_local	ext/dialogue/attention_with_intention.h	/^    Expression i_va_local, i_Wa_local, i_ba_local;$/;"	m	class:cnn::AttMultiSource_LinearEncoder
i_att_gate_A	ext/dialogue/attention_with_intention.h	/^    Expression i_att_gate_A, i_att_gate_b, v_att_gate_b;$/;"	m	class:cnn::GatedAttention
i_att_gate_b	ext/dialogue/attention_with_intention.h	/^    Expression i_att_gate_A, i_att_gate_b, v_att_gate_b;$/;"	m	class:cnn::GatedAttention
i_ba_local	ext/dialogue/attention_with_intention.h	/^    Expression i_va_local, i_Wa_local, i_ba_local;$/;"	m	class:cnn::AWI_LocalGeneralInputFeeding
i_ba_local	ext/dialogue/attention_with_intention.h	/^    Expression i_va_local, i_Wa_local, i_ba_local;$/;"	m	class:cnn::AttMultiSource_LinearEncoder
i_bias	examples/attentional.h	/^    Expression i_bias;$/;"	m	struct:cnn::AttentionalModel
i_bias	examples/cxtattentional.h	/^    Expression i_bias;$/;"	m	struct:cnn::CxtAttentionalModel
i_bias	examples/regattentional.h	/^    Expression i_bias;$/;"	m	struct:cnn::RegAttentionalModel
i_bias	ext/dialogue/attention_with_intention.h	/^    Expression i_R, i_bias;$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_bias	ext/dialogue/dialogue.h	/^    Expression i_bias, i_R;$/;"	m	class:cnn::DialogueBuilder
i_cls	cnn/approximator.h	/^        Expression i_cls, i_cls_bias;$/;"	m	class:cnn::ClsBasedBuilder
i_cls_bias	cnn/approximator.h	/^        Expression i_cls, i_cls_bias;$/;"	m	class:cnn::ClsBasedBuilder
i_cxt2dec_w	ext/dialogue/dialogue.h	/^    Expression i_cxt2dec_w;$/;"	m	class:cnn::DialogueBuilder
i_cxt2dec_w	ext/encdec/encdec.h	/^    Expression i_cxt2dec_w;$/;"	m	class:cnn::EncModel
i_cxt_to_decoder	ext/dialogue/attention_with_intention.h	/^    Expression i_cxt_to_decoder, i_enc_to_intention;$/;"	m	class:cnn::MultiSource_LinearEncoder
i_cxt_to_decoder	ext/dialogue/attention_with_intention.h	/^    Expression i_cxt_to_decoder;$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_cxt_to_decoder	ext/ir/ir.h	/^        Expression i_cxt_to_decoder, i_enc_to_intention;$/;"	m	class:cnn::ClassificationEncoderDecoder
i_cxt_to_decoder_bias	ext/dialogue/attention_with_intention.h	/^    Expression i_cxt_to_decoder_bias;  \/\/ for affine transformation of context to fact encoder$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_cxt_to_encoder	ext/dialogue/attention_with_intention.h	/^    Expression i_cxt_to_encoder;$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_cxt_to_encoder_bias	ext/dialogue/attention_with_intention.h	/^    Expression i_cxt_to_encoder_bias;  \/\/ for affine transformation of context to fact encoder$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_emb2enc	ext/dialogue/attention_with_intention.h	/^    Expression   i_emb2enc;$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
i_emb2enc	ext/dialogue/attention_with_intention.h	/^    Expression   i_emb2enc;$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
i_emb2enc_b	ext/dialogue/attention_with_intention.h	/^    Expression   i_emb2enc_b;           \/\/\/ the bias that is to be applied to each sentence$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
i_emb2enc_b	ext/dialogue/attention_with_intention.h	/^    Expression   i_emb2enc_b;           \/\/\/ the bias that is to be applied to each sentence$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
i_emb2enc_b_all_words	ext/dialogue/attention_with_intention.h	/^    Expression   i_emb2enc_b_all_words; \/\/\/ the bias that is to be applied to every word$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
i_emb2enc_b_all_words	ext/dialogue/attention_with_intention.h	/^    Expression   i_emb2enc_b_all_words; \/\/\/ the bias that is to be applied to every word$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
i_enc_to_intention	ext/dialogue/attention_with_intention.h	/^    Expression i_cxt_to_decoder, i_enc_to_intention;$/;"	m	class:cnn::MultiSource_LinearEncoder
i_enc_to_intention	ext/ir/ir.h	/^        Expression i_cxt_to_decoder, i_enc_to_intention;$/;"	m	class:cnn::ClassificationEncoderDecoder
i_errs	ext/dialogue/dialogue_process.h	/^        vector<Expression> i_errs; $/;"	m	class:cnn::HREDModel
i_errs	ext/dialogue/dialogue_process.h	/^        vector<Expression> i_errs;$/;"	m	class:cnn::DialogueSeq2SeqModel
i_fact_encoder_state	ext/dialogue/attention_with_intention.h	/^    Expression i_fact_encoder_state;$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_fact_encoder_state_bias	ext/dialogue/attention_with_intention.h	/^    Expression i_fact_encoder_state_bias;  \/\/ for affine transformation of fact states$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_fact_encoder_state_to_cxt	ext/dialogue/attention_with_intention.h	/^    Expression i_fact_encoder_state_to_cxt;$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_fact_encoder_state_to_cxt_bias	ext/dialogue/attention_with_intention.h	/^    Expression i_fact_encoder_state_to_cxt_bias;  \/\/ for affine transformation of fact states to context$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_glb_me_feature	ext/dialogue/attention_with_intention.h	/^    Expression i_glb_me_feature;     \/\/\/ computed global me feature$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch
i_global_me_weight	ext/dialogue/attention_with_intention.h	/^    Expression i_global_me_weight;$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch
i_h0	examples/attentional.h	/^    std::vector<Expression> i_h0;$/;"	m	struct:cnn::AttentionalModel
i_h0	examples/cxtattentional.h	/^    std::vector<Expression> i_h0;  \/\/ for target even history$/;"	m	struct:cnn::CxtAttentionalModel
i_h0	examples/regattentional.h	/^    std::vector<Expression> i_h0;$/;"	m	struct:cnn::RegAttentionalModel
i_h0	ext/dialogue/attention_with_intention.h	/^    vector<Expression> i_h0;$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_h0	ext/dialogue/dialogue.h	/^    vector<Expression> i_h0;$/;"	m	class:cnn::DialogueBuilder
i_h0	ext/encdec/encdec.h	/^    vector<Expression> i_h0;$/;"	m	class:cnn::EncModel
i_max_ent_obs	ext/dialogue/attention_with_intention.h	/^    Expression        i_max_ent_obs;$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
i_max_ent_obs	ext/dialogue/attention_with_intention.h	/^    Expression        i_max_ent_obs;$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
i_scale	ext/dialogue/attention_with_intention.h	/^    Expression i_scale; $/;"	m	class:cnn::AWI_LocalGeneralInputFeeding
i_scale	ext/dialogue/attention_with_intention.h	/^    Expression i_scale;$/;"	m	class:cnn::AWI_GeneralInputFeeding
i_scale	ext/dialogue/attention_with_intention.h	/^    Expression i_scale;$/;"	m	class:cnn::AttMultiSource_LinearEncoder
i_scale	ext/dialogue/attention_with_intention.h	/^    Expression i_scale;$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_sm0	examples/cxtattentional.h	/^    Expression i_sm0;  \/\/ the first input to decoder, even before observed$/;"	m	struct:cnn::CxtAttentionalModel
i_sm0	ext/dialogue/attention_with_intention.h	/^    Expression i_sm0;  \/\/ the first input to decoder, even before observed$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_sm0	ext/dialogue/dialogue.h	/^    Expression i_sm0;  \/\/ the first input to decoder, even before observed$/;"	m	class:cnn::DialogueBuilder
i_sm0	ext/encdec/encdec.h	/^    Expression i_sm0;  \/\/ the first input to decoder, even before observed$/;"	m	class:cnn::EncModel
i_src_idx	examples/attentional.h	/^    Expression i_src_idx;$/;"	m	struct:cnn::AttentionalModel
i_src_idx	examples/cxtattentional.h	/^    Expression i_src_idx;$/;"	m	struct:cnn::CxtAttentionalModel
i_src_len	examples/attentional.h	/^    Expression i_src_len;$/;"	m	struct:cnn::AttentionalModel
i_src_len	examples/cxtattentional.h	/^    Expression i_src_len;$/;"	m	struct:cnn::CxtAttentionalModel
i_tgt2cxt	ext/dialogue/attention_with_intention.h	/^    Expression i_tgt2cxt;$/;"	m	class:cnn::AttentionWithIntention
i_tgt2enc_b	ext/dialogue/attention_with_intention.h	/^        vector<Expression> i_tgt2enc_b, i_tgt2enc_w;$/;"	m	class:cnn::AWI_Bilinear
i_tgt2enc_w	ext/dialogue/attention_with_intention.h	/^        vector<Expression> i_tgt2enc_b, i_tgt2enc_w;$/;"	m	class:cnn::AWI_Bilinear
i_uax	examples/attentional.h	/^    Expression i_uax;$/;"	m	struct:cnn::AttentionalModel
i_uax	examples/cxtattentional.h	/^    Expression i_uax; $/;"	m	struct:cnn::CxtAttentionalModel
i_uax	examples/regattentional.h	/^    Expression i_uax;$/;"	m	struct:cnn::RegAttentionalModel
i_va	examples/attentional.h	/^    Expression i_va;$/;"	m	struct:cnn::AttentionalModel
i_va	examples/regattentional.h	/^    Expression i_va;$/;"	m	struct:cnn::RegAttentionalModel
i_va	ext/dialogue/attention_with_intention.h	/^    Expression i_Wa, i_va, i_Q;$/;"	m	class:cnn::AttentionWithIntention
i_va	ext/dialogue/attention_with_intention.h	/^    Expression i_Wa, i_va, i_Q;$/;"	m	class:cnn::DynamicMemoryNetDialogue
i_va	ext/dialogue/attention_with_intention.h	/^    Expression i_Wa, i_va;$/;"	m	class:cnn::AttMultiSource_LinearEncoder
i_va_local	ext/dialogue/attention_with_intention.h	/^    Expression i_va_local, i_Wa_local, i_ba_local;$/;"	m	class:cnn::AWI_LocalGeneralInputFeeding
i_va_local	ext/dialogue/attention_with_intention.h	/^    Expression i_va_local, i_Wa_local, i_ba_local;$/;"	m	class:cnn::AttMultiSource_LinearEncoder
i_zero	ext/dialogue/attention_with_intention.h	/^    Expression i_zero;$/;"	m	class:cnn::AWI_GeneralInputFeeding
i_zero	ext/dialogue/attention_with_intention.h	/^    Expression i_zero;$/;"	m	class:cnn::AWI_LocalGeneralInputFeeding
i_zero	ext/dialogue/attention_with_intention.h	/^    Expression i_zero;$/;"	m	class:cnn::AttMultiSource_LinearEncoder
i_zero	ext/dialogue/attention_with_intention.h	/^    Expression i_zero;$/;"	m	class:cnn::MultiSource_LinearEncoder
i_zero_emb	ext/dialogue/attention_with_intention.h	/^    Expression i_zero_emb; \/\/\/ Expresison for embedding of zeros in the embedding space$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
i_zero_emb	ext/dialogue/attention_with_intention.h	/^    Expression i_zero_emb; \/\/\/ Expresison for embedding of zeros in the embedding space$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
id2str	ext/trainer/train_proc.h	/^cnn::stId2String<string> id2str;$/;"	v
incremental_forward	cnn/cnn.cc	/^const Tensor& ComputationGraph::incremental_forward() { return ee->incremental_forward(); }$/;"	f	class:cnn::ComputationGraph
incremental_forward	cnn/exec.cc	/^const Tensor& SimpleExecutionEngine::incremental_forward() {$/;"	f	class:cnn::SimpleExecutionEngine
incremental_forward	cnn/exec.cc	/^const Tensor& SimpleExecutionEngine::incremental_forward(VariableIndex i) {$/;"	f	class:cnn::SimpleExecutionEngine
ind	cnn/nodes.h	/^  mutable std::vector<unsigned> ind;$/;"	m	struct:cnn::MaxPooling1D
index	cnn/param-nodes.h	/^  unsigned index;$/;"	m	struct:cnn::LookupNode
indices	cnn/param-nodes.h	/^  std::vector<unsigned> indices;$/;"	m	struct:cnn::LookupNode
info_arch	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	/^char const* info_arch = "INFO" ":" "arch[" ARCHITECTURE_ID "]";$/;"	v
info_arch	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	/^char const* info_arch = "INFO" ":" "arch[" ARCHITECTURE_ID "]";$/;"	v
info_compiler	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	/^char const* info_compiler = "INFO" ":" "compiler[" COMPILER_ID "]";$/;"	v
info_compiler	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	/^char const* info_compiler = "INFO" ":" "compiler[" COMPILER_ID "]";$/;"	v
info_platform	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	/^char const* info_platform = "INFO" ":" "platform[" PLATFORM_ID "]";$/;"	v
info_platform	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	/^char const* info_platform = "INFO" ":" "platform[" PLATFORM_ID "]";$/;"	v
info_version	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	/^char const info_version[] = {$/;"	v
info_version	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	/^char const info_version[] = {$/;"	v
init	ext/lda/lda.h	/^ldaModel* ldaModel::init(variables_map vm)$/;"	f	class:ldaModel
init_test	ext/lda/lda.h	/^int ldaModel::init_test()$/;"	f	class:ldaModel
init_train	ext/lda/lda.h	/^int ldaModel::init_train()$/;"	f	class:ldaModel
init_word_embedding	ext/dialogue/dialogue.h	/^    void init_word_embedding(const map<int, vector<cnn::real>> & vWordEmbedding)$/;"	f	class:cnn::DialogueBuilder
init_word_embedding	ext/dialogue/dialogue_process.h	/^        void init_word_embedding(const map<int, vector<cnn::real>> &vWordEmbedding)$/;"	f	class:cnn::DialogueProcessInfo
initialise	examples/attentional.cc	/^void initialise(Model &model, const string &filename)$/;"	f
initialise	examples/rnnlm2.cc	/^void initialise(Model &model, const string &filename)$/;"	f
initialise	examples/rnnlm2_cls_based.cc	/^void initialise(Model &model, const string &filename)$/;"	f
input	cnn/expr.cc	/^Expression input(ComputationGraph& g, cnn::real s) { return Expression(&g, g.add_input(s)); }$/;"	f	namespace:cnn::expr
input	cnn/expr.cc	/^Expression input(ComputationGraph& g, const Dim& d, const std::vector<cnn::real>& pdata) { return Expression(&g, g.add_input(d, pdata)); }$/;"	f	namespace:cnn::expr
input	cnn/expr.cc	/^Expression input(ComputationGraph& g, const Dim& d, const std::vector<cnn::real>* pdata) { return Expression(&g, g.add_input(d, pdata)); }$/;"	f	namespace:cnn::expr
input	cnn/expr.cc	/^Expression input(ComputationGraph& g, const cnn::real *ps) { return Expression(&g, g.add_input(ps)); }$/;"	f	namespace:cnn::expr
input_dim	cnn/approximator.h	/^        unsigned input_dim;$/;"	m	class:cnn::ClsBasedBuilder
input_dims	cnn/dnn.h	/^        std::vector<unsigned> input_dims;  \/\/\/ input dimension at each layer$/;"	m	class:cnn::DNNBuilder
input_dims	cnn/rnn.h	/^  std::vector<unsigned> input_dims;  \/\/\/ input dimension at each layer$/;"	m	struct:cnn::RNNBuilder
internal	cnn/simd-functors.h	/^namespace Eigen { namespace internal {$/;"	n	namespace:Eigen
interpolation_wgt	ext/ngram/ngram.h	/^    cnn::real interpolation_wgt; $/;"	m	class:nGram
invalidate	cnn/cnn.cc	/^void ComputationGraph::invalidate() { ee->invalidate(); }$/;"	f	class:cnn::ComputationGraph
invalidate	cnn/exec.cc	/^void SimpleExecutionEngine::invalidate() {$/;"	f	class:cnn::SimpleExecutionEngine
is_close	cnn/expr-xtra.h	/^inline bool is_close(cnn::real a, cnn::real b) {$/;"	f
is_close	cnn/rnnem.cc	/^inline bool is_close(cnn::real a, cnn::real b) {$/;"	f
is_nan	cnn/data-util.cc	/^bool is_nan( const cnn::real & value)$/;"	f
is_valid	cnn/tensor.h	/^  inline bool is_valid() const {$/;"	f	struct:cnn::Tensor
is_valid	cnn/training.cc	/^bool is_valid(const Eigen::MatrixBase<Derived>& x) {$/;"	f	namespace:cnn
iscale	ext/dialogue/attention_with_intention.h	/^    cnn::real iscale; $/;"	m	class:cnn::ClsBasedMultiSource_LinearEncoder
join	cnn/data-util.h	/^    void join() { m_Thread.join(); }$/;"	f	class:DataReader
k	cnn/conv.h	/^  unsigned k;$/;"	m	struct:cnn::KMaxPooling
kEOS	examples/encdec.cc	/^int kEOS;$/;"	v
kEOS	examples/poisson-regression.cc	/^int kEOS;$/;"	v
kEOS	examples/rnnlm-aevb.cc	/^int kEOS;$/;"	v
kEOS	examples/rnnlm.cc	/^int kEOS;$/;"	v
kEOS	examples/rnnlm2.cc	/^int kEOS;$/;"	v
kEOS	examples/rnnlm2_cls_based.cc	/^int kEOS;$/;"	v
kEOS	examples/skiprnnlm.cc	/^int kEOS;$/;"	v
kEOS	examples/tag-bilstm.cc	/^int kEOS;$/;"	v
kEOS	examples/textcat.cc	/^int kEOS;$/;"	v
kNONE	examples/tag-bilstm.cc	/^int kNONE;$/;"	v
kSCALAR_MINUSONE	cnn/cnn.cc	/^cnn::real* kSCALAR_MINUSONE;$/;"	m	namespace:cnn	file:
kSCALAR_ONE	cnn/cnn.cc	/^cnn::real* kSCALAR_ONE;$/;"	m	namespace:cnn	file:
kSCALAR_ONE_OVER_INT	cnn/cnn.cc	/^std::vector<cnn::real*> kSCALAR_ONE_OVER_INT;$/;"	m	namespace:cnn	file:
kSCALAR_ZERO	cnn/cnn.cc	/^cnn::real* kSCALAR_ZERO;$/;"	m	namespace:cnn	file:
kSOS	examples/encdec.cc	/^int kSOS;$/;"	v
kSOS	examples/poisson-regression.cc	/^int kSOS;$/;"	v
kSOS	examples/rnnlm-aevb.cc	/^int kSOS;$/;"	v
kSOS	examples/rnnlm.cc	/^int kSOS;$/;"	v
kSOS	examples/rnnlm2.cc	/^int kSOS;$/;"	v
kSOS	examples/rnnlm2_cls_based.cc	/^int kSOS;$/;"	v
kSOS	examples/skiprnnlm.cc	/^int kSOS;$/;"	v
kSOS	examples/tag-bilstm.cc	/^int kSOS;$/;"	v
kSOS	examples/textcat.cc	/^int kSOS;$/;"	v
kSRC_EOS	examples/attentional.cc	/^int kSRC_EOS;$/;"	v
kSRC_EOS	examples/embed-cl.cc	/^int kSRC_EOS;$/;"	v
kSRC_EOS	examples/mem_seq2seq_encdec.cc	/^int kSRC_EOS;$/;"	v
kSRC_EOS	examples/seq2seq_encdec.cc	/^int kSRC_EOS;$/;"	v
kSRC_EOS	ext/trainer/train_proc.h	/^int kSRC_EOS;$/;"	v
kSRC_SOS	examples/attentional.cc	/^int kSRC_SOS;$/;"	v
kSRC_SOS	examples/embed-cl.cc	/^int kSRC_SOS;$/;"	v
kSRC_SOS	examples/mem_seq2seq_encdec.cc	/^int kSRC_SOS;$/;"	v
kSRC_SOS	examples/seq2seq_encdec.cc	/^int kSRC_SOS;$/;"	v
kSRC_SOS	ext/trainer/train_proc.h	/^int kSRC_SOS;$/;"	v
kTGT_EOS	examples/attentional.cc	/^int kTGT_EOS;$/;"	v
kTGT_EOS	examples/mem_seq2seq_encdec.cc	/^int kTGT_EOS;$/;"	v
kTGT_EOS	examples/seq2seq_encdec.cc	/^int kTGT_EOS;$/;"	v
kTGT_EOS	ext/trainer/train_proc.h	/^int kTGT_EOS;$/;"	v
kTGT_SOS	examples/attentional.cc	/^int kTGT_SOS;$/;"	v
kTGT_SOS	examples/mem_seq2seq_encdec.cc	/^int kTGT_SOS;$/;"	v
kTGT_SOS	examples/seq2seq_encdec.cc	/^int kTGT_SOS;$/;"	v
kTGT_SOS	ext/trainer/train_proc.h	/^int kTGT_SOS;$/;"	v
kTRG_EOS	examples/embed-cl.cc	/^int kTRG_EOS;$/;"	v
kTRG_SOS	examples/embed-cl.cc	/^int kTRG_SOS;$/;"	v
k_fold_rows	examples/convmodel.h	/^        int k_fold_rows;$/;"	m	struct:cnn::ConvLayer
k_fold_rows	examples/textcat.cc	/^  int k_fold_rows;$/;"	m	struct:ConvLayer	file:
kmax_pooling	cnn/expr.cc	/^Expression kmax_pooling(const Expression& x, unsigned k) { return Expression(x.pg, x.pg->add_function<KMaxPooling>({x.i}, k)); }$/;"	f	namespace:cnn::expr
kmh_ngram	cnn/expr.cc	/^Expression kmh_ngram(const Expression& x, unsigned n) { return Expression(x.pg, x.pg->add_function<KMHNGram>({x.i}, n)); }$/;"	f	namespace:cnn::expr
l1_distance	cnn/expr.cc	/^Expression l1_distance(const Expression& x, const Expression& y) { return Expression(x.pg, x.pg->add_function<L1Distance>({x.i, y.i})); }$/;"	f	namespace:cnn::expr
l2rbuilder	examples/tag-bilstm.cc	/^  Builder l2rbuilder;$/;"	m	struct:RNNLanguageModel	file:
lagging	cnn/rnn.h	/^  bool lagging;$/;"	m	struct:cnn::SimpleRNNBuilder
lambda	cnn/functors.h	/^    cnn::real *lambda;$/;"	m	struct:cnn::FL2SGDUpdatePtrArguments
lambda	cnn/functors.h	/^    cnn::real lambda;$/;"	m	struct:cnn::FL2SGDMomentumUpdate
lambda	cnn/functors.h	/^    cnn::real lambda;$/;"	m	struct:cnn::FL2SGDMomentumWithDenUpdate
lambda	cnn/functors.h	/^    cnn::real lambda;$/;"	m	struct:cnn::FL2SGDUpdate
lambda	cnn/training.h	/^  cnn::real lambda; \/\/ weight regularization (l2)$/;"	m	struct:cnn::Trainer
lambda	examples/attentional.cc	/^cnn::real lambda;$/;"	v
lambda	ext/trainer/train_proc.h	/^cnn::real lambda = 1e-6;$/;"	v
last	cnn/data-util.h	/^    T last;$/;"	m	struct:triplet
last_context_exp	ext/dialogue/dialogue.h	/^    vector<Expression> last_context_exp;  \/\/\/ expression to the last context hidden state$/;"	m	class:cnn::DialogueBuilder
last_cxt_s	ext/dialogue/dialogue.h	/^    vector<cnn::real*> last_cxt_s;  \/\/\/ memory of context history for LSTM including h and c, use this for initialization of intent RNN$/;"	m	class:cnn::DialogueBuilder
last_decoder_s	ext/dialogue/dialogue.h	/^    vector<vector<cnn::real>> last_decoder_s;  \/\/\/ memory of target side decoder history for LSTM including h and c, use this for initialization of source side RNN$/;"	m	class:cnn::DialogueBuilder
layers	cnn/deep-lstm.h	/^  unsigned layers;$/;"	m	struct:cnn::DeepLSTMBuilder
layers	cnn/dnn.h	/^        unsigned layers;  \/\/\/ number of layers$/;"	m	class:cnn::DNNBuilder
layers	cnn/rnn.h	/^  unsigned layers;  \/\/\/ number of layers$/;"	m	struct:cnn::RNNBuilder
layers	cnn/rnnem.h	/^  long layers;$/;"	m	struct:cnn::NMNBuilder
layers	cnn/treelstm.h	/^  unsigned layers;$/;"	m	struct:cnn::TreeLSTMBuilder
layers	examples/attentional.h	/^    size_t layers; $/;"	m	struct:cnn::AttentionalModel
layers	examples/cxtattentional.h	/^    size_t layers; $/;"	m	struct:cnn::CxtAttentionalModel
layers	examples/regattentional.h	/^    size_t layers; $/;"	m	struct:cnn::RegAttentionalModel
layers	ext/dialogue/attention_with_intention.h	/^    vector<size_t> layers;$/;"	m	class:cnn::DynamicMemoryNetDialogue
layers	ext/dialogue/dialogue.h	/^    vector<unsigned int> layers;$/;"	m	class:cnn::DialogueBuilder
layers	ext/encdec/encdec.h	/^    size_t layers;$/;"	m	class:cnn::EncModel
ld	examples/textcat.cc	/^cnn::Dict ld;$/;"	v
ldaModel	ext/lda/lda.h	/^class ldaModel {$/;"	c
ldaModel	ext/lda/lda.h	/^ldaModel::ldaModel(const Corpus& training, const Corpus& test):$/;"	f	class:ldaModel
lda_test	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::lda_test(variables_map vm, const Corpus& test, Dict& sd)$/;"	f	class:TrainProcess
lda_train	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::lda_train(variables_map vm, const Corpus &training, const Corpus& test, Dict& sd)$/;"	f	class:TrainProcess
leq	cnn/expr-xtra.cc	/^Expression leq(const Expression &expr, cnn::real value, Expression &one, cnn::real epsilon) $/;"	f
levenshtein_distance	cnn/metric-util.cc	/^    int levenshtein_distance(const vector<std::string> &s1, const vector<std::string> &s2)$/;"	f	namespace:cnn::metric
lgBiLM	ext/ngram/ngram.h	/^    tBigram  lgBiLM;  \/\/\/ bigram$/;"	m	class:nGram
lgUniLM	ext/ngram/ngram.h	/^    tUnigram lgUniLM;  \/\/\/ unigram$/;"	m	class:nGram
likelihood	ext/lda/lda.h	/^	std::vector<double> likelihood; \/\/ likelihood after each iteration$/;"	m	class:ldaModel
llhw	ext/lda/lda.h	/^double ldaModel::llhw() const$/;"	f	class:ldaModel
lm	cnn/training.h	/^  std::vector<ShadowLookupParameters> lm;$/;"	m	struct:cnn::AdamTrainer
load	cnn/model.h	/^    void load(Archive& ar, const unsigned int version) {$/;"	f	class:cnn::Model
load	cnn/model.h	/^  void load(Archive& ar, const unsigned int) {$/;"	f	struct:cnn::LookupParameters
load	cnn/tensor.h	/^  void load(Archive& ar, const unsigned int) {$/;"	f	struct:cnn::Tensor
load	ext/lda/lda.h	/^    template<class Archive> void load(Archive& ar, const unsigned int version) {$/;"	f	class:ldaModel
load_cls_info_from_file	ext/dialogue/attention_with_intention.h	/^    bool load_cls_info_from_file(string word2clsfn, string clsszefn, Dict& sd, Model& model)$/;"	f	class:cnn::ClsBasedMultiSource_LinearEncoder
load_cls_info_from_file	ext/dialogue/dialogue.h	/^    bool load_cls_info_from_file(string word2clsfn, string clsszefn, Dict& sd, Model& model){$/;"	f	class:cnn::DialogueBuilder
load_cls_info_from_file	ext/dialogue/dialogue_process.h	/^        void load_cls_info_from_file(string word2clsfn, string clsszefn, Dict& sd, Model& model)$/;"	f	class:cnn::DialogueProcessInfo
load_clssize_fn	examples/rnnlm2_cls_based.cc	/^void load_clssize_fn(string clsszefn, std::vector<int> & cls2size, std::vector<long>& acc_cls2size)$/;"	f
load_cnn_model	cnn/model.cc	/^void load_cnn_model(std::string filename, Model* model) {$/;"	f	namespace:cnn
load_ldaModel	ext/lda/lda.h	/^int ldaModel::load_ldaModel(const string & filename)$/;"	f	class:ldaModel
load_ldaModel	ext/lda/lda.h	/^int ldaModel::load_ldaModel(int iter)$/;"	f	class:ldaModel
load_word2cls_fn	cnn/approximator.cc	/^    void ClsBasedBuilder::load_word2cls_fn(string word2clsfn, Dict& sd, std::vector<long>& wrd2cls, std::vector<long>& dict_wrd_id2within_class_id, std::vector<int> & cls2size)$/;"	f	class:cnn::ClsBasedBuilder
load_word2cls_fn	examples/rnnlm2_cls_based.cc	/^void load_word2cls_fn(string word2clsfn, Dict& sd, std::vector<long>& wrd2cls, std::vector<long>& dict_wrd_id2within_class_id)$/;"	f
local_attention_to	cnn/expr-xtra.cc	/^vector<Expression> local_attention_to(ComputationGraph& cg, const vector<unsigned>& v_slen,$/;"	f
log	cnn/expr.cc	/^Expression log(const Expression& x) { return Expression(x.pg, x.pg->add_function<Log>({x.i})); }$/;"	f	namespace:cnn::expr
log_softmax	cnn/expr.cc	/^Expression log_softmax(const Expression& x) { return Expression(x.pg, x.pg->add_function<LogSoftmax>({x.i})); }$/;"	f	namespace:cnn::expr
log_softmax	cnn/expr.cc	/^Expression log_softmax(const Expression& x, const std::vector<unsigned>& d) { return Expression(x.pg, x.pg->add_function<RestrictedLogSoftmax>({x.i}, d)); }$/;"	f	namespace:cnn::expr
logicId2phyId	cnn/dict.h	/^    std::vector<int> logicId2phyId; \/\/\/ logic id is in sequence order$/;"	m	class:cnn::stId2String
logistic	cnn/expr.cc	/^Expression logistic(const Expression& x) { return Expression(x.pg, x.pg->add_function<LogisticSigmoid>({x.i})); }$/;"	f	namespace:cnn::expr
logsoftmax	cnn/functors.h	/^void logsoftmax(int row, int col, const ElemType* a, ElemType* v, const bool isColWise)$/;"	f	namespace:cnn
logsumexp	cnn/expr.h	/^inline Expression logsumexp(const T& xs) { return detail::f<LogSumExp>(xs); }$/;"	f	namespace:cnn::expr
logsumexp	cnn/expr.h	/^inline Expression logsumexp(const std::initializer_list<Expression>& xs) { return detail::f<LogSumExp>(xs); }$/;"	f	namespace:cnn::expr
logsumexp	cnn/nodes.cc	/^EIGEN_STRONG_INLINE cnn::real logsumexp(const T& x) {$/;"	f	namespace:cnn
logsumexp	cnn/nodes.cc	/^EIGEN_STRONG_INLINE cnn::real logsumexp(const T& x, const vector<unsigned>& denom) {$/;"	f	namespace:cnn
logz	cnn/functors.h	/^  cnn::real logz;$/;"	m	struct:cnn::FLogSoftmaxNormalize
logz	cnn/functors.h	/^  cnn::real logz;$/;"	m	struct:cnn::FNegLogSoftmaxBackward
logz	cnn/functors.h	/^  cnn::real logz;$/;"	m	struct:cnn::FSoftmaxNormalize
logz	cnn/functors.h	/^  const cnn::real* logz;$/;"	m	struct:cnn::FPtrNegLogSoftmaxBackward
logz	cnn/simd-functors.h	/^  Scalar logz;$/;"	m	struct:cnn::scalar_nlsoftmax_backward_op
lookup	cnn/expr.cc	/^Expression lookup(ComputationGraph& g, LookupParameters* p, const std::vector<unsigned>& indices) { return Expression(&g, g.add_lookup(p, indices)); }$/;"	f	namespace:cnn::expr
lookup	cnn/expr.cc	/^Expression lookup(ComputationGraph& g, LookupParameters* p, const std::vector<unsigned>* pindices) { return Expression(&g, g.add_lookup(p, pindices)); }$/;"	f	namespace:cnn::expr
lookup	cnn/expr.cc	/^Expression lookup(ComputationGraph& g, LookupParameters* p, const unsigned* pindex) { return Expression(&g, g.add_lookup(p, pindex)); }$/;"	f	namespace:cnn::expr
lookup	cnn/expr.cc	/^Expression lookup(ComputationGraph& g, LookupParameters* p, unsigned index) { return Expression(&g, g.add_lookup(p, index)); }$/;"	f	namespace:cnn::expr
lookup_parameters_list	cnn/model.h	/^    const std::vector<LookupParameters*>& lookup_parameters_list() const { return lookup_params; }$/;"	f	class:cnn::Model
lookup_params	cnn/model.h	/^    std::vector<LookupParameters*> lookup_params;$/;"	m	class:cnn::Model
loss	examples/mp.cc	/^  cnn::real loss;$/;"	m	struct:SharedObject	file:
lparam_vars	cnn/treelstm.h	/^  std::vector<std::vector<Expression>> lparam_vars;$/;"	m	struct:cnn::TreeLSTMBuilder
lparams	cnn/treelstm.h	/^  std::vector<std::vector<LookupParameters*>> lparams;$/;"	m	struct:cnn::TreeLSTMBuilder
lv	cnn/training.h	/^  std::vector<ShadowLookupParameters> lv;$/;"	m	struct:cnn::AdamTrainer
m	cnn/training.h	/^  std::vector<ShadowParameters> m; \/\/ History of gradients$/;"	m	struct:cnn::AdamTrainer
m	examples/embed-cl.cc	/^  vector<Expression> m;$/;"	m	struct:Encoder	file:
m	examples/mp.cc	/^  Parameters* m;$/;"	m	struct:ModelParameters	file:
m	examples/mp.cc	/^  cnn::real m;$/;"	m	struct:SharedObject	file:
m_Corpus	cnn/data-util.h	/^    Corpus        m_Corpus;   \/\/\/ the corpsu;$/;"	m	class:DataReader
m_Filename	cnn/data-util.h	/^    string        m_Filename; \/\/\/ the file name$/;"	m	class:DataReader
m_Thread	cnn/data-util.h	/^    boost::thread m_Thread; $/;"	m	class:DataReader
m_align_dim	cnn/rnnem.h	/^  long m_align_dim;$/;"	m	struct:cnn::NMNBuilder
m_allStats	cnn/metric-util.h	/^    LossStats m_allStats;$/;"	m	class:BleuMetric
m_device_id	cnn/tensor.h	/^  int m_device_id; \/\/\/ the device where values are saved; -1 CPU, 0 and otherwise are GPUs$/;"	m	struct:cnn::Tensor
m_direct_order	ext/dialogue/attention_with_intention.h	/^    int m_direct_order; \/\/\/ max-entropy feature order$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
m_hash_size	ext/dialogue/attention_with_intention.h	/^    int m_hash_size; $/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
m_hypIndex	cnn/metric-util.h	/^    int m_hypIndex;$/;"	m	class:BleuMetric
m_ifs	cnn/data-util.h	/^    std::ifstream m_ifs;$/;"	m	class:DataReader
m_map_idf	ext/trainer/train_proc.h	/^    std::map<string, cnn::real> m_map_idf; \/\/\/ the dictionary for saving tfidf$/;"	m	class:TrainProcess
m_matchIndex	cnn/metric-util.h	/^    int m_matchIndex;$/;"	m	class:BleuMetric
m_mem_dim	cnn/rnnem.h	/^  long m_mem_dim;$/;"	m	struct:cnn::NMNBuilder
m_mem_size	cnn/rnnem.h	/^  long m_mem_size;$/;"	m	struct:cnn::NMNBuilder
m_pined_memory	ext/dialogue/dialogue.h	/^    cnn::real * m_pined_memory; \/\/\/ memory for serialization either on device or on host$/;"	m	class:cnn::DialogueBuilder
m_refIndex	cnn/metric-util.h	/^    int m_refIndex;$/;"	m	class:BleuMetric
m_time_embedding_weight	ext/dialogue/attention_with_intention.h	/^    map<size_t, map<size_t, tExpression>> m_time_embedding_weight;$/;"	m	class:cnn::MultiSource_LinearEncoder
main	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	/^int main(int argc, char* argv[])$/;"	f
main	build/CMakeFiles/2.8.11/CompilerIdC/CMakeCCompilerId.c	/^void main() {}$/;"	f
main	build/CMakeFiles/2.8.11/CompilerIdCXX/CMakeCXXCompilerId.cpp	/^int main(int argc, char* argv[])$/;"	f
main	examples/attentional.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/embed-cl.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/encdec.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/mem_seq2seq_encdec.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/mp.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/nlm.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/poisson-regression.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/rnnlm-aevb.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/rnnlm.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/rnnlm2.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/rnnlm2_cls_based.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/seq2seq_encdec.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/skiprnnlm.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/tag-bilstm.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/textcat.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/xor-xent.cc	/^int main(int argc, char** argv) {$/;"	f
main	examples/xor.cc	/^int main(int argc, char** argv) {$/;"	f
main_body	examples/attentional.cc	/^int main_body(variables_map vm, int repnumber)$/;"	f
main_body	ext/trainer/train_proc_wrapper.h	/^int main_body(variables_map vm, size_t nreplicate = 0, size_t decoder_additiona_input_to = 0, size_t mem_slots = MEM_SIZE)$/;"	f
make_triplet	cnn/data-util.h	/^triplet<T> make_triplet(const T &m1, const T &m2, const T &m3)$/;"	f
make_triplet_sentence	cnn/data-util.cc	/^SentenceTuple make_triplet_sentence(const Sentence& m1, const Sentence& m2, const Sentence& m3)$/;"	f
mapNumTurn2DialogId	cnn/data-util.h	/^    map<int, vector<int>> mapNumTurn2DialogId;$/;"	m	struct:__anon18
map_unk	cnn/dict.h	/^  bool map_unk; \/\/ if true, map unknown word to unk_id$/;"	m	class:cnn::stDict
margin	cnn/functors.h	/^  cnn::real margin;$/;"	m	struct:cnn::FPairwiseRankLoss
margin	cnn/nodes.h	/^  cnn::real margin;$/;"	m	struct:cnn::Hinge
margin	cnn/nodes.h	/^  cnn::real margin;$/;"	m	struct:cnn::PairwiseRankLoss
math	exp/lm/lm.py	/^import math$/;"	i
max	cnn/expr.cc	/^Expression max(const Expression& x, const Expression& y) { return Expression(x.pg, x.pg->add_function<Max>({x.i, y.i})); }$/;"	f	namespace:cnn::expr
max	cnn/expr.h	/^inline Expression max(const T& xs) { return detail::f<Max>(xs); }$/;"	f	namespace:cnn::expr
max	cnn/expr.h	/^inline Expression max(const std::initializer_list<Expression>& xs) { return detail::f<Max>(xs); }$/;"	f	namespace:cnn::expr
mb_allocate_on_cpu_only	cnn/aligned-mem-pool.h	/^  bool mb_allocate_on_cpu_only; $/;"	m	class:cnn::AlignedMemoryPool
mbsize	ext/trainer/train_proc.h	/^long mbsize = -1;$/;"	v
mdir	ext/lda/lda.h	/^	std::string mdir;				\/\/ ldaModel directory$/;"	m	class:ldaModel
mem	cnn/aligned-mem-pool.h	/^  void* mem;$/;"	m	class:cnn::AlignedMemoryPool
mem_nodes	cnn/init.cc	/^    AlignedMemoryPool<ALIGN>* mem_nodes= nullptr;   \/\/\/ for nodes allocation\/delocation. operation of new\/delete of each node has been overwritten to use this memory pool for speed-up$/;"	m	namespace:cnn	file:
metric	cnn/metric-util.cc	/^namespace cnn { namespace metric {$/;"	n	namespace:cnn	file:
metric	cnn/metric-util.h	/^    namespace metric {$/;"	n	namespace:cnn
middle	cnn/data-util.h	/^    T middle;$/;"	m	struct:triplet
min	cnn/expr.cc	/^Expression min(const Expression& x, const Expression& y) { return Expression(x.pg, x.pg->add_function<Min>({x.i, y.i})); }$/;"	f	namespace:cnn::expr
model	cnn/training.h	/^  Model* model;  \/\/ parameters and gradients live here$/;"	m	struct:cnn::Trainer
model	ext/dialogue/attention_with_intention.h	/^    Model model;$/;"	m	class:cnn::DynamicMemoryNetDialogue
model	ext/dialogue/dialogue.h	/^    Model model;$/;"	m	class:cnn::DialogueBuilder
model	ext/encdec/encdec.h	/^    Model model;$/;"	m	class:cnn::EncModel
model_filename	ext/ngram/ngram.h	/^    string model_filename;$/;"	m	class:nGram
momentum	cnn/functors.h	/^    cnn::real momentum;$/;"	m	struct:cnn::FL2SGDMomentumUpdate
momentum	cnn/functors.h	/^    cnn::real momentum;$/;"	m	struct:cnn::FL2SGDMomentumWithDenUpdate
momentum	cnn/training.h	/^    cnn::real momentum;$/;"	m	struct:cnn::RmsPropWithMomentumTrainer
momentum	cnn/training.h	/^  cnn::real momentum;$/;"	m	struct:cnn::MomentumSGDTrainer
msg	cnn/timing.h	/^  std::string msg;$/;"	m	struct:cnn::Timer
n	cnn/nodes.h	/^  unsigned n;  \/\/ width, n=2 for Karl's paper$/;"	m	struct:cnn::KMHNGram
nGram	ext/ngram/ngram.h	/^    nGram()$/;"	f	class:nGram
nGram	ext/ngram/ngram.h	/^class nGram$/;"	c
nInputDim	examples/convmodel.h	/^        unsigned nInputDim, nOutputDim;$/;"	m	struct:cnn::ConvNet
nOutputDim	examples/convmodel.h	/^        unsigned nInputDim, nOutputDim;$/;"	m	struct:cnn::ConvNet
n_hgs	cnn/cnn.cc	/^int n_hgs = 0;$/;"	m	namespace:cnn	file:
n_iters	ext/lda/lda.h	/^	int n_iters;	 				\/\/ Number of Gibbs sampling iterations$/;"	m	class:ldaModel
n_k	ext/lda/lda.h	/^	std::vector<int> n_k;						\/\/ number of words assigned to topic k = sum_w n_wk = sum_m n_mk$/;"	m	class:ldaModel
n_mks	ext/lda/lda.h	/^	std::vector< std::vector< std::pair<int, int> > > n_mks; \/\/sparse representation of n_mk: number of words assigned to topic k in document m$/;"	m	class:ldaModel
n_save	ext/lda/lda.h	/^	int n_save;			 			\/\/ Number of iters in between saving$/;"	m	class:ldaModel
n_topWords	ext/lda/lda.h	/^	int n_topWords; 				\/\/ Number of top words to be printed per topic$/;"	m	class:ldaModel
n_wk	ext/lda/lda.h	/^	std::vector<vector<int>> n_wk;					\/\/ number of times word w assigned to topic k$/;"	m	class:ldaModel
name	cnn/model.h	/^  std::string name;$/;"	m	struct:cnn::LookupParameters
name	cnn/model.h	/^  std::string name;$/;"	m	struct:cnn::Parameters
nbr_turns	ext/dialogue/dialogue_process.h	/^        int nbr_turns;$/;"	m	class:cnn::DialogueProcessInfo
ncls	cnn/approximator.h	/^        unsigned int ncls;$/;"	m	class:cnn::ClsBasedBuilder
ncls	examples/rnnlm2_cls_based.cc	/^  unsigned int ncls;$/;"	m	struct:RNNLanguageModel	file:
nd	cnn/dim.h	/^  unsigned int nd;$/;"	m	struct:cnn::Dim
ndEdfs	cnn/exec.h	/^  std::vector<Tensor> ndEdfs;$/;"	m	class:cnn::SimpleExecutionEngine
nd_m	ext/lda/lda.h	/^	int *nd_m;$/;"	m	class:ldaModel
ndims	cnn/dim.h	/^  inline unsigned int ndims() const { return nd; }$/;"	f	struct:cnn::Dim
new_graph	cnn/approximator.h	/^        void new_graph(ComputationGraph& cg) {$/;"	f	class:cnn::ClsBasedBuilder
new_graph	cnn/c2w.h	/^  void new_graph(ComputationGraph* cg) {$/;"	f	struct:cnn::C2WBuilder
new_graph	cnn/dnn.h	/^        void new_graph(ComputationGraph& cg) {$/;"	f	class:cnn::DNNBuilder
new_graph	cnn/rnn-state-machine.h	/^enum RNNOp {new_graph, start_new_sequence, add_input};$/;"	e	enum:cnn::RNNOp
new_graph	cnn/rnn.h	/^  void new_graph(ComputationGraph& cg) {$/;"	f	struct:cnn::RNNBuilder
new_graph_impl	cnn/approximator.cc	/^    void ClsBasedBuilder::new_graph_impl(ComputationGraph& cg) {$/;"	f	class:cnn::ClsBasedBuilder
new_graph_impl	cnn/deep-lstm.cc	/^void DeepLSTMBuilder::new_graph_impl(ComputationGraph& cg){$/;"	f	class:cnn::DeepLSTMBuilder
new_graph_impl	cnn/dglstm.cc	/^void DGLSTMBuilder::new_graph_impl(ComputationGraph& cg){$/;"	f	class:cnn::DGLSTMBuilder
new_graph_impl	cnn/dnn.cc	/^    void DNNBuilder::new_graph_impl(ComputationGraph& cg) {$/;"	f	class:cnn::DNNBuilder
new_graph_impl	cnn/gru.cc	/^void GRUBuilder::new_graph_impl(ComputationGraph& cg) {$/;"	f	class:cnn::GRUBuilder
new_graph_impl	cnn/lstm.cc	/^void LSTMBuilder::new_graph_impl(ComputationGraph& cg){$/;"	f	class:cnn::LSTMBuilder
new_graph_impl	cnn/rnn.cc	/^void SimpleRNNBuilder::new_graph_impl(ComputationGraph& cg) {$/;"	f	class:cnn::SimpleRNNBuilder
new_graph_impl	cnn/rnnem.cc	/^    void NMNBuilder::new_graph_impl(ComputationGraph& cg){$/;"	f	class:cnn::NMNBuilder
new_graph_impl	cnn/treelstm.cc	/^void TreeLSTMBuilder::new_graph_impl(ComputationGraph& cg){$/;"	f	class:cnn::TreeLSTMBuilder
newllhw	ext/lda/lda.h	/^double ldaModel::newllhw() const$/;"	f	class:ldaModel
nfxs	cnn/exec.h	/^  std::vector<Tensor> nfxs;$/;"	m	class:cnn::SimpleExecutionEngine
ngram_clustering	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::ngram_clustering(variables_map vm, const Corpus& test, Dict& sd)$/;"	f	class:TrainProcess
ngram_one_pass_clustering	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::ngram_one_pass_clustering(variables_map vm, const Corpus& test, Dict& sd)$/;"	f	class:TrainProcess
ngram_train	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::ngram_train(variables_map vm, const Corpus& test, Dict& sd)$/;"	f	class:TrainProcess
nodes	cnn/cnn.h	/^  std::vector<Node*> nodes;       \/\/ **stored in topological order**$/;"	m	struct:cnn::ComputationGraph
noise	cnn/expr.cc	/^Expression noise(const Expression& x, cnn::real stddev) { return Expression(x.pg, x.pg->add_function<GaussianNoise>({x.i}, stddev)); }$/;"	f	namespace:cnn::expr
non_zero_grads	cnn/model.h	/^  std::unordered_set<unsigned> non_zero_grads;$/;"	m	struct:cnn::LookupParameters
nosegmental_forward_backward	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::nosegmental_forward_backward(Model &model, AM_t &am, PDialogue &v_v_dialogues, int nutt, TrainingScores* scores, bool resetmodel = false, int init_turn_id = 0, Trainer* sgd = nullptr)$/;"	f	class:TrainProcess
np	exp/lm/lm.py	/^import numpy as np$/;"	i
nparallel	ext/trainer/train_proc.h	/^long nparallel = -1;$/;"	v
nrows	cnn/conv.h	/^  unsigned nrows;$/;"	m	struct:cnn::FoldRows
num_aux_vecs	examples/attentional.h	/^    unsigned num_aux_vecs;$/;"	m	struct:cnn::AttentionalModel
num_children	examples/mp.cc	/^const unsigned num_children = 4;$/;"	v
num_h0_components	cnn/dnn.h	/^        unsigned num_h0_components() const { return layers; }$/;"	f	class:cnn::DNNBuilder
num_nodes_evaluated	cnn/exec.h	/^  VariableIndex num_nodes_evaluated;$/;"	m	class:cnn::SimpleExecutionEngine
nutt	ext/dialogue/attention_with_intention.h	/^    unsigned int nutt; \/\/ for multiple training utterance per inibatch$/;"	m	class:cnn::DynamicMemoryNetDialogue
nutt	ext/dialogue/dialogue.h	/^    unsigned int nutt; \/\/ for multiple training utterance per inibatch$/;"	m	class:cnn::DialogueBuilder
nutt	ext/encdec/encdec.h	/^    unsigned nutt; \/\/ for multiple training utterance per inibatch$/;"	m	class:cnn::EncModel
nwords	ext/ngram/ngram.h	/^    unsigned long nwords;$/;"	m	class:nGram
o	cnn/deep-lstm.h	/^  std::vector<Expression> o;$/;"	m	struct:cnn::DeepLSTMBuilder
off_diag_sum	cnn/functors.h	/^  cnn::real off_diag_sum;$/;"	m	struct:cnn::FLogSoftmaxBackward
off_diag_sum	cnn/functors.h	/^  cnn::real off_diag_sum;$/;"	m	struct:cnn::FSoftmaxBackward
operator	exp/lm/lm.py	/^import operator$/;"	i
operator !=	cnn/dim.h	/^inline bool operator!=(const Dim& a, const Dim& b) { return !(a == b); }$/;"	f	namespace:cnn
operator ()	cnn/decode.h	/^    bool operator()(const Hypothesis& h1, const Hypothesis& h2)$/;"	f	struct:cnn::CompareHypothesis
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &a, const cnn::real &b) const {$/;"	f	struct:cnn::FProduct
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &a, const cnn::real &b) const {$/;"	f	struct:cnn::FSubtract
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &t, const cnn::real &d) const {$/;"	f	struct:cnn::FExponentialLinearUnitsBackward
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &t, const cnn::real &d) const {$/;"	f	struct:cnn::FRectifyBackward
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FConstantMultiply
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FCopy
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FExp
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FExponentialLinearUnits
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FLog
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FRectify
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FSquare
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x, const cnn::real &g) const {$/;"	f	struct:cnn::FL2SGDUpdate
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x, const cnn::real &g) const {$/;"	f	struct:cnn::FL2SGDUpdatePtrArguments
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x, const cnn::real &g, cnn::real &v) {$/;"	f	struct:cnn::FL2SGDMomentumUpdate
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real& r, const cnn::real &x, const cnn::real &g, cnn::real &v) {$/;"	f	struct:cnn::FL2SGDMomentumWithDenUpdate
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real& x) const$/;"	f	struct:cnn::scale_functor
operator ()	cnn/functors.h	/^    CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real& x, const cnn::real& y) const$/;"	f	struct:cnn::saxpy_functor
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC cnn::real operator()(const cnn::real & t, const cnn::real &d) const {$/;"	f	struct:cnn::FWeightedError
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC cnn::real operator()(const cnn::real &a, const cnn::real &b) const {$/;"	f	struct:cnn::FPairwiseRankLoss
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(cnn::real t, cnn::real d) const {$/;"	f	struct:cnn::FSqrtBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(cnn::real x, cnn::real d) const {$/;"	f	struct:cnn::FErfBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(cnn::real x, cnn::real d) const {$/;"	f	struct:cnn::FLogGammaBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(cnn::real x, cnn::real x_true) const {$/;"	f	struct:cnn::FBinaryLogLossBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real & t, const cnn::real& d) const {$/;"	f	struct:cnn::FLogBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real & x) const {$/;"	f	struct:cnn::FHuberBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real & x) const {$/;"	f	struct:cnn::FL1Backward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &a, const cnn::real &b) const {$/;"	f	struct:cnn::FEuclideanBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &a, const cnn::real &b) const {$/;"	f	struct:cnn::FQuotient
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &a, const cnn::real &b) const {$/;"	f	struct:cnn::FSqDist
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &t) const {$/;"	f	struct:cnn::FNegLogSoftmaxBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &t) const {$/;"	f	struct:cnn::FPtrNegLogSoftmaxBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &t, const cnn::real &d) const {$/;"	f	struct:cnn::FLogSoftmaxBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &t, const cnn::real &d) const {$/;"	f	struct:cnn::FLogisticSigmoidBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &t, const cnn::real &d) const {$/;"	f	struct:cnn::FRectifyNegateBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &t, const cnn::real &d) const {$/;"	f	struct:cnn::FSoftSignBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &t, const cnn::real &d) const {$/;"	f	struct:cnn::FSoftmaxBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &t, const cnn::real &d) const {$/;"	f	struct:cnn::FTanhBackward
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &u, const cnn::real &d) const {$/;"	f	struct:cnn::FMaxBackwardInv
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FConstantMinus
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FConstantPlus
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FErf
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FLogSoftmaxNormalize
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FLogisticSigmoid
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FNegate
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FSoftSign
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FSoftmaxNormalize
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x) const {$/;"	f	struct:cnn::FTanh
operator ()	cnn/functors.h	/^  CNN_DEVICE_FUNC inline cnn::real operator()(const cnn::real &x, const cnn::real &x_true) const {$/;"	f	struct:cnn::FBinaryLogLoss
operator ()	cnn/functors.h	/^CNN_DEVICE_FUNC inline cnn::real operator()(cnn::real x) const {$/;"	f	struct:cnn::FHuberForward
operator ()	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator() (const Scalar& t, const Scalar& d) const { return (1 - t * t) * d; }$/;"	f	struct:cnn::scalar_tanh_backward_op
operator ()	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(const Scalar& t) const {$/;"	f	struct:cnn::scalar_nlsoftmax_backward_op
operator ()	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const { using std::tanh; return tanh(a); }$/;"	f	struct:cnn::scalar_tanh_op
operator ()	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC inline const Scalar operator() (const Scalar& t, const Scalar& d) const {$/;"	f	struct:cnn::scalar_logistic_sigmoid_backward_op
operator ()	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC inline const Scalar operator() (const Scalar& x) const {$/;"	f	struct:cnn::const_add_op
operator ()	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC inline const Scalar operator() (const Scalar& x) const {$/;"	f	struct:cnn::const_minus_op
operator ()	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC inline const Scalar operator() (const Scalar& x) const {$/;"	f	struct:cnn::scalar_logistic_sigmoid_op
operator ()	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC inline const Scalar operator() (const Scalar& x, const Scalar& d) const {$/;"	f	struct:cnn::scalar_erf_backward_op
operator ()	examples/attentional.h	/^    bool operator()(const Hypothesis& h1, const Hypothesis& h2)$/;"	f	struct:cnn::CompareHypothesis
operator ()	examples/cxtattentional.h	/^    bool operator()(const Hypothesis& h1, const Hypothesis& h2)$/;"	f	struct:cnn::CompareHypothesis
operator *	cnn/expr.cc	/^Expression operator*(const Expression& x, cnn::real y) { return Expression(x.pg, x.pg->add_function<ConstScalarMultiply>({x.i}, y)); }$/;"	f	namespace:cnn::expr
operator *	cnn/expr.cc	/^Expression operator*(const Expression& x, const Expression& y) { return Expression(x.pg, x.pg->add_function<MatrixMultiply>({x.i, y.i})); }$/;"	f	namespace:cnn::expr
operator *	cnn/expr.h	/^inline Expression operator*(cnn::real y, const Expression& x) { return x * y; }$/;"	f	namespace:cnn::expr
operator *	cnn/tensor.h	/^  Eigen::Map<EMatrix, Eigen::Unaligned> operator*() {$/;"	f	struct:cnn::Tensor
operator *	cnn/tensor.h	/^  const Eigen::Map<EMatrix, Eigen::Unaligned> operator*() const {$/;"	f	struct:cnn::Tensor
operator +	cnn/expr.cc	/^Expression operator+(cnn::real x, const Expression& y) { return Expression(y.pg, y.pg->add_function<ConstantPlusX>({y.i}, x)); }$/;"	f	namespace:cnn::expr
operator +	cnn/expr.cc	/^Expression operator+(const Expression& x, cnn::real y) { return y+x; }$/;"	f	namespace:cnn::expr
operator +	cnn/expr.cc	/^Expression operator+(const Expression& x, const Expression& y) { return Expression(x.pg, x.pg->add_function<Sum>({x.i, y.i})); }$/;"	f	namespace:cnn::expr
operator -	cnn/expr.cc	/^Expression operator-(cnn::real x, const Expression& y) { return Expression(y.pg, y.pg->add_function<ConstantMinusX>({y.i}, x)); }$/;"	f	namespace:cnn::expr
operator -	cnn/expr.cc	/^Expression operator-(const Expression& x) { return Expression(x.pg, x.pg->add_function<Negate>({x.i})); }$/;"	f	namespace:cnn::expr
operator -	cnn/expr.cc	/^Expression operator-(const Expression& x, cnn::real y) { return -(y-x); }$/;"	f	namespace:cnn::expr
operator -	cnn/expr.cc	/^Expression operator-(const Expression& x, const Expression& y) { return x+(-y); }$/;"	f	namespace:cnn::expr
operator /	cnn/expr.h	/^inline Expression operator\/(const Expression& x, cnn::real y) { return x * (1.f \/ y); }$/;"	f	namespace:cnn::expr
operator <<	cnn/dim.cc	/^ostream& operator<<(ostream& os, const Dim& d) {$/;"	f	namespace:cnn
operator <<	cnn/dim.cc	/^ostream& operator<<(ostream& os, const vector<Dim>& ds) {$/;"	f	namespace:cnn
operator <<	cnn/tensor.cc	/^    ostream& operator<<(ostream& os, const Tensor& t) {$/;"	f	namespace:cnn
operator <<	cnn/tests/test_utils.h	/^std::ostream& operator<<(std::ostream& os, const Tensor& T) {$/;"	f	namespace:cnn
operator ==	cnn/dim.h	/^inline bool operator==(const Dim& a, const Dim& b) {$/;"	f	namespace:cnn
operator []	cnn/dim.h	/^  inline unsigned int operator[](unsigned int i) const { return i < nd ? d[i] : 1; }$/;"	f	struct:cnn::Dim
operator delete	cnn/cnn.h	/^    static void operator delete (void* p)$/;"	f	struct:cnn::Node
operator new	cnn/cnn.h	/^    static void * operator new (size_t sz)$/;"	f	struct:cnn::Node
operator_sys	exp/lm/create_lm_class.py	/^operator_sys = ''$/;"	v
operator_sys	exp/lm/lm.py	/^operator_sys = ''$/;"	v
org_and_lower_counts	exp/lm/lm.py	/^def org_and_lower_counts(ifile, norder):$/;"	f
os	exp/lm/create_lm_class.py	/^import os$/;"	i
out_of_memory	cnn/except.h	/^  out_of_memory(const std::string& what_arg) : runtime_error(what_arg) {}$/;"	f	class:cnn::out_of_memory
out_of_memory	cnn/except.h	/^class out_of_memory : public std::runtime_error {$/;"	c	namespace:cnn
override	cnn/conv.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::AddVectorToAllColumns
override	cnn/conv.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::Conv1DNarrow
override	cnn/conv.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::Conv1DWide
override	cnn/conv.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::FoldRows
override	cnn/conv.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::KMaxPooling
override	cnn/conv.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::AddVectorToAllColumns
override	cnn/conv.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Conv1DNarrow
override	cnn/conv.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Conv1DWide
override	cnn/conv.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::FoldRows
override	cnn/conv.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::KMaxPooling
override	cnn/conv.h	/^  size_t aux_storage_size() const override;$/;"	m	struct:cnn::KMaxPooling
override	cnn/conv.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::AddVectorToAllColumns
override	cnn/conv.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Conv1DNarrow
override	cnn/conv.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Conv1DWide
override	cnn/conv.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::FoldRows
override	cnn/conv.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::KMaxPooling
override	cnn/conv.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::AddVectorToAllColumns
override	cnn/conv.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Conv1DNarrow
override	cnn/conv.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Conv1DWide
override	cnn/conv.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::FoldRows
override	cnn/conv.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::KMaxPooling
override	cnn/deep-lstm.h	/^  Expression add_input_impl(int prev, const Expression& x) override;$/;"	m	struct:cnn::DeepLSTMBuilder
override	cnn/deep-lstm.h	/^  void new_graph_impl(ComputationGraph& cg) override;$/;"	m	struct:cnn::DeepLSTMBuilder
override	cnn/deep-lstm.h	/^  void start_new_sequence_impl(const std::vector<Expression>& h0) override;$/;"	m	struct:cnn::DeepLSTMBuilder
override	cnn/dglstm.h	/^  Expression add_input_impl(int prev, const Expression& x) override;$/;"	m	struct:cnn::DGLSTMBuilder
override	cnn/dglstm.h	/^  Expression add_input_impl(int prev, const std::vector<Expression>& x) override;$/;"	m	struct:cnn::DGLSTMBuilder
override	cnn/dglstm.h	/^  void copy(const RNNBuilder & params) override;$/;"	m	struct:cnn::DGLSTMBuilder
override	cnn/dglstm.h	/^  void new_graph_impl(ComputationGraph& cg) override;$/;"	m	struct:cnn::DGLSTMBuilder
override	cnn/dglstm.h	/^  void start_new_sequence_impl(const std::vector<Expression>& h0) override;$/;"	m	struct:cnn::DGLSTMBuilder
override	cnn/dnn.h	/^        Expression add_input_impl(const Expression& x) override;$/;"	m	class:cnn::ReluDNNBuilder
override	cnn/exec.h	/^  const Tensor& forward() override;$/;"	m	class:cnn::SimpleExecutionEngine
override	cnn/exec.h	/^  const Tensor& forward(VariableIndex i) override;$/;"	m	class:cnn::SimpleExecutionEngine
override	cnn/exec.h	/^  const Tensor& get_error(VariableIndex i) override;$/;"	m	class:cnn::SimpleExecutionEngine
override	cnn/exec.h	/^  const Tensor& get_value(VariableIndex i) override;$/;"	m	class:cnn::SimpleExecutionEngine
override	cnn/exec.h	/^  const Tensor& incremental_forward() override;  \/\/ if you want to add nodes and evaluate just the new parts$/;"	m	class:cnn::SimpleExecutionEngine
override	cnn/exec.h	/^  const Tensor& incremental_forward(VariableIndex i) override;$/;"	m	class:cnn::SimpleExecutionEngine
override	cnn/exec.h	/^  void  set_value(const Tensor& t, VariableIndex i) override;$/;"	m	class:cnn::SimpleExecutionEngine
override	cnn/exec.h	/^  void backward(VariableIndex i, cnn::real * kScalarInit = nullptr ) override;$/;"	m	class:cnn::SimpleExecutionEngine
override	cnn/exec.h	/^  void backward(cnn::real * kScalarInit = nullptr) override;$/;"	m	class:cnn::SimpleExecutionEngine
override	cnn/exec.h	/^  void invalidate() override;$/;"	m	class:cnn::SimpleExecutionEngine
override	cnn/exec.h	/^  void set_last_node_evaluated(VariableIndex i) override;$/;"	m	class:cnn::SimpleExecutionEngine
override	cnn/gru.h	/^  Expression add_input_impl(const std::vector<Expression>& prev, const Expression& x) override;$/;"	m	struct:cnn::GRUBuilder
override	cnn/gru.h	/^  Expression add_input_impl(int prev, const Expression& x) override;$/;"	m	struct:cnn::GRUBuilder
override	cnn/gru.h	/^  Expression add_input_impl(int prev, const std::vector<Expression>& x) override;$/;"	m	struct:cnn::GRUBuilder
override	cnn/gru.h	/^  void copy(const RNNBuilder & params) override;$/;"	m	struct:cnn::GRUBuilder
override	cnn/gru.h	/^  void new_graph_impl(ComputationGraph& cg) override;$/;"	m	struct:cnn::GRUBuilder
override	cnn/gru.h	/^  void start_new_sequence_impl(const std::vector<Expression>& h0) override;$/;"	m	struct:cnn::GRUBuilder
override	cnn/lstm.h	/^  Expression add_input_impl(const std::vector<Expression>& prv_history, const Expression& x) override;$/;"	m	struct:cnn::LSTMBuilder
override	cnn/lstm.h	/^  Expression add_input_impl(int prev, const Expression& x) override;$/;"	m	struct:cnn::LSTMBuilder
override	cnn/lstm.h	/^  Expression add_input_impl(int prev, const std::vector<Expression>& x) override;$/;"	m	struct:cnn::LSTMBuilder
override	cnn/lstm.h	/^  void copy(const RNNBuilder & params) override;$/;"	m	struct:cnn::LSTMBuilder
override	cnn/lstm.h	/^  void new_graph_impl(ComputationGraph& cg) override;$/;"	m	struct:cnn::LSTMBuilder
override	cnn/lstm.h	/^  void start_new_sequence_impl(const std::vector<Expression>& h0) override;$/;"	m	struct:cnn::LSTMBuilder
override	cnn/model.h	/^  size_t size() const override;$/;"	m	struct:cnn::LookupParameters
override	cnn/model.h	/^  size_t size() const override;$/;"	m	struct:cnn::Parameters
override	cnn/model.h	/^  void g_squared_l2norm(cnn::real* sqnorm) const override;$/;"	m	struct:cnn::LookupParameters
override	cnn/model.h	/^  void g_squared_l2norm(cnn::real* sqnorm) const override;$/;"	m	struct:cnn::Parameters
override	cnn/model.h	/^  void scale_parameters(cnn::real a) override;$/;"	m	struct:cnn::LookupParameters
override	cnn/model.h	/^  void scale_parameters(cnn::real a) override;$/;"	m	struct:cnn::Parameters
override	cnn/model.h	/^  void squared_l2norm(cnn::real* sqnorm) const override;$/;"	m	struct:cnn::LookupParameters
override	cnn/model.h	/^  void squared_l2norm(cnn::real* sqnorm) const override;$/;"	m	struct:cnn::Parameters
override	cnn/nodes.h	/^                     Tensor& dEdxi) const override;$/;"	m	struct:cnn::Pow
override	cnn/nodes.h	/^                    Tensor& dEdxi) const override;$/;"	m	struct:cnn::LogSoftmax
override	cnn/nodes.h	/^                    Tensor& dEdxi) const override;$/;"	m	struct:cnn::LogSumExp
override	cnn/nodes.h	/^                    Tensor& dEdxi) const override;$/;"	m	struct:cnn::LogisticSigmoid
override	cnn/nodes.h	/^                    Tensor& dEdxi) const override;$/;"	m	struct:cnn::PickElement
override	cnn/nodes.h	/^                    Tensor& dEdxi) const override;$/;"	m	struct:cnn::PickRange
override	cnn/nodes.h	/^                    Tensor& dEdxi) const override;$/;"	m	struct:cnn::RestrictedLogSoftmax
override	cnn/nodes.h	/^                    Tensor& dEdxi) const override;$/;"	m	struct:cnn::SoftSign
override	cnn/nodes.h	/^                    Tensor& dEdxi) const override;$/;"	m	struct:cnn::Softmax
override	cnn/nodes.h	/^                    Tensor& dEdxi) const override;$/;"	m	struct:cnn::Sum
override	cnn/nodes.h	/^                    Tensor& dEdxi) const override;$/;"	m	struct:cnn::SumBatches
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::AffineTransform
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::BinaryLogLoss
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::Concatenate
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::ConcatenateColumns
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::ConstantMinusX
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::ConstantPlusX
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::Cube
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::CwiseMultiply
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::Exp
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::GaussianNoise
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::Hinge
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::Identity
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::InnerProduct3D_1D
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::KMHNGram
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::L1Distance
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::Log
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::MatrixMultiply
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::MaxPooling1D
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::Negate
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::PairwiseRankLoss
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::Rectify
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::Reshape
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::Sqrt
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::Square
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::SquaredEuclideanDistance
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::Tanh
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::Transpose
override	cnn/nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::Zeroes
override	cnn/nodes.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::BlockDropout
override	cnn/nodes.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::ConstScalarMultiply
override	cnn/nodes.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::CwiseQuotient
override	cnn/nodes.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::DotProduct
override	cnn/nodes.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::Dropout
override	cnn/nodes.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::HuberDistance
override	cnn/nodes.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::Max
override	cnn/nodes.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::Min
override	cnn/nodes.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::PoissonRegressionLoss
override	cnn/nodes.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::SumColumns
override	cnn/nodes.h	/^                Tensor& dEdxi) const override;$/;"	m	struct:cnn::TraceOfProduct
override	cnn/nodes.h	/^        Tensor& dEdxi) const override;$/;"	m	struct:cnn::ColumnSlices
override	cnn/nodes.h	/^        Tensor& dEdxi) const override;$/;"	m	struct:cnn::ExponentialLinearUnits
override	cnn/nodes.h	/^        Tensor& dEdxi) const override;$/;"	m	struct:cnn::Reduce
override	cnn/nodes.h	/^      Tensor& dEdxi) const override;$/;"	m	struct:cnn::Average
override	cnn/nodes.h	/^    Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::ColumnSlices
override	cnn/nodes.h	/^    Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::ExponentialLinearUnits
override	cnn/nodes.h	/^    Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Reduce
override	cnn/nodes.h	/^    std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::ColumnSlices
override	cnn/nodes.h	/^    std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::ExponentialLinearUnits
override	cnn/nodes.h	/^    std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Reduce
override	cnn/nodes.h	/^    void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::ColumnSlices
override	cnn/nodes.h	/^    void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::ExponentialLinearUnits
override	cnn/nodes.h	/^    void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Reduce
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::AffineTransform
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Average
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::BinaryLogLoss
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::BlockDropout
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Concatenate
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::ConcatenateColumns
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::ConstScalarMultiply
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::ConstantMinusX
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::ConstantPlusX
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Cube
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::CwiseMultiply
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::CwiseQuotient
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::DotProduct
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Dropout
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Exp
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::GaussianNoise
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Hinge
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::HuberDistance
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Identity
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::InnerProduct3D_1D
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::KMHNGram
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::L1Distance
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Log
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::LogSoftmax
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::LogSumExp
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::LogisticSigmoid
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::MatrixMultiply
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Max
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::MaxPooling1D
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Min
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Negate
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::PairwiseRankLoss
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::PickElement
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::PickRange
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::PoissonRegressionLoss
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Pow
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Rectify
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Reshape
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::RestrictedLogSoftmax
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::SoftSign
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Softmax
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Sqrt
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Square
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::SquaredEuclideanDistance
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Sum
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::SumBatches
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::SumColumns
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Tanh
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::TraceOfProduct
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Transpose
override	cnn/nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::Zeroes
override	cnn/nodes.h	/^  size_t aux_storage_size() const override;$/;"	m	struct:cnn::Average
override	cnn/nodes.h	/^  size_t aux_storage_size() const override;$/;"	m	struct:cnn::BlockDropout
override	cnn/nodes.h	/^  size_t aux_storage_size() const override;$/;"	m	struct:cnn::Dropout
override	cnn/nodes.h	/^  size_t aux_storage_size() const override;$/;"	m	struct:cnn::GaussianNoise
override	cnn/nodes.h	/^  size_t aux_storage_size() const override;$/;"	m	struct:cnn::Hinge
override	cnn/nodes.h	/^  size_t aux_storage_size() const override;$/;"	m	struct:cnn::LogSoftmax
override	cnn/nodes.h	/^  size_t aux_storage_size() const override;$/;"	m	struct:cnn::LogSumExp
override	cnn/nodes.h	/^  size_t aux_storage_size() const override;$/;"	m	struct:cnn::Max
override	cnn/nodes.h	/^  size_t aux_storage_size() const override;$/;"	m	struct:cnn::Min
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::AffineTransform
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Average
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::BinaryLogLoss
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::BlockDropout
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Concatenate
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::ConcatenateColumns
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::ConstScalarMultiply
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::ConstantMinusX
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::ConstantPlusX
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Cube
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::CwiseMultiply
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::CwiseQuotient
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::DotProduct
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Dropout
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Exp
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::GaussianNoise
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Hinge
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::HuberDistance
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Identity
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::InnerProduct3D_1D
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::KMHNGram
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::L1Distance
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Log
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::LogSoftmax
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::LogSumExp
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::LogisticSigmoid
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::MatrixMultiply
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Max
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::MaxPooling1D
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Min
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Negate
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::PairwiseRankLoss
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::PickElement
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::PickRange
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::PoissonRegressionLoss
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Pow
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Rectify
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Reshape
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::RestrictedLogSoftmax
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::SoftSign
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Softmax
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Sqrt
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Square
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::SquaredEuclideanDistance
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Sum
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::SumBatches
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::SumColumns
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Tanh
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::TraceOfProduct
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Transpose
override	cnn/nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::Zeroes
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::AffineTransform
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Average
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::BinaryLogLoss
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::BlockDropout
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Concatenate
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::ConcatenateColumns
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::ConstScalarMultiply
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::ConstantMinusX
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::ConstantPlusX
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Cube
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::CwiseMultiply
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::CwiseQuotient
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::DotProduct
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Dropout
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Exp
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::GaussianNoise
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Hinge
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::HuberDistance
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Identity
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::InnerProduct3D_1D
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::KMHNGram
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::L1Distance
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Log
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::LogSoftmax
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::LogSumExp
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::LogisticSigmoid
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::MatrixMultiply
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Max
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::MaxPooling1D
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Min
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Negate
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::PairwiseRankLoss
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::PickElement
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::PickRange
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::PoissonRegressionLoss
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Pow
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Rectify
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Reshape
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::RestrictedLogSoftmax
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::SoftSign
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Softmax
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Sqrt
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Square
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::SquaredEuclideanDistance
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Sum
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::SumBatches
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::SumColumns
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Tanh
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::TraceOfProduct
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Transpose
override	cnn/nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::Zeroes
override	cnn/param-nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::ConstParameterNode
override	cnn/param-nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::InputNode
override	cnn/param-nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::LookupNode
override	cnn/param-nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::ParameterNode
override	cnn/param-nodes.h	/^                  Tensor& dEdxi) const override;$/;"	m	struct:cnn::ScalarInputNode
override	cnn/param-nodes.h	/^        Tensor& dEdxi) const override;$/;"	m	struct:cnn::ReferenceNode
override	cnn/param-nodes.h	/^    Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::ReferenceNode
override	cnn/param-nodes.h	/^    std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::ReferenceNode
override	cnn/param-nodes.h	/^    void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::ReferenceNode
override	cnn/param-nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::ConstParameterNode
override	cnn/param-nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::InputNode
override	cnn/param-nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::LookupNode
override	cnn/param-nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::ParameterNode
override	cnn/param-nodes.h	/^  Dim dim_forward(const std::vector<Dim>& xs) const override;$/;"	m	struct:cnn::ScalarInputNode
override	cnn/param-nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::ConstParameterNode
override	cnn/param-nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::InputNode
override	cnn/param-nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::LookupNode
override	cnn/param-nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::ParameterNode
override	cnn/param-nodes.h	/^  std::string as_string(const std::vector<std::string>& arg_names) const override;$/;"	m	struct:cnn::ScalarInputNode
override	cnn/param-nodes.h	/^  void accumulate_grad(const Tensor& g) override;$/;"	m	struct:cnn::LookupNode
override	cnn/param-nodes.h	/^  void accumulate_grad(const Tensor& g) override;$/;"	m	struct:cnn::ParameterNode
override	cnn/param-nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::ConstParameterNode
override	cnn/param-nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::InputNode
override	cnn/param-nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::LookupNode
override	cnn/param-nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::ParameterNode
override	cnn/param-nodes.h	/^  void forward_impl(const std::vector<const Tensor*>& xs, Tensor& fx) const override;$/;"	m	struct:cnn::ScalarInputNode
override	cnn/rnn.h	/^    Expression add_input_impl(const std::vector<Expression>& prev_history, const Expression& x) override;$/;"	m	struct:cnn::SimpleRNNBuilderWithELU
override	cnn/rnn.h	/^    Expression add_input_impl(int prev, const Expression& x) override;$/;"	m	struct:cnn::SimpleRNNBuilderWithELU
override	cnn/rnn.h	/^    Expression add_input_impl(int prev, const std::vector<Expression>& x) override;$/;"	m	struct:cnn::SimpleRNNBuilderWithELU
override	cnn/rnn.h	/^  Expression add_input_impl(const std::vector<Expression>& prev_history, const Expression& x) override;$/;"	m	struct:cnn::SimpleRNNBuilder
override	cnn/rnn.h	/^  Expression add_input_impl(int prev, const Expression& x) override;$/;"	m	struct:cnn::SimpleRNNBuilder
override	cnn/rnn.h	/^  Expression add_input_impl(int prev, const std::vector<Expression>& x) override;$/;"	m	struct:cnn::SimpleRNNBuilder
override	cnn/rnn.h	/^  void copy(const RNNBuilder & params) override;$/;"	m	struct:cnn::SimpleRNNBuilder
override	cnn/rnn.h	/^  void new_graph_impl(ComputationGraph& cg) override;$/;"	m	struct:cnn::SimpleRNNBuilder
override	cnn/rnn.h	/^  void start_new_sequence_impl(const std::vector<Expression>& h_0) override;$/;"	m	struct:cnn::SimpleRNNBuilder
override	cnn/rnnem.h	/^  Expression add_input_impl(int prev, const Expression& x) override;$/;"	m	struct:cnn::NMNBuilder
override	cnn/rnnem.h	/^  void new_graph_impl(ComputationGraph& cg) override;$/;"	m	struct:cnn::NMNBuilder
override	cnn/rnnem.h	/^  void start_new_sequence_impl(const std::vector<Expression>& h0) override;$/;"	m	struct:cnn::NMNBuilder
override	cnn/training.h	/^    void update(cnn::real nutt, cnn::real scale = 1.0) override;$/;"	m	struct:cnn::RmsPropWithMomentumTrainer
override	cnn/training.h	/^    void update(cnn::real nutt, cnn::real scale = 1.0) override;$/;"	m	struct:cnn::SimpleSGDTrainer
override	cnn/training.h	/^  void update(cnn::real nutt, cnn::real scale = 1.0) override;$/;"	m	struct:cnn::AdadeltaTrainer
override	cnn/training.h	/^  void update(cnn::real nutt, cnn::real scale = 1.0) override;$/;"	m	struct:cnn::AdagradTrainer
override	cnn/training.h	/^  void update(cnn::real nutt, cnn::real scale = 1.0) override;$/;"	m	struct:cnn::AdamTrainer
override	cnn/training.h	/^  void update(cnn::real nutt, cnn::real scale = 1.0) override;$/;"	m	struct:cnn::MomentumSGDTrainer
override	cnn/training.h	/^  void update(cnn::real nutt, cnn::real scale = 1.0) override;$/;"	m	struct:cnn::RmsPropTrainer
override	cnn/treelstm.h	/^  Expression add_input_impl(int prev, const Expression& x) override;$/;"	m	struct:cnn::TreeLSTMBuilder
override	cnn/treelstm.h	/^  void copy(const RNNBuilder & params) override;$/;"	m	struct:cnn::TreeLSTMBuilder
override	cnn/treelstm.h	/^  void new_graph_impl(ComputationGraph& cg) override;$/;"	m	struct:cnn::TreeLSTMBuilder
override	cnn/treelstm.h	/^  void start_new_sequence_impl(const std::vector<Expression>& h0) override;$/;"	m	struct:cnn::TreeLSTMBuilder
override	ext/dialogue/attention_with_intention.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg) override;$/;"	m	class:cnn::AWI_Bilinear
override	ext/dialogue/attention_with_intention.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg) override;$/;"	m	class:cnn::AttentionWithIntention
override	ext/dialogue/attention_with_intention.h	/^    Expression decoder_step(vector<int> trg_tok, ComputationGraph& cg) override;$/;"	m	class:cnn::GatedAttention
p	cnn/nodes.h	/^  cnn::real p;$/;"	m	struct:cnn::Dropout
p	ext/lda/lda.h	/^	double * p;$/;"	m	class:ldaModel
p2c	examples/mp.cc	/^  int p2c[2]; \/\/ Parent to child pipe$/;"	m	struct:Workload	file:
p_H	examples/rnnlm-aevb.cc	/^  Parameters* p_H;$/;"	m	struct:RNNLanguageModel	file:
p_P	examples/attentional.h	/^    Parameters* p_P;$/;"	m	struct:cnn::AttentionalModel
p_P	examples/regattentional.h	/^    Parameters* p_P;$/;"	m	struct:cnn::RegAttentionalModel
p_Q	examples/attentional.h	/^    Parameters* p_Q;$/;"	m	struct:cnn::AttentionalModel
p_Q	examples/regattentional.h	/^    Parameters* p_Q, *p_Qa;$/;"	m	struct:cnn::RegAttentionalModel
p_Q	ext/dialogue/attention_with_intention.h	/^    Parameters* p_Q;$/;"	m	class:cnn::AttentionWithIntention
p_Q	ext/dialogue/attention_with_intention.h	/^    Parameters* p_Q;$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_Qa	examples/regattentional.h	/^    Parameters* p_Q, *p_Qa;$/;"	m	struct:cnn::RegAttentionalModel
p_R	cnn/approximator.h	/^        vector<Parameters*> p_R;$/;"	m	class:cnn::ClsBasedBuilder
p_R	examples/attentional.h	/^    Parameters* p_R;$/;"	m	struct:cnn::AttentionalModel
p_R	examples/cxtattentional.h	/^    Parameters* p_R;$/;"	m	struct:cnn::CxtAttentionalModel
p_R	examples/encdec.cc	/^    Parameters* p_R;$/;"	m	struct:EncoderDecoder	file:
p_R	examples/mem_seq2seq_encdec.cc	/^  Parameters* p_R;$/;"	m	struct:EncoderDecoder	file:
p_R	examples/poisson-regression.cc	/^  Parameters* p_R;$/;"	m	struct:RNNLengthPredictor	file:
p_R	examples/regattentional.h	/^    Parameters* p_R;$/;"	m	struct:cnn::RegAttentionalModel
p_R	examples/rnnlm-aevb.cc	/^  Parameters* p_R;$/;"	m	struct:RNNLanguageModel	file:
p_R	examples/rnnlm.cc	/^  Parameters* p_R;$/;"	m	struct:RNNLanguageModel	file:
p_R	examples/rnnlm2.cc	/^  Parameters* p_R;$/;"	m	struct:RNNLanguageModel	file:
p_R	examples/rnnlm2_cls_based.cc	/^  vector<Parameters*> p_R;$/;"	m	struct:RNNLanguageModel	file:
p_R	examples/seq2seq_encdec.cc	/^  Parameters* p_R;$/;"	m	struct:EncoderDecoder	file:
p_R	examples/skiprnnlm.cc	/^    Parameters* p_R;$/;"	m	struct:RNNSkipLM	file:
p_R	ext/dialogue/attention_with_intention.h	/^    Parameters* p_R;  \/\/ for affine transformation after decoder$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_R	ext/dialogue/dialogue.h	/^    Parameters* p_R;  \/\/ for affine transformation after decoder$/;"	m	class:cnn::DialogueBuilder
p_R	ext/encdec/encdec.h	/^    Parameters* p_R;  \/\/ for affine transformation after decoder$/;"	m	class:cnn::EncModel
p_Ta	examples/attentional.h	/^    Parameters* p_Ta;$/;"	m	struct:cnn::AttentionalModel
p_Ta	examples/regattentional.h	/^    Parameters* p_Ta;$/;"	m	struct:cnn::RegAttentionalModel
p_U	ext/dialogue/attention_with_intention.h	/^    Parameters* p_U;$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_U	ext/dialogue/dialogue.h	/^    Parameters* p_U;$/;"	m	class:cnn::DialogueBuilder
p_U	ext/encdec/encdec.h	/^    Parameters* p_U;$/;"	m	class:cnn::EncModel
p_Ua	examples/attentional.h	/^    Parameters* p_Ua;$/;"	m	struct:cnn::AttentionalModel
p_Ua	examples/cxtattentional.h	/^    Parameters* p_Ua;  \/\/ for alignment$/;"	m	struct:cnn::CxtAttentionalModel
p_Ua	examples/regattentional.h	/^    Parameters* p_Ua;$/;"	m	struct:cnn::RegAttentionalModel
p_Wa	examples/attentional.h	/^    Parameters* p_Wa;$/;"	m	struct:cnn::AttentionalModel
p_Wa	examples/cxtattentional.h	/^    Parameters* p_Wa;$/;"	m	struct:cnn::CxtAttentionalModel
p_Wa	examples/regattentional.h	/^    Parameters* p_Wa;$/;"	m	struct:cnn::RegAttentionalModel
p_Wa	ext/dialogue/attention_with_intention.h	/^    Parameters* p_Wa, *p_va;$/;"	m	class:cnn::AttMultiSource_LinearEncoder
p_Wa	ext/dialogue/attention_with_intention.h	/^    Parameters* p_va, *p_Wa;$/;"	m	class:cnn::AttentionWithIntention
p_Wa	ext/dialogue/attention_with_intention.h	/^    Parameters* p_va, *p_Wa;$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_Wa_local	ext/dialogue/attention_with_intention.h	/^    Parameters* p_va_local, *p_Wa_local, *p_ba_local;$/;"	m	class:cnn::AWI_LocalGeneralInputFeeding
p_Wa_local	ext/dialogue/attention_with_intention.h	/^    Parameters* p_va_local, *p_Wa_local, *p_ba_local;$/;"	m	class:cnn::AttMultiSource_LinearEncoder
p_att_gate_A	ext/dialogue/attention_with_intention.h	/^    Parameters* p_att_gate_A, *p_att_gate_b;$/;"	m	class:cnn::GatedAttention
p_att_gate_b	ext/dialogue/attention_with_intention.h	/^    Parameters* p_att_gate_A, *p_att_gate_b;$/;"	m	class:cnn::GatedAttention
p_b0	examples/regattentional.h	/^    std::vector<Parameters*> p_h0, p_f0, p_b0;$/;"	m	struct:cnn::RegAttentionalModel
p_ba	examples/cxtattentional.h	/^    Parameters* p_ba;  $/;"	m	struct:cnn::CxtAttentionalModel
p_ba_local	ext/dialogue/attention_with_intention.h	/^    Parameters* p_va_local, *p_Wa_local, *p_ba_local;$/;"	m	class:cnn::AWI_LocalGeneralInputFeeding
p_ba_local	ext/dialogue/attention_with_intention.h	/^    Parameters* p_va_local, *p_Wa_local, *p_ba_local;$/;"	m	class:cnn::AttMultiSource_LinearEncoder
p_bias	cnn/approximator.h	/^        vector<Parameters*> p_bias;$/;"	m	class:cnn::ClsBasedBuilder
p_bias	examples/attentional.h	/^    Parameters* p_bias;$/;"	m	struct:cnn::AttentionalModel
p_bias	examples/cxtattentional.h	/^    Parameters* p_bias;$/;"	m	struct:cnn::CxtAttentionalModel
p_bias	examples/encdec.cc	/^    Parameters* p_bias;$/;"	m	struct:EncoderDecoder	file:
p_bias	examples/mem_seq2seq_encdec.cc	/^  Parameters* p_bias;$/;"	m	struct:EncoderDecoder	file:
p_bias	examples/poisson-regression.cc	/^  Parameters* p_bias;$/;"	m	struct:RNNLengthPredictor	file:
p_bias	examples/regattentional.h	/^    Parameters* p_bias;$/;"	m	struct:cnn::RegAttentionalModel
p_bias	examples/rnnlm-aevb.cc	/^  Parameters* p_bias;$/;"	m	struct:RNNLanguageModel	file:
p_bias	examples/rnnlm.cc	/^  Parameters* p_bias;$/;"	m	struct:RNNLanguageModel	file:
p_bias	examples/rnnlm2.cc	/^  Parameters* p_bias;$/;"	m	struct:RNNLanguageModel	file:
p_bias	examples/rnnlm2_cls_based.cc	/^  vector<Parameters*> p_bias;$/;"	m	struct:RNNLanguageModel	file:
p_bias	examples/seq2seq_encdec.cc	/^  Parameters* p_bias;$/;"	m	struct:EncoderDecoder	file:
p_bias	examples/skiprnnlm.cc	/^    Parameters* p_bias;$/;"	m	struct:RNNSkipLM	file:
p_bias	ext/dialogue/attention_with_intention.h	/^    Parameters* p_bias;$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_bias	ext/dialogue/dialogue.h	/^    Parameters* p_bias;$/;"	m	class:cnn::DialogueBuilder
p_bias	ext/encdec/encdec.h	/^    Parameters* p_bias;$/;"	m	class:cnn::EncModel
p_bias_cxt	examples/cxtattentional.h	/^    Parameters* p_bias_cxt;$/;"	m	struct:cnn::CxtAttentionalModel
p_bie	examples/encdec.cc	/^    Parameters* p_bie;$/;"	m	struct:EncoderDecoder	file:
p_boe	examples/encdec.cc	/^    Parameters* p_boe;$/;"	m	struct:EncoderDecoder	file:
p_c	examples/encdec.cc	/^    LookupParameters* p_c;$/;"	m	struct:EncoderDecoder	file:
p_c	examples/mem_seq2seq_encdec.cc	/^  LookupParameters* p_c;$/;"	m	struct:EncoderDecoder	file:
p_c	examples/poisson-regression.cc	/^  LookupParameters* p_c;$/;"	m	struct:RNNLengthPredictor	file:
p_c	examples/rnnlm-aevb.cc	/^  LookupParameters* p_c;  \/\/ should we have two of these?$/;"	m	struct:RNNLanguageModel	file:
p_c	examples/rnnlm.cc	/^  LookupParameters* p_c;$/;"	m	struct:RNNLanguageModel	file:
p_c	examples/rnnlm2.cc	/^  LookupParameters* p_c;$/;"	m	struct:RNNLanguageModel	file:
p_c	examples/rnnlm2_cls_based.cc	/^  LookupParameters* p_c;$/;"	m	struct:RNNLanguageModel	file:
p_c	examples/seq2seq_encdec.cc	/^  LookupParameters* p_c;$/;"	m	struct:EncoderDecoder	file:
p_c	examples/skiprnnlm.cc	/^    LookupParameters* p_c;$/;"	m	struct:RNNSkipLM	file:
p_c2h	examples/textcat.cc	/^  Parameters* p_c2h;$/;"	m	struct:NeuralBagOfWords	file:
p_cls	cnn/approximator.h	/^        Parameters* p_cls, *p_cls_bias;$/;"	m	class:cnn::ClsBasedBuilder
p_cls	examples/rnnlm2_cls_based.cc	/^  Parameters* p_cls, *p_cls_bias;$/;"	m	struct:RNNLanguageModel	file:
p_cls_bias	cnn/approximator.h	/^        Parameters* p_cls, *p_cls_bias;$/;"	m	class:cnn::ClsBasedBuilder
p_cls_bias	examples/rnnlm2_cls_based.cc	/^  Parameters* p_cls, *p_cls_bias;$/;"	m	struct:RNNLanguageModel	file:
p_clsbased_error	ext/dialogue/attention_with_intention.h	/^    ClsBasedBuilder* p_clsbased_error;$/;"	m	class:cnn::ClsBasedMultiSource_LinearEncoder
p_cs	examples/attentional.h	/^    LookupParameters* p_cs;$/;"	m	struct:cnn::AttentionalModel
p_cs	examples/cxtattentional.h	/^    LookupParameters* p_cs;$/;"	m	struct:cnn::CxtAttentionalModel
p_cs	ext/dialogue/attention_with_intention.h	/^    LookupParameters* p_cs;$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_cs	ext/dialogue/dialogue.h	/^    LookupParameters* p_cs;$/;"	m	class:cnn::DialogueBuilder
p_cs	ext/encdec/encdec.h	/^    LookupParameters* p_cs;$/;"	m	class:cnn::EncModel
p_ct	examples/attentional.h	/^    LookupParameters* p_ct;$/;"	m	struct:cnn::AttentionalModel
p_cxt2dec_w	ext/dialogue/dialogue.h	/^    Parameters* p_cxt2dec_w;$/;"	m	class:cnn::DialogueBuilder
p_cxt2dec_w	ext/encdec/encdec.h	/^    Parameters* p_cxt2dec_w;$/;"	m	class:cnn::EncModel
p_cxt_to_decoder	ext/dialogue/attention_with_intention.h	/^    Parameters * p_cxt_to_decoder, *p_enc_to_intention;$/;"	m	class:cnn::MultiSource_LinearEncoder
p_cxt_to_decoder	ext/dialogue/attention_with_intention.h	/^    Parameters* p_cxt_to_decoder;$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_cxt_to_decoder	ext/ir/ir.h	/^        Parameters * p_cxt_to_decoder, *p_enc_to_intention;$/;"	m	class:cnn::ClassificationEncoderDecoder
p_cxt_to_decoder_bias	ext/dialogue/attention_with_intention.h	/^    Parameters* p_cxt_to_decoder_bias;  \/\/ for affine transformation of context to fact encoder$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_cxt_to_encoder	ext/dialogue/attention_with_intention.h	/^    Parameters* p_cxt_to_encoder;$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_cxt_to_encoder_bias	ext/dialogue/attention_with_intention.h	/^    Parameters* p_cxt_to_encoder_bias;  \/\/ for affine transformation of context to fact encoder$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_ec	examples/encdec.cc	/^    LookupParameters* p_ec;  \/\/ map input to embedding (used in fwd and rev models)$/;"	m	struct:EncoderDecoder	file:
p_ec	examples/mem_seq2seq_encdec.cc	/^  LookupParameters* p_ec;  \/\/ map input to embedding (used in fwd and rev models)$/;"	m	struct:EncoderDecoder	file:
p_ec	examples/seq2seq_encdec.cc	/^  LookupParameters* p_ec;  \/\/ map input to embedding (used in fwd and rev models)$/;"	m	struct:EncoderDecoder	file:
p_emb2enc	ext/dialogue/attention_with_intention.h	/^    Parameters * p_emb2enc; \/\/\/ embedding to encoding$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
p_emb2enc	ext/dialogue/attention_with_intention.h	/^    Parameters * p_emb2enc; \/\/\/ embedding to encoding$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
p_emb2enc_b	ext/dialogue/attention_with_intention.h	/^    Parameters * p_emb2enc_b; \/\/\/ bias $/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
p_emb2enc_b	ext/dialogue/attention_with_intention.h	/^    Parameters * p_emb2enc_b; \/\/\/ bias $/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
p_enc_to_intention	ext/dialogue/attention_with_intention.h	/^    Parameters * p_cxt_to_decoder, *p_enc_to_intention;$/;"	m	class:cnn::MultiSource_LinearEncoder
p_enc_to_intention	ext/ir/ir.h	/^        Parameters * p_cxt_to_decoder, *p_enc_to_intention;$/;"	m	class:cnn::ClassificationEncoderDecoder
p_f0	examples/regattentional.h	/^    std::vector<Parameters*> p_h0, p_f0, p_b0;$/;"	m	struct:cnn::RegAttentionalModel
p_fact_encoder_state	ext/dialogue/attention_with_intention.h	/^    Parameters* p_fact_encoder_state;$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_fact_encoder_state_bias	ext/dialogue/attention_with_intention.h	/^    Parameters* p_fact_encoder_state_bias;  \/\/ for affine transformation of fact states$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_fact_encoder_state_to_cxt	ext/dialogue/attention_with_intention.h	/^    Parameters* p_fact_encoder_state_to_cxt;$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_fact_encoder_state_to_cxt_bias	ext/dialogue/attention_with_intention.h	/^    Parameters* p_fact_encoder_state_to_cxt_bias;  \/\/ for affine transformation of fact states to context$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_fbias	examples/convmodel.h	/^        vector<vector<Parameters*>> p_fbias; \/\/ [feature map index from][feature map index to]$/;"	m	struct:cnn::ConvLayer
p_fbias	examples/textcat.cc	/^  vector<vector<Parameters*>> p_fbias; \/\/ [feature map index from][feature map index to]$/;"	m	struct:ConvLayer	file:
p_filts	examples/convmodel.h	/^        vector<vector<Parameters*>> p_filts; \/\/ [feature map index from][feature map index to]$/;"	m	struct:cnn::ConvLayer
p_filts	examples/textcat.cc	/^  vector<vector<Parameters*>> p_filts; \/\/ [feature map index from][feature map index to]$/;"	m	struct:ConvLayer	file:
p_global_me_weight	ext/dialogue/attention_with_intention.h	/^    Parameters * p_global_me_weight;\/\/\/ weight for global ME feature$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch
p_h0	examples/attentional.h	/^    std::vector<Parameters*> p_h0;$/;"	m	struct:cnn::AttentionalModel
p_h0	examples/cxtattentional.h	/^    std::vector<Parameters*> p_h0;$/;"	m	struct:cnn::CxtAttentionalModel
p_h0	examples/regattentional.h	/^    std::vector<Parameters*> p_h0, p_f0, p_b0;$/;"	m	struct:cnn::RegAttentionalModel
p_h0	ext/dialogue/attention_with_intention.h	/^    vector<Parameters*> p_h0;$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_h0	ext/dialogue/dialogue.h	/^    vector<Parameters*> p_h0;$/;"	m	class:cnn::DialogueBuilder
p_h0	ext/encdec/encdec.h	/^    vector<Parameters*> p_h0;$/;"	m	class:cnn::EncModel
p_h0b	examples/rnnlm-aevb.cc	/^  Parameters* p_h0b;$/;"	m	struct:RNNLanguageModel	file:
p_h2m	examples/rnnlm-aevb.cc	/^  Parameters* p_h2m;$/;"	m	struct:RNNLanguageModel	file:
p_h2o	examples/textcat.cc	/^  Parameters* p_h2o;$/;"	m	struct:NeuralBagOfWords	file:
p_h2oe	examples/encdec.cc	/^    Parameters* p_h2oe;$/;"	m	struct:EncoderDecoder	file:
p_h2s	examples/rnnlm-aevb.cc	/^  Parameters* p_h2s;$/;"	m	struct:RNNLanguageModel	file:
p_hb	examples/rnnlm-aevb.cc	/^  Parameters* p_hb;$/;"	m	struct:RNNLanguageModel	file:
p_hbias	examples/textcat.cc	/^  Parameters* p_hbias;$/;"	m	struct:NeuralBagOfWords	file:
p_ie2h	examples/encdec.cc	/^    Parameters* p_ie2h;$/;"	m	struct:EncoderDecoder	file:
p_l2th	examples/tag-bilstm.cc	/^  Parameters* p_l2th;$/;"	m	struct:RNNLanguageModel	file:
p_lookup	cnn/c2w.h	/^  LookupParameters* p_lookup;$/;"	m	struct:cnn::C2WBuilder
p_max_ent	ext/dialogue/attention_with_intention.h	/^    LookupParameters* p_max_ent; \/\/\/ weight for max-entropy feature$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
p_max_ent	ext/dialogue/attention_with_intention.h	/^    LookupParameters* p_max_ent; \/\/\/ weight for max-entropy feature$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
p_mb	examples/rnnlm-aevb.cc	/^  Parameters* p_mb;$/;"	m	struct:RNNLanguageModel	file:
p_obias	examples/convmodel.h	/^        Parameters* p_obias;$/;"	m	struct:cnn::ConvNet
p_obias	examples/textcat.cc	/^  Parameters* p_obias;$/;"	m	struct:ConvNet	file:
p_obias	examples/textcat.cc	/^  Parameters* p_obias;$/;"	m	struct:NeuralBagOfWords	file:
p_parameters	ext/encdec/encdec.h	/^    vector<Parameters*> p_parameters;$/;"	m	class:cnn::EncModel
p_r2th	examples/tag-bilstm.cc	/^  Parameters* p_r2th;$/;"	m	struct:RNNLanguageModel	file:
p_s	examples/embed-cl.cc	/^  LookupParameters* p_s;$/;"	m	struct:Encoder	file:
p_sb	examples/rnnlm-aevb.cc	/^  Parameters* p_sb;$/;"	m	struct:RNNLanguageModel	file:
p_scale	ext/dialogue/attention_with_intention.h	/^    Parameters* p_scale;$/;"	m	class:cnn::AWI_GeneralInputFeeding
p_scale	ext/dialogue/attention_with_intention.h	/^    Parameters* p_scale;$/;"	m	class:cnn::AWI_LocalGeneralInputFeeding
p_scale	ext/dialogue/attention_with_intention.h	/^    Parameters* p_scale;$/;"	m	class:cnn::AttMultiSource_LinearEncoder
p_scale	ext/dialogue/attention_with_intention.h	/^    Parameters* p_scale;$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_t	examples/embed-cl.cc	/^  LookupParameters* p_t;$/;"	m	struct:Encoder	file:
p_t2o	examples/convmodel.h	/^        Parameters* p_t2o;$/;"	m	struct:cnn::ConvNet
p_t2o	examples/textcat.cc	/^  Parameters* p_t2o;$/;"	m	struct:ConvNet	file:
p_tbias	examples/tag-bilstm.cc	/^  Parameters* p_tbias;$/;"	m	struct:RNNLanguageModel	file:
p_tgt2enc_b	ext/dialogue/attention_with_intention.h	/^        vector<Parameters*> p_tgt2enc_b;$/;"	m	class:cnn::AWI_Bilinear
p_tgt2enc_w	ext/dialogue/attention_with_intention.h	/^        vector<Parameters*> p_tgt2enc_w;$/;"	m	class:cnn::AWI_Bilinear
p_tgt_side_emb	ext/dialogue/attention_with_intention.h	/^    LookupParameters* p_tgt_side_emb;  \/\/\/ target side embedding$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch
p_th2t	examples/tag-bilstm.cc	/^  Parameters* p_th2t;$/;"	m	struct:RNNLanguageModel	file:
p_thbias	examples/tag-bilstm.cc	/^  Parameters* p_thbias;$/;"	m	struct:RNNLanguageModel	file:
p_va	examples/attentional.h	/^    Parameters* p_va;$/;"	m	struct:cnn::AttentionalModel
p_va	examples/cxtattentional.h	/^    Parameters* p_va;$/;"	m	struct:cnn::CxtAttentionalModel
p_va	examples/regattentional.h	/^    Parameters* p_va;$/;"	m	struct:cnn::RegAttentionalModel
p_va	ext/dialogue/attention_with_intention.h	/^    Parameters* p_Wa, *p_va;$/;"	m	class:cnn::AttMultiSource_LinearEncoder
p_va	ext/dialogue/attention_with_intention.h	/^    Parameters* p_va, *p_Wa;$/;"	m	class:cnn::AttentionWithIntention
p_va	ext/dialogue/attention_with_intention.h	/^    Parameters* p_va, *p_Wa;$/;"	m	class:cnn::DynamicMemoryNetDialogue
p_va_local	ext/dialogue/attention_with_intention.h	/^    Parameters* p_va_local, *p_Wa_local, *p_ba_local;$/;"	m	class:cnn::AWI_LocalGeneralInputFeeding
p_va_local	ext/dialogue/attention_with_intention.h	/^    Parameters* p_va_local, *p_Wa_local, *p_ba_local;$/;"	m	class:cnn::AttMultiSource_LinearEncoder
p_w	examples/convmodel.h	/^        LookupParameters* p_w;$/;"	m	struct:cnn::ConvNet
p_w	examples/tag-bilstm.cc	/^  LookupParameters* p_w;$/;"	m	struct:RNNLanguageModel	file:
p_w	examples/textcat.cc	/^  LookupParameters* p_w;$/;"	m	struct:ConvNet	file:
p_w	examples/textcat.cc	/^  LookupParameters* p_w;$/;"	m	struct:NeuralBagOfWords	file:
p_z2h0	examples/rnnlm-aevb.cc	/^  Parameters* p_z2h0;$/;"	m	struct:RNNLanguageModel	file:
pack_obs	cnn/data-util.cc	/^vector<vector<Expression>> pack_obs(FCorpusPointers raw, size_t mbsize, ComputationGraph& cg, const vector<size_t>& randstt)$/;"	f
pack_obs_uttfirst	cnn/data-util.cc	/^vector<vector<Expression>> pack_obs_uttfirst(FCorpusPointers raw, unsigned mbsize, ComputationGraph& cg, const vector<size_t>& randstt)$/;"	f
packetOp	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& t) const {$/;"	f	struct:cnn::scalar_nlsoftmax_backward_op
packetOp	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& t, const Packet& d) const {$/;"	f	struct:cnn::scalar_tanh_backward_op
packetOp	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const { return Eigen::internal::ptanh(a); }$/;"	f	struct:cnn::scalar_tanh_op
packetOp	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC inline Packet packetOp(const Packet& t, const Packet& d) const {$/;"	f	struct:cnn::scalar_logistic_sigmoid_backward_op
packetOp	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC inline Packet packetOp(const Packet& x) const {$/;"	f	struct:cnn::const_add_op
packetOp	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC inline Packet packetOp(const Packet& x) const {$/;"	f	struct:cnn::const_minus_op
packetOp	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC inline Packet packetOp(const Packet& x) const {$/;"	f	struct:cnn::scalar_logistic_sigmoid_op
packetOp	cnn/simd-functors.h	/^  CNN_DEVICE_FUNC inline Packet packetOp(const Packet& x, const Packet& d) const {$/;"	f	struct:cnn::scalar_erf_backward_op
padding_with_eos	cnn/data-util.cc	/^PDialogue padding_with_eos(const PDialogue& v_diag, int padding_symbol, const std::vector<bool>& padding_to_the_back)$/;"	f
padding_with_eos	cnn/data-util.cc	/^Sentences padding_with_eos(const Sentences& v_sent, int padding_symbol, bool  padding_to_the_back)$/;"	f
pairwise_rank_loss	cnn/expr.cc	/^Expression pairwise_rank_loss(const Expression& x, const Expression& y, cnn::real m) { return Expression(x.pg, x.pg->add_function<PairwiseRankLoss>({x.i, y.i}, m)); }$/;"	f	namespace:cnn::expr
param_vars	cnn/approximator.h	/^        std::vector<std::vector<Expression>> param_vars;$/;"	m	class:cnn::ClsBasedBuilder
param_vars	cnn/deep-lstm.h	/^  std::vector<std::vector<Expression>> param_vars;$/;"	m	struct:cnn::DeepLSTMBuilder
param_vars	cnn/dnn.h	/^        std::vector<std::vector<Expression>> param_vars;$/;"	m	class:cnn::DNNBuilder
param_vars	cnn/rnn.h	/^  std::vector<std::vector<Expression>> param_vars;$/;"	m	struct:cnn::RNNBuilder
param_vars	cnn/rnnem.h	/^  std::vector<std::vector<Expression>> param_vars;$/;"	m	struct:cnn::NMNBuilder
param_vars	cnn/treelstm.h	/^  std::vector<std::vector<Expression>> param_vars;$/;"	m	struct:cnn::TreeLSTMBuilder
parameter	cnn/expr.cc	/^Expression parameter(ComputationGraph& g, Parameters* p) { return Expression(&g, g.add_parameters(p)); }$/;"	f	namespace:cnn::expr
parameter_nodes	cnn/cnn.h	/^  std::vector<VariableIndex> parameter_nodes; \/\/ nodes that contain parameters that can be updated (subset of nodes)$/;"	m	struct:cnn::ComputationGraph
parameters_list	cnn/model.h	/^    const std::vector<Parameters*>& parameters_list() const { return params; }$/;"	f	class:cnn::Model
params	cnn/deep-lstm.h	/^  std::vector<std::vector<Parameters*>> params;$/;"	m	struct:cnn::DeepLSTMBuilder
params	cnn/dnn.h	/^        std::vector<std::vector<Parameters*>> params;$/;"	m	class:cnn::DNNBuilder
params	cnn/model.h	/^    std::vector<Parameters*> params;$/;"	m	class:cnn::Model
params	cnn/param-nodes.h	/^  LookupParameters* params;$/;"	m	struct:cnn::LookupNode
params	cnn/param-nodes.h	/^  Parameters* params;$/;"	m	struct:cnn::ConstParameterNode
params	cnn/param-nodes.h	/^  Parameters* params;$/;"	m	struct:cnn::ParameterNode
params	cnn/rnn.h	/^  std::vector<std::vector<Parameters*>> params;$/;"	m	struct:cnn::RNNBuilder
params	cnn/rnnem.h	/^  std::vector<std::vector<Parameters*>> params;$/;"	m	struct:cnn::NMNBuilder
params	cnn/treelstm.h	/^  std::vector<std::vector<Parameters*>> params;$/;"	m	struct:cnn::TreeLSTMBuilder
pdata	cnn/param-nodes.h	/^    const cnn::real* pdata;$/;"	m	struct:cnn::ReferenceNode
pdata	cnn/param-nodes.h	/^  const cnn::real* pdata;$/;"	m	struct:cnn::ScalarInputNode
pdata	cnn/param-nodes.h	/^  const std::vector<cnn::real>* pdata;$/;"	m	struct:cnn::InputNode
pdropout	examples/textcat.cc	/^cnn::real pdropout = 0.5;$/;"	v
pelement	cnn/nodes.h	/^  const unsigned* pelement;$/;"	m	struct:cnn::Hinge
pg	cnn/expr.h	/^  ComputationGraph *pg;$/;"	m	struct:cnn::expr::Expression
phyId2logicId	cnn/dict.h	/^    std::unordered_map<int, int> phyId2logicId; \/\/\/ physical id to logic id$/;"	m	class:cnn::stId2String
phyIdOflogicId	cnn/dict.h	/^    int phyIdOflogicId(int logicid) { if (logicid >= 0 && logicid < logicId2phyId.size()) return logicId2phyId[logicid]; return -1; }$/;"	f	class:cnn::stId2String
pick	cnn/expr.cc	/^Expression pick(const Expression& x, unsigned v) { return Expression(x.pg, x.pg->add_function<PickElement>({x.i}, v)); }$/;"	f	namespace:cnn::expr
pick	cnn/expr.cc	/^Expression pick(const Expression& x, unsigned* pv) { return Expression(x.pg, x.pg->add_function<PickElement>({x.i}, pv)); }$/;"	f	namespace:cnn::expr
pickrange	cnn/expr.cc	/^Expression pickrange(const Expression& x, unsigned v, unsigned u) { return Expression(x.pg, x.pg->add_function<PickRange>({ x.i }, v, u)); }$/;"	f	namespace:cnn::expr
pid	examples/mp.cc	/^  pid_t pid;$/;"	m	struct:Workload	file:
pin_memory_size	ext/dialogue/dialogue.h	/^    int pin_memory_size()$/;"	f	class:cnn::DialogueBuilder
pindex	cnn/param-nodes.h	/^  const unsigned* pindex;$/;"	m	struct:cnn::LookupNode
pindices	cnn/param-nodes.h	/^  const std::vector<unsigned>* pindices;$/;"	m	struct:cnn::LookupNode
pointer_to_one_over_size	cnn/nodes.cc	/^cnn::real* pointer_to_one_over_size(int sz, cnn::real * back_off_mem)$/;"	f	namespace:cnn
poisson_loss	cnn/expr.cc	/^Expression poisson_loss(const Expression& x, const unsigned* py) { return Expression(x.pg, x.pg->add_function<PoissonRegressionLoss>({x.i}, py)); }$/;"	f	namespace:cnn::expr
poisson_loss	cnn/expr.cc	/^Expression poisson_loss(const Expression& x, unsigned y) { return Expression(x.pg, x.pg->add_function<PoissonRegressionLoss>({x.i}, y)); }$/;"	f	namespace:cnn::expr
pow	cnn/expr.cc	/^Expression pow(const Expression& x, const Expression& y) { return Expression(x.pg, x.pg->add_function<Pow>({x.i, y.i})); }$/;"	f	namespace:cnn::expr
ppl_hist	ext/trainer/train_proc.h	/^    vector<cnn::real> ppl_hist;$/;"	m	class:TrainProcess
prob	exp/lm/lm.py	/^def prob(testfile, count_org_order, count_lower_order, norder):$/;"	f
project_weights	cnn/model.cc	/^void Model::project_weights(cnn::real radius) {$/;"	f	class:cnn::Model
prt_model_info	ext/trainer/train_proc_wrapper.h	/^void prt_model_info(size_t LAYERS, size_t VOCAB_SIZE_SRC, const vector<unsigned>& dims, size_t nreplicate, size_t decoder_additiona_input_to, size_t mem_slots, cnn::real scale)$/;"	f
prv_response	ext/trainer/train_proc.h	/^Sentence prv_response;$/;"	v
pty	cnn/nodes.h	/^  const unsigned* pty;$/;"	m	struct:cnn::PoissonRegressionLoss
pval	cnn/nodes.h	/^  const unsigned* pval;$/;"	m	struct:cnn::PickElement
q_	cnn/rnn-state-machine.h	/^  RNNState q_;$/;"	m	class:cnn::RNNStateMachine
query_obs	ext/dialogue/attention_with_intention.h	/^    vector<Expression> query_obs;  \/\/\/ the observed context\/query$/;"	m	class:cnn::DynamicMemoryNetDialogue
r2lbuilder	examples/tag-bilstm.cc	/^  Builder r2lbuilder;$/;"	m	struct:RNNLanguageModel	file:
r_softmax_scale	ext/dialogue/attention_with_intention.h	/^    cnn::real r_softmax_scale; \/\/\/ for attention softmax exponential scale$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
r_softmax_scale	ext/dialogue/attention_with_intention.h	/^    cnn::real r_softmax_scale; \/\/\/ for attention softmax exponential scale$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
rand01	cnn/math.cc	/^    cnn::real rand01() {$/;"	f	namespace:cnn
rand0n	cnn/math.cc	/^    int rand0n(int n) {$/;"	f	namespace:cnn
rand0n_uniform	cnn/math.cc	/^    int rand0n_uniform(int n)$/;"	f	namespace:cnn
rand0n_uniform	cnn/math.cc	/^    std::vector<int> rand0n_uniform(int vecsize, int n_exclusive)$/;"	f	namespace:cnn
rand0n_uniform	cnn/math.cc	/^    std::vector<int> rand0n_uniform(int vecsize, int n_exclusive, const std::vector<cnn::real>& sample_dist)$/;"	f	namespace:cnn
rand_normal	cnn/math.cc	/^    cnn::real rand_normal() {$/;"	f	namespace:cnn
rc2w	cnn/c2w.h	/^  LSTMBuilder rc2w;$/;"	m	struct:cnn::C2WBuilder
re	exp/lm/create_lm_class.py	/^import re$/;"	i
readEmbedding	ext/trainer/eval_proc.h	/^void EvaluateProcess<Proc>::readEmbedding(const string& embedding_fn, Dict& sd)$/;"	f	class:EvaluateProcess
read_corpus	cnn/data-util.cc	/^Corpus read_corpus(const string &filename, Dict& sd, int kSRC_SOS, int kSRC_EOS, bool backofftounk, const pair<int, int>& columnids)$/;"	f
read_corpus	cnn/data-util.cc	/^Corpus read_corpus(const string &filename, Dict& sd, int kSRC_SOS, int kSRC_EOS, int maxSentLength, bool backofftounk, bool bcharacter)$/;"	f
read_corpus	cnn/data-util.cc	/^Corpus read_corpus(const string &filename, unsigned& min_diag_id, WDict& sd, int kSRC_SOS, int kSRC_EOS, int maxSentLength, bool appendBSandES)$/;"	f
read_corpus	cnn/data-util.cc	/^Corpus read_corpus(ifstream & in, Dict& sd, int kSRC_SOS, int kSRC_EOS, long part_size)$/;"	f
read_corpus	cnn/data-util.cc	/^Corpus read_corpus(ifstream & in, Dict& sd, int kSRC_SOS, int kSRC_EOS, long part_size, const pair<int, int>& columids, const pair<bool, bool>& use_dict, unordered_map<int,int>& phyid2logicid)$/;"	f
read_corpus	cnn/data-util.cc	/^void DataReader::read_corpus(Dict& sd, int kSRC_SOS, int kSRC_EOS, long part_size)$/;"	f	class:DataReader
read_corpus	examples/attentional.cc	/^Corpus read_corpus(const string &filename)$/;"	f
read_corpus	examples/mem_seq2seq_encdec.cc	/^Corpus read_corpus(const string &filename)$/;"	f
read_corpus	examples/seq2seq_encdec.cc	/^Corpus read_corpus(const string &filename)$/;"	f
read_corpus_with_classid	cnn/data-util.cc	/^CorpusWithClassId read_corpus_with_classid(const string &filename, Dict& sd, int kSRC_SOS, int kSRC_EOS)$/;"	f
read_data	ext/lda/lda.h	/^int ldaModel::read_data(const Corpus & training, const Dict& sd, const Corpus& testing)$/;"	f	class:ldaModel
read_documents	examples/skiprnnlm.cc	/^void read_documents(const std::string &filename, Corpus &corpus) {$/;"	f
read_embedding	cnn/data-util.cc	/^vector<cnn::real> read_embedding(const string& line, Dict& sd, int & index)$/;"	f
read_embedding	cnn/data-util.cc	/^void read_embedding(const string& embedding_fn, Dict& sd, map<int, vector<cnn::real>> & vWordEmbedding)$/;"	f
read_facebook_qa_corpus	cnn/data-util.cc	/^FBCorpus read_facebook_qa_corpus(const string &filename, size_t& diag_id, Dict& sd)$/;"	f
read_memory	cnn/rnnem.cc	/^    std::vector<Expression> NMNBuilder::read_memory(const int& t, const Expression & x_t, const size_t layer)$/;"	f	class:cnn::NMNBuilder
read_one_line_facebook_qa	cnn/data-util.cc	/^int read_one_line_facebook_qa(const std::string& line, std::vector<int>& v, Dict& sd)$/;"	f
read_tuple_corpus	cnn/data-util.cc	/^TupleCorpus read_tuple_corpus(const string &filename, Dict& sd, int kSRC_SOS, int kSRC_EOS, Dict& td, int kTGT_SOS, int kTGT_EOS, int maxSentLength)$/;"	f
real	cnn/macros.h	/^typedef double real;$/;"	t	namespace:cnn
rectify	cnn/expr.cc	/^Expression rectify(const Expression& x) { return Expression(x.pg, x.pg->add_function<Rectify>({ x.i })); }$/;"	f	namespace:cnn::expr
reduce	cnn/expr.cc	/^Expression reduce(const Expression& x) { return Expression(x.pg, x.pg->add_function<Reduce>({ x.i })); }$/;"	f	namespace:cnn::expr
reference	cnn/expr.cc	/^Expression reference(ComputationGraph& g, const Dim& d, const cnn::real* pdata) { return Expression(&g, g.add_reference(d, pdata)); }$/;"	f	namespace:cnn::expr
remove_first_and_last	cnn/data-util.cc	/^vector<int> remove_first_and_last(const vector<int>& rep)$/;"	f
remove_from_topic	ext/lda/lda.h	/^	inline int remove_from_topic(int word, int doc, int topic)$/;"	f	class:ldaModel
rep_hidden	ext/dialogue/attention_with_intention.h	/^    int rep_hidden;$/;"	m	class:cnn::DynamicMemoryNetDialogue
rep_hidden	ext/dialogue/dialogue.h	/^    int rep_hidden;$/;"	m	class:cnn::DialogueBuilder
rep_hidden	ext/encdec/encdec.h	/^    int rep_hidden;$/;"	m	class:cnn::EncModel
repeat	cnn/expr-xtra.cc	/^Expression repeat(ComputationGraph &cg, unsigned num, cnn::real value, std::vector<cnn::real> *aux_mem) $/;"	f
repnumber	ext/trainer/train_proc.h	/^int repnumber;$/;"	v
representative_presentation	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::representative_presentation($/;"	f	class:TrainProcess
reset	examples/cxtattentional.h	/^void CxtAttentionalModel<Builder>::reset(ComputationGraph & cg)$/;"	f	class:cnn::CxtAttentionalModel
reset	ext/dialogue/attention_with_intention.h	/^    void reset()$/;"	f	class:cnn::DynamicMemoryNetDialogue
reset	ext/dialogue/dialogue.h	/^    void reset()$/;"	f	class:cnn::DialogueBuilder
reset	ext/dialogue/dialogue_process.h	/^        void reset()$/;"	f	class:cnn::DialogueProcessInfo
reset	ext/encdec/encdec.h	/^    void reset()$/;"	f	class:cnn::EncModel
reset	ext/trainer/train_proc.h	/^    void reset()$/;"	f	struct:TrainingScores
reset_gradient	cnn/model.cc	/^void Model::reset_gradient() {$/;"	f	class:cnn::Model
reset_smoothed_ppl	ext/trainer/train_proc.h	/^    void reset_smoothed_ppl(){$/;"	f	class:TrainProcess
reset_to_zero	cnn/model.cc	/^void Parameters::reset_to_zero()$/;"	f	class:cnn::Parameters
reshape	cnn/expr.cc	/^Expression reshape(const Expression& x, const Dim& d) { return Expression(x.pg, x.pg->add_function<Reshape>({x.i}, d)); }$/;"	f	namespace:cnn::expr
resize	cnn/dim.h	/^  inline void resize(unsigned int i) { nd = i; }$/;"	f	struct:cnn::Dim
respond	cnn/approximator.cc	/^    vector<cnn::real> ClsBasedBuilder::respond(const Expression &in, ComputationGraph& cg) $/;"	f	class:cnn::ClsBasedBuilder
respond	ext/dialogue/dialogue_process.h	/^        int respond(vector<SentencePair> diag, Dict & td, bool bcharlevel = false)$/;"	f	class:cnn::DialogueProcessInfo
respond	ext/dialogue/dialogue_process.h	/^        int respond(vector<SentencePair> diag, vector<SentencePair>& results, Dict & td)$/;"	f	class:cnn::DialogueProcessInfo
respond	ext/dialogue/dialogue_process.h	/^        int respond(vector<SentencePair> diag, vector<SentencePair>& results, Dict & td, stId2String<string>& responses)$/;"	f	class:cnn::ClassificationBasedMultiSourceDialogue
respond	ext/dialogue/dialogue_process.h	/^        wstring respond(Model &model, wstring strquery, Dict<std::wstring>& td, bool bcharlevel = false)$/;"	f	class:cnn::DialogueProcessInfo
response_layer	ext/dialogue/attention_with_intention.h	/^    DNNBuilder response_layer;$/;"	m	class:cnn::AWI_InputFeedingWithNNAttention
restart	cnn/data-util.h	/^    void restart()$/;"	f	class:DataReader
rev_enc_builder	examples/encdec.cc	/^    Builder rev_enc_builder;$/;"	m	struct:EncoderDecoder	file:
rev_enc_builder	examples/seq2seq_encdec.cc	/^  Builder rev_enc_builder;$/;"	m	struct:EncoderDecoder	file:
rev_mapper	ext/lda/lda.h	/^	int *rev_mapper;$/;"	m	class:ldaModel
rewind_one_step	cnn/rnn.h	/^  void rewind_one_step() {$/;"	f	struct:cnn::RNNBuilder
rewind_one_step	cnn/rnnem.h	/^  void rewind_one_step() {$/;"	f	struct:cnn::NMNBuilder
rho	cnn/training.h	/^    cnn::real rho;$/;"	m	struct:cnn::RmsPropWithMomentumTrainer
rho	cnn/training.h	/^  cnn::real rho;$/;"	m	struct:cnn::AdadeltaTrainer
rho	cnn/training.h	/^  cnn::real rho;$/;"	m	struct:cnn::RmsPropTrainer
rl_build_graph	ext/dialogue/dialogue_process.h	/^        Expression rl_build_graph(ComputationGraph& cg)$/;"	f	class:cnn::RLAttentionWithIntentionModel
rndeng	cnn/init.cc	/^    mt19937* rndeng = nullptr;$/;"	m	namespace:cnn	file:
rnn_h0_for_each_utt	cnn/expr-xtra.cc	/^vector<vector<Expression>> rnn_h0_for_each_utt(vector<Expression> v_h0, unsigned nutt, unsigned feat_dim)$/;"	f
rnn_src_embeddings	examples/attentional.h	/^    bool rnn_src_embeddings;$/;"	m	struct:cnn::AttentionalModel
rnn_src_embeddings	examples/regattentional.h	/^    bool rnn_src_embeddings;$/;"	m	struct:cnn::RegAttentionalModel
round_up_align	cnn/aligned-mem-pool.h	/^  inline static size_t round_up_align(unsigned long n) {$/;"	f	class:cnn::AlignedMemoryPool
rowcol_matrix	cnn/tensor.h	/^  Eigen::Map<EMatrix, Eigen::Unaligned> rowcol_matrix() {$/;"	f	struct:cnn::Tensor
rowcol_matrix	cnn/tensor.h	/^  const Eigen::Map<EMatrix, Eigen::Unaligned> rowcol_matrix() const {$/;"	f	struct:cnn::Tensor
rows	cnn/dim.h	/^  inline unsigned int rows() const { return d[0]; }$/;"	f	struct:cnn::Dim
rows	cnn/nodes.h	/^    unsigned rows;$/;"	m	struct:cnn::ColumnSlices
s2tmodel	ext/dialogue/dialogue_process.h	/^        DBuilder s2tmodel;  \/\/\/ source to target $/;"	m	class:cnn::DialogueProcessInfo
s2txent	ext/dialogue/dialogue_process.h	/^        Expression s2txent;$/;"	m	class:cnn::DialogueProcessInfo
s_unk	cnn/dict.h	/^    T s_unk; $/;"	m	class:cnn::stDict
sample	examples/attentional.h	/^AttentionalModel<Builder>::sample(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict &tdict)$/;"	f	class:cnn::AttentionalModel
sample	examples/cxtattentional.h	/^CxtAttentionalModel<Builder>::sample(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict &tdict)$/;"	f	class:cnn::CxtAttentionalModel
sample	ext/dialogue/attention_with_intention.h	/^std::vector<int> AttentionWithIntention<Builder, Decoder>::sample(const std::vector<int> &source, ComputationGraph& cg, cnn::Dict &tdict)$/;"	f	class:cnn::AttentionWithIntention
sample	ext/encdec/encdec.h	/^    vector<vector<vector<cnn::real>>> sample(vector<Expression> & mean_var, ComputationGraph& cg, size_t nsamples = 1)$/;"	f	class:cnn::EncModel
sampling	ext/lda/lda.h	/^int ldaModel::sampling(int m)$/;"	f	class:ldaModel
sanity	ext/lda/lda.h	/^int ldaModel::sanity() const$/;"	f	class:ldaModel
save	cnn/model.h	/^    void save(Archive& ar, const unsigned int version) const {$/;"	f	class:cnn::Model
save	cnn/model.h	/^  void save(Archive& ar, const unsigned int) const {$/;"	f	struct:cnn::LookupParameters
save	cnn/tensor.h	/^  void save(Archive& ar, const unsigned int) const {$/;"	f	struct:cnn::Tensor
save	ext/lda/lda.h	/^    template<class Archive> void save(Archive& ar, const unsigned int version) const {$/;"	f	class:ldaModel
save_cnn_model	cnn/model.cc	/^void save_cnn_model(std::string filename, Model* model) {$/;"	f	namespace:cnn
save_context	ext/dialogue/cxtencdec.h	/^    void save_context(ComputationGraph& cg)$/;"	f	class:cnn::Seq2SeqEncDecModel
save_context	ext/dialogue/dialogue.h	/^    void save_context(ComputationGraph& cg)$/;"	f	class:cnn::DialogueBuilder
save_ldaModel	ext/lda/lda.h	/^int ldaModel::save_ldaModel(int iter) const$/;"	f	class:ldaModel
save_ldaModel_llh	ext/lda/lda.h	/^int ldaModel::save_ldaModel_llh(std::string filename) const$/;"	f	class:ldaModel
save_ldaModel_phi	ext/lda/lda.h	/^int ldaModel::save_ldaModel_phi(std::string filename) const$/;"	f	class:ldaModel
save_ldaModel_time	ext/lda/lda.h	/^int ldaModel::save_ldaModel_time(std::string filename) const$/;"	f	class:ldaModel
save_ldaModel_topWords	ext/lda/lda.h	/^int ldaModel::save_ldaModel_topWords(std::string filename, Dict& sd) const$/;"	f	class:ldaModel
saxpy_functor	cnn/functors.h	/^    saxpy_functor(cnn::real _a) : a(_a) {}$/;"	f	struct:cnn::saxpy_functor
saxpy_functor	cnn/functors.h	/^struct saxpy_functor$/;"	s	namespace:cnn
scalar	cnn/functors.h	/^  const cnn::real* scalar;$/;"	m	struct:cnn::FEuclideanBackward
scalar_erf_backward_op	cnn/simd-functors.h	/^template<typename Scalar> struct scalar_erf_backward_op {$/;"	s	namespace:cnn
scalar_logistic_sigmoid_backward_op	cnn/simd-functors.h	/^template<typename Scalar> struct scalar_logistic_sigmoid_backward_op {$/;"	s	namespace:cnn
scalar_logistic_sigmoid_op	cnn/simd-functors.h	/^template<typename Scalar> struct scalar_logistic_sigmoid_op {$/;"	s	namespace:cnn
scalar_nlsoftmax_backward_op	cnn/simd-functors.h	/^  scalar_nlsoftmax_backward_op(const Scalar& lz, const Scalar& err) : logz(lz), d(err) {}$/;"	f	struct:cnn::scalar_nlsoftmax_backward_op
scalar_nlsoftmax_backward_op	cnn/simd-functors.h	/^template<typename Scalar> struct scalar_nlsoftmax_backward_op {$/;"	s	namespace:cnn
scalar_tanh_backward_op	cnn/simd-functors.h	/^template<typename Scalar> struct scalar_tanh_backward_op {$/;"	s	namespace:cnn
scalar_tanh_op	cnn/simd-functors.h	/^template<typename Scalar> struct scalar_tanh_op {$/;"	s	namespace:cnn
scale	cnn/functors.h	/^    cnn::real *scale;$/;"	m	struct:cnn::FL2SGDUpdatePtrArguments
scale	cnn/functors.h	/^    cnn::real scale;$/;"	m	struct:cnn::FL2SGDMomentumUpdate
scale	cnn/functors.h	/^    cnn::real scale;$/;"	m	struct:cnn::FL2SGDMomentumWithDenUpdate
scale	cnn/functors.h	/^    cnn::real scale;$/;"	m	struct:cnn::FL2SGDUpdate
scale	cnn/nodes.h	/^    cnn::real scale; \/\/\/ scale in the negative part of inputs$/;"	m	struct:cnn::ExponentialLinearUnits
scale_functor	cnn/functors.h	/^    scale_functor(cnn::real _a) : a(_a) {}$/;"	f	struct:cnn::scale_functor
scale_functor	cnn/functors.h	/^struct scale_functor$/;"	s	namespace:cnn
scale_parameters	cnn/model.cc	/^void LookupParameters::scale_parameters(cnn::real a) {$/;"	f	class:cnn::LookupParameters
scale_parameters	cnn/model.cc	/^void Parameters::scale_parameters(cnn::real a) {$/;"	f	class:cnn::Parameters
score	ext/trainer/eval_proc.h	/^Expression EvaluateProcess<Proc>::score(const vector<int>& ref, const vector<int>& res, ComputationGraph& cg)$/;"	f	class:EvaluateProcess
score	ext/trainer/eval_proc.h	/^cnn::real EvaluateProcess<Proc>::score(Expression er, ComputationGraph& cg)$/;"	f	class:EvaluateProcess
scoreInEmbeddingSpace	ext/trainer/eval_proc.h	/^int EvaluateProcess<AM_t>::scoreInEmbeddingSpace(AM_t &am, Dialogue &v_v_dialogues, Dict& td, cnn::real &dloss, cnn::real & dchars_s, cnn::real & dchars_t)$/;"	f	class:EvaluateProcess
sd	examples/attentional.cc	/^cnn::Dict sd;$/;"	v
sd	examples/embed-cl.cc	/^cnn::Dict sd;$/;"	v
sd	examples/mem_seq2seq_encdec.cc	/^cnn::Dict sd, td;$/;"	v
sd	examples/seq2seq_encdec.cc	/^cnn::Dict sd, td;$/;"	v
sd	ext/trainer/train_proc.h	/^cnn::Dict sd;$/;"	v
segmental_forward_backward	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::segmental_forward_backward(Model &model, AM_t &am, PDialogue &v_v_dialogues, int nutt, TrainingScores * scores, bool resetmodel, bool doGradientCheck, Trainer* sgd)$/;"	f	class:TrainProcess
select_trainer	ext/trainer/train_proc_wrapper.h	/^Trainer* select_trainer(variables_map vm, Model* model)$/;"	f
sentence_distance	ext/dialogue/dialogue_process.h	/^        cnn::real sentence_distance(const Sentence& sentencea, const Sentence& sentenceb)$/;"	f	class:cnn::DialogueProcessInfo
sentence_embedding	ext/dialogue/dialogue.h	/^    Expression sentence_embedding(const Sentence& sent, ComputationGraph& cg)$/;"	f	class:cnn::DialogueBuilder
sentence_embedding	ext/dialogue/dialogue_process.h	/^        vector<cnn::real> sentence_embedding(const Sentence& sentence)$/;"	f	class:cnn::DialogueProcessInfo
serialise	ext/dialogue/dialogue.h	/^    void serialise(ComputationGraph& cg, Builder& combiner)$/;"	f	class:cnn::DialogueBuilder
serialise_context	ext/dialogue/attention_with_intention.h	/^    void serialise_context(ComputationGraph& cg)$/;"	f	class:cnn::DynamicMemoryNetDialogue
serialise_context	ext/dialogue/attention_with_intention.h	/^    void serialise_context(ComputationGraph& cg)$/;"	f	class:cnn::MultiSource_LinearEncoder
serialise_context	ext/dialogue/dialogue.h	/^    void serialise_context(ComputationGraph& cg)$/;"	f	class:cnn::DialogueBuilder
serialise_context	ext/ir/ir.h	/^        void serialise_context(ComputationGraph& cg)$/;"	f	class:cnn::ClassificationEncoderDecoder
serialise_context	ext/ir/ir.h	/^        void serialise_context(ComputationGraph& cg,$/;"	f	class:cnn::ClassificationEncoderDecoder
serialise_cxt	ext/dialogue/dialogue_process.h	/^        void serialise_cxt(ComputationGraph& cg)$/;"	f	class:cnn::DialogueProcessInfo
serialization	cnn/dim.h	/^namespace boost { namespace serialization { class access; } }$/;"	n	namespace:boost
serialize	cnn/dict.h	/^    template<class Archive> void serialize(Archive& ar, const unsigned int) {$/;"	f	class:cnn::stId2String
serialize	cnn/dict.h	/^  template<class Archive> void serialize(Archive& ar, const unsigned int) {$/;"	f	class:cnn::stDict
serialize	cnn/dim.h	/^  template<class Archive> void serialize(Archive& ar, const unsigned int) {$/;"	f	struct:cnn::Dim
serialize	cnn/model.h	/^  template<class Archive> void serialize(Archive& ar, const unsigned int version) {$/;"	f	struct:cnn::Parameters
serialize	ext/ngram/ngram.h	/^    template<class Archive> void serialize(Archive& ar, const unsigned int version) {$/;"	f	class:nGram
set	cnn/dim.h	/^  inline void set(unsigned int i, unsigned int s) { assert(i < nd); assert(s > 0); d[i] = s; }$/;"	f	struct:cnn::Dim
setAlignDim	ext/dialogue/attention_with_intention.h	/^void AttentionWithIntention<Builder, Decoder>::setAlignDim(cnn::Model& model, unsigned alignd, cnn::real iscale)$/;"	f	class:cnn::AttentionWithIntention
set_data_in_parallel	cnn/approximator.cc	/^    void ClsBasedBuilder::set_data_in_parallel(int n)$/;"	f	class:cnn::ClsBasedBuilder
set_data_in_parallel	cnn/dglstm.cc	/^void DGLSTMBuilder::set_data_in_parallel(int n)$/;"	f	class:cnn::DGLSTMBuilder
set_data_in_parallel	cnn/dnn.cc	/^    void DNNBuilder::set_data_in_parallel(int n)$/;"	f	class:cnn::DNNBuilder
set_data_in_parallel	cnn/gru.cc	/^void GRUBuilder::set_data_in_parallel(int n)$/;"	f	class:cnn::GRUBuilder
set_data_in_parallel	cnn/lstm.cc	/^void LSTMBuilder::set_data_in_parallel(int n)$/;"	f	class:cnn::LSTMBuilder
set_data_in_parallel	cnn/rnn.cc	/^void SimpleRNNBuilder::set_data_in_parallel(int n)$/;"	f	class:cnn::SimpleRNNBuilder
set_data_in_parallel	cnn/rnn.h	/^  void set_data_in_parallel(int n) { dparallel = n; }$/;"	f	struct:cnn::RNNBuilder
set_dim_for_new_node	cnn/cnn.cc	/^void ComputationGraph::set_dim_for_new_node(const VariableIndex& i) {$/;"	f	class:cnn::ComputationGraph
set_dims	ext/trainer/train_proc_wrapper.h	/^vector<unsigned> set_dims(variables_map vm)$/;"	f
set_last_node_evaluated	cnn/cnn.cc	/^void ComputationGraph::set_last_node_evaluated(VariableIndex idx){$/;"	f	class:cnn::ComputationGraph
set_last_node_evaluated	cnn/exec.cc	/^void SimpleExecutionEngine::set_last_node_evaluated(VariableIndex idx)$/;"	f	class:cnn::SimpleExecutionEngine
set_value	cnn/cnn.cc	/^void  ComputationGraph::set_value(const Tensor& t, VariableIndex i) { ee->set_value(t, i); }$/;"	f	class:cnn::ComputationGraph
set_value	cnn/cnn.cc	/^void  ComputationGraph::set_value(const Tensor& t, expr::Expression& e) { ee->set_value(t, e.i); }$/;"	f	class:cnn::ComputationGraph
set_value	cnn/exec.cc	/^void SimpleExecutionEngine::set_value(const Tensor& t, VariableIndex i) {$/;"	f	class:cnn::SimpleExecutionEngine
sgn	cnn/functors.h	/^template <typename T> int sgn(T val) {$/;"	f	namespace:cnn
shadow_params_allocated	cnn/training.h	/^    bool shadow_params_allocated;$/;"	m	struct:cnn::RmsPropWithMomentumTrainer
shadow_params_allocated	cnn/training.h	/^  bool shadow_params_allocated;$/;"	m	struct:cnn::AdadeltaTrainer
shadow_params_allocated	cnn/training.h	/^  bool shadow_params_allocated;$/;"	m	struct:cnn::AdagradTrainer
shadow_params_allocated	cnn/training.h	/^  bool shadow_params_allocated;$/;"	m	struct:cnn::AdamTrainer
shadow_params_allocated	cnn/training.h	/^  bool shadow_params_allocated;$/;"	m	struct:cnn::RmsPropTrainer
shared_memory	examples/mp.cc	/^SharedObject* shared_memory = nullptr;$/;"	v
shuffle_data	cnn/data-util.cc	/^Expression shuffle_data(Expression src, unsigned nutt, unsigned feat_dim, unsigned slen)$/;"	f
shuffle_data	cnn/data-util.cc	/^vector<Expression> shuffle_data(Expression src, unsigned nutt, unsigned feat_dim, const vector<unsigned>& v_slen)$/;"	f
similar_length	cnn/expr-xtra.cc	/^bool similar_length(const vector<vector<int>>& source)$/;"	f
single_batch	cnn/dim.h	/^  inline Dim single_batch() const {$/;"	f	struct:cnn::Dim
size	cnn/dict.h	/^    inline unsigned size() const { return words_.size(); }$/;"	f	class:cnn::stId2String
size	cnn/dict.h	/^  inline unsigned size() const { return words_.size(); }$/;"	f	class:cnn::stDict
size	cnn/dim.h	/^  inline unsigned int size() const {$/;"	f	struct:cnn::Dim
size	cnn/dim.h	/^  inline unsigned int size(unsigned int i) const { return (*this)[i]; }$/;"	f	struct:cnn::Dim
size	cnn/model.cc	/^size_t LookupParameters::size() const {$/;"	f	class:cnn::LookupParameters
size	cnn/model.cc	/^size_t Parameters::size() const { return dim.size(); }$/;"	f	class:cnn::Parameters
size	cnn/tests/test_edges.cc	/^Dim size(const Tensor& t) {$/;"	f
slen	examples/attentional.h	/^    unsigned slen;$/;"	m	struct:cnn::AttentionalModel
slen	examples/cxtattentional.h	/^    unsigned slen; \/\/\/ session length so far$/;"	m	struct:cnn::CxtAttentionalModel
slen	examples/regattentional.h	/^    unsigned slen;$/;"	m	struct:cnn::RegAttentionalModel
slen	ext/dialogue/attention_with_intention.h	/^    unsigned slen;$/;"	m	class:cnn::DynamicMemoryNetDialogue
slen	ext/dialogue/dialogue.h	/^    unsigned slen;$/;"	m	class:cnn::DialogueBuilder
slen	ext/encdec/encdec.h	/^    unsigned slen;$/;"	m	class:cnn::EncModel
slowReduceKernel	cnn/gpu-kernels.h	/^__global__ void slowReduceKernel(int n, const cnn::real* x0, const cnn::real* x1, cnn::real* y, Func func)$/;"	f	namespace:cnn::gpu
sm	cnn/rnn.h	/^  RNNStateMachine sm;$/;"	m	struct:cnn::RNNBuilder
smoothed_ppl	ext/trainer/train_proc.h	/^cnn::real TrainProcess<AM_t>::smoothed_ppl(cnn::real curPPL)$/;"	f	class:TrainProcess
softmax	cnn/expr.cc	/^Expression softmax(const Expression& x) { return Expression(x.pg, x.pg->add_function<Softmax>({x.i})); }$/;"	f	namespace:cnn::expr
softmax	cnn/functors.h	/^void softmax(int row, int col, const ElemType* a, ElemType* v, const bool isColWise)$/;"	f	namespace:cnn
softsign	cnn/expr.cc	/^Expression softsign(const Expression& x) { return Expression(x.pg, x.pg->add_function<SoftSign>({x.i})); }$/;"	f	namespace:cnn::expr
specific_init	ext/lda/lda.h	/^	virtual int specific_init() { return 0; }	\/\/ if sampling algo need some specific inits$/;"	f	class:ldaModel
split_data_batch_train	ext/trainer/train_proc.h	/^void ClassificationTrainProcess<AM_t>::split_data_batch_train(string train_filename, Model &model, AM_t &am, Corpus &devel,$/;"	f	class:ClassificationTrainProcess
split_data_batch_train	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::split_data_batch_train(string train_filename, Model &model, AM_t &am, Corpus &devel, $/;"	f	class:TrainProcess
sqrt	cnn/expr.cc	/^Expression sqrt(const Expression& x) { return Expression(x.pg, x.pg->add_function<Sqrt>({x.i})); }$/;"	f	namespace:cnn::expr
square	cnn/expr.cc	/^Expression square(const Expression& x) { return Expression(x.pg, x.pg->add_function<Square>({x.i})); }$/;"	f	namespace:cnn::expr
squared_distance	cnn/expr.cc	/^Expression squared_distance(const Expression& x, const Expression& y) { return Expression(x.pg, x.pg->add_function<SquaredEuclideanDistance>({x.i, y.i})); }$/;"	f	namespace:cnn::expr
squared_l2norm	cnn/model.cc	/^void LookupParameters::squared_l2norm(cnn::real* sqnorm) const {$/;"	f	class:cnn::LookupParameters
squared_l2norm	cnn/model.cc	/^void Parameters::squared_l2norm(cnn::real* sqnorm) const {$/;"	f	class:cnn::Parameters
src	examples/attentional.h	/^    Expression src;$/;"	m	struct:cnn::AttentionalModel
src	examples/cxtattentional.h	/^    Expression src;$/;"	m	struct:cnn::CxtAttentionalModel
src	examples/regattentional.h	/^    Expression src;$/;"	m	struct:cnn::RegAttentionalModel
src	ext/dialogue/attention_with_intention.h	/^    Expression src;$/;"	m	class:cnn::DynamicMemoryNetDialogue
src	ext/dialogue/dialogue.h	/^    Expression src;$/;"	m	class:cnn::DialogueBuilder
src	ext/encdec/encdec.h	/^    Expression src;$/;"	m	class:cnn::EncModel
src_bwd	examples/regattentional.h	/^    std::vector<Expression> src_fwd, src_bwd;$/;"	m	struct:cnn::RegAttentionalModel
src_fwd	examples/regattentional.h	/^    std::vector<Expression> src_fwd, src_bwd;$/;"	m	struct:cnn::RegAttentionalModel
src_fwd	ext/dialogue/attention_with_intention.h	/^    Expression src_fwd;$/;"	m	class:cnn::DynamicMemoryNetDialogue
src_fwd	ext/dialogue/dialogue.h	/^    Expression src_fwd;$/;"	m	class:cnn::DialogueBuilder
src_fwd	ext/encdec/encdec.h	/^    Expression src_fwd;$/;"	m	class:cnn::EncModel
src_len	ext/dialogue/attention_with_intention.h	/^    std::vector<size_t> src_len;$/;"	m	class:cnn::DynamicMemoryNetDialogue
src_len	ext/dialogue/dialogue.h	/^    std::vector<unsigned> src_len;$/;"	m	class:cnn::DialogueBuilder
src_len	ext/encdec/encdec.h	/^    std::vector<unsigned> src_len;$/;"	m	class:cnn::EncModel
src_row_indices	cnn/nodes.h	/^  mutable std::vector<unsigned> src_row_indices;$/;"	m	struct:cnn::Concatenate
src_words	ext/dialogue/attention_with_intention.h	/^    size_t src_words;$/;"	m	class:cnn::DynamicMemoryNetDialogue
src_words	ext/dialogue/dialogue.h	/^    size_t src_words;$/;"	m	class:cnn::DialogueBuilder
src_words	ext/encdec/encdec.h	/^    size_t src_words;$/;"	m	class:cnn::EncModel
stDict	cnn/dict.h	/^  stDict() : frozen(false) {$/;"	f	class:cnn::stDict
stDict	cnn/dict.h	/^class stDict {$/;"	c	namespace:cnn
stId2String	cnn/dict.h	/^    stId2String() : frozen(false) {$/;"	f	class:cnn::stId2String
stId2String	cnn/dict.h	/^class stId2String {$/;"	c	namespace:cnn
start	cnn/data-util.h	/^    void start(Dict& sd, int kSRC_SOS, int kSRC_EOS, long part_size)$/;"	f	class:DataReader
start	cnn/nodes.h	/^  unsigned start;$/;"	m	struct:cnn::PickRange
start	cnn/timing.h	/^  std::chrono::high_resolution_clock::time_point start;$/;"	m	struct:cnn::Timer
start_column	cnn/nodes.h	/^    unsigned start_column;$/;"	m	struct:cnn::ColumnSlices
start_new_instance	examples/attentional.h	/^void AttentionalModel<Builder>::start_new_instance(const std::vector<int> &source, ComputationGraph &cg)$/;"	f	class:cnn::AttentionalModel
start_new_instance	examples/attentional.h	/^void AttentionalModel<Builder>::start_new_instance(const std::vector<int> &source, ComputationGraph &cg, vector<Expression>& decoderInit)$/;"	f	class:cnn::AttentionalModel
start_new_instance	examples/cxtattentional.h	/^void CxtAttentionalModel<Builder>::start_new_instance(const std::vector<int> &source, ComputationGraph& cg)$/;"	f	class:cnn::CxtAttentionalModel
start_new_instance	examples/regattentional.h	/^void RegAttentionalModel<Builder>::start_new_instance(FCorpus& source, FCorpus& target, size_t mbsize, ComputationGraph &cg)$/;"	f	class:cnn::RegAttentionalModel
start_new_instance	examples/regattentional.h	/^void RegAttentionalModel<Builder>::start_new_instance(const std::vector<vector<cnn::real>> &source, ComputationGraph &cg)$/;"	f	class:cnn::RegAttentionalModel
start_new_instance	ext/dialogue/attention_with_intention.h	/^    void start_new_instance(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::AttMultiSource_LinearEncoder
start_new_instance	ext/dialogue/attention_with_intention.h	/^    void start_new_instance(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
start_new_instance	ext/dialogue/attention_with_intention.h	/^    void start_new_instance(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
start_new_instance	ext/dialogue/attention_with_intention.h	/^    void start_new_instance(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch
start_new_instance	ext/dialogue/attention_with_intention.h	/^    void start_new_instance(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::ClsBasedMultiSource_LinearEncoder
start_new_instance	ext/dialogue/attention_with_intention.h	/^    void start_new_instance(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::MultiSource_LinearEncoder
start_new_instance	ext/dialogue/attention_with_intention.h	/^    void start_new_instance(const std::vector<std::vector<int>> &source, ComputationGraph &cg)$/;"	f	class:cnn::DynamicMemoryNetDialogue
start_new_instance	ext/dialogue/dialogue.h	/^     virtual void start_new_instance(const std::vector<std::vector<int>> &source, ComputationGraph &cg) $/;"	f	class:cnn::DialogueBuilder
start_new_instance	ext/dialogue/dialogue.h	/^     void start_new_instance(const std::vector<std::vector<int>> &source,$/;"	f	class:cnn::DialogueBuilder
start_new_instance	ext/encdec/encdec.h	/^    virtual Expression start_new_instance(const std::vector<std::vector<int>> &source, ComputationGraph &cg)$/;"	f	class:cnn::EncModel
start_new_instance	ext/ir/ir.h	/^        void start_new_instance(const std::vector<std::vector<int>> &prv_response,$/;"	f	class:cnn::ClassificationEncoderDecoder
start_new_instance	ext/ir/ir.h	/^        void start_new_instance(const std::vector<std::vector<int>> &source, ComputationGraph &cg)$/;"	f	class:cnn::ClassificationEncoderDecoder
start_new_sequence	cnn/approximator.h	/^        void start_new_sequence() {$/;"	f	class:cnn::ClsBasedBuilder
start_new_sequence	cnn/dnn.h	/^        void start_new_sequence(const std::vector<Expression>& h_0 = {}) {$/;"	f	class:cnn::DNNBuilder
start_new_sequence	cnn/rnn-state-machine.h	/^enum RNNOp {new_graph, start_new_sequence, add_input};$/;"	e	enum:cnn::RNNOp
start_new_sequence	cnn/rnn.h	/^  void start_new_sequence(const std::vector<Expression>& h_0={}) {$/;"	f	struct:cnn::RNNBuilder
start_new_sequence_impl	cnn/deep-lstm.cc	/^void DeepLSTMBuilder::start_new_sequence_impl(const vector<Expression>& hinit) {$/;"	f	class:cnn::DeepLSTMBuilder
start_new_sequence_impl	cnn/dglstm.cc	/^void DGLSTMBuilder::start_new_sequence_impl(const vector<Expression>& hinit) {$/;"	f	class:cnn::DGLSTMBuilder
start_new_sequence_impl	cnn/gru.cc	/^void GRUBuilder::start_new_sequence_impl(const std::vector<Expression>& h_0) {$/;"	f	class:cnn::GRUBuilder
start_new_sequence_impl	cnn/lstm.cc	/^void LSTMBuilder::start_new_sequence_impl(const vector<Expression>& hinit) {$/;"	f	class:cnn::LSTMBuilder
start_new_sequence_impl	cnn/rnn.cc	/^void SimpleRNNBuilder::start_new_sequence_impl(const vector<Expression>& h_0) {$/;"	f	class:cnn::SimpleRNNBuilder
start_new_sequence_impl	cnn/rnnem.cc	/^    void NMNBuilder::start_new_sequence_impl(const vector<Expression>& hinit) {$/;"	f	class:cnn::NMNBuilder
start_new_sequence_impl	cnn/treelstm.cc	/^void TreeLSTMBuilder::start_new_sequence_impl(const vector<Expression>& hinit) {$/;"	f	class:cnn::TreeLSTMBuilder
start_new_single_instance	ext/dialogue/attention_with_intention.h	/^    void start_new_single_instance(const std::vector<int> &prv_response, const std::vector<int> &src, ComputationGraph &cg)$/;"	f	class:cnn::AttMultiSource_LinearEncoder
start_new_single_instance	ext/dialogue/attention_with_intention.h	/^    void start_new_single_instance(const std::vector<int> &prv_response, const std::vector<int> &src, ComputationGraph &cg)$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
start_new_single_instance	ext/dialogue/attention_with_intention.h	/^    void start_new_single_instance(const std::vector<int> &prv_response, const std::vector<int> &src, ComputationGraph &cg)$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
start_new_single_instance	ext/dialogue/attention_with_intention.h	/^    void start_new_single_instance(const std::vector<int> &prv_response, const std::vector<int> &src, ComputationGraph &cg)$/;"	f	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature_AndGlobalDirectFeature_Batch
start_new_single_instance	ext/dialogue/attention_with_intention.h	/^    void start_new_single_instance(const std::vector<int> &prv_response, const std::vector<int> &src, ComputationGraph &cg)$/;"	f	class:cnn::ClsBasedMultiSource_LinearEncoder
start_new_single_instance	ext/dialogue/attention_with_intention.h	/^    void start_new_single_instance(const std::vector<int> &prv_response, const std::vector<int> &src, ComputationGraph &cg)$/;"	f	class:cnn::MultiSource_LinearEncoder
start_new_single_instance	ext/dialogue/attention_with_intention.h	/^    void start_new_single_instance(const std::vector<int> &src, ComputationGraph &cg)$/;"	f	class:cnn::DynamicMemoryNetDialogue
start_new_single_instance	ext/dialogue/dialogue.h	/^     void start_new_single_instance(const std::vector<int> &src, ComputationGraph &cg)$/;"	f	class:cnn::DialogueBuilder
start_new_single_instance	ext/ir/ir.h	/^        void start_new_single_instance(const std::vector<int> &prv_response, const std::vector<int> &src, ComputationGraph &cg)$/;"	f	class:cnn::ClassificationEncoderDecoder
state	cnn/rnn.h	/^  RNNPointer state() const { return cur; }$/;"	f	struct:cnn::RNNBuilder
status	cnn/training.h	/^  void status() {$/;"	f	struct:cnn::Trainer
stddev	cnn/nodes.h	/^  cnn::real stddev;$/;"	m	struct:cnn::GaussianNoise
step	examples/regattentional.h	/^Expression RegAttentionalModel<Builder>::step(int t, ComputationGraph &cg, RNNPointer *prev_state)$/;"	f	class:cnn::RegAttentionalModel
step	examples/regattentional.h	/^Expression RegAttentionalModel<Builder>::step(int t, ComputationGraph &cg, size_t nutt, RNNPointer *prev_state)$/;"	f	class:cnn::RegAttentionalModel
sum	cnn/expr.h	/^inline Expression sum(const T& xs) { return detail::f<Sum>(xs); }$/;"	f	namespace:cnn::expr
sum	cnn/expr.h	/^inline Expression sum(const std::initializer_list<Expression>& xs) { return detail::f<Sum>(xs); }$/;"	f	namespace:cnn::expr
sum_batches	cnn/expr.cc	/^Expression sum_batches(const Expression& x) { return Expression(x.pg, x.pg->add_function<SumBatches>({x.i})); }$/;"	f	namespace:cnn::expr
sum_cols	cnn/expr.cc	/^Expression sum_cols(const Expression& x) { return Expression(x.pg, x.pg->add_function<SumColumns>({x.i})); }$/;"	f	namespace:cnn::expr
sum_dims	cnn/dim.h	/^  inline unsigned int sum_dims() const {$/;"	f	struct:cnn::Dim
supervised_pretrain	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::supervised_pretrain(Model &model, AM_t &am, Corpus &training, Corpus &devel,$/;"	f	class:TrainProcess
supports_multibatch	cnn/cnn.h	/^  virtual bool supports_multibatch() const { return false; }$/;"	f	struct:cnn::Node
swap	cnn/cnn.h	/^inline void swap(VariableIndex& i1, VariableIndex& i2) {$/;"	f	namespace:cnn
swap	cnn/rnn.h	/^inline void swap(RNNPointer& i1, RNNPointer& i2) {$/;"	f	namespace:cnn
swords	ext/dialogue/dialogue_process.h	/^        int swords;$/;"	m	class:cnn::DialogueProcessInfo
swords	ext/trainer/train_proc.h	/^    long swords; \/\/\/ source side number of words$/;"	m	struct:TrainingScores
sys	exp/lm/create_lm_class.py	/^import sys$/;"	i
sys	exp/lm/lm.py	/^import sys$/;"	i
sys_alloc	cnn/aligned-mem-pool.h	/^  void sys_alloc(unsigned long cap) {$/;"	f	class:cnn::AlignedMemoryPool
t	cnn/decode.h	/^    int t;$/;"	m	struct:cnn::Hypothesis
t	cnn/tests/test_utils.h	/^double t(const Tensor& T, unsigned i, unsigned j) {$/;"	f	namespace:cnn
t	examples/attentional.h	/^    int t;$/;"	m	struct:cnn::Hypothesis
t	examples/cxtattentional.h	/^    int t;$/;"	m	struct:cnn::Hypothesis
tBiCount	ext/ngram/ngram.h	/^typedef std::map<pair<int,int>, int> tBiCount;$/;"	t
tBigram	ext/ngram/ngram.h	/^typedef std::map<pair<int, int>, cnn::real>  tBigram;  \/\/\/ bigram$/;"	t
tExpression	cnn/expr-xtra.h	/^typedef std::map<size_t, Expression> tExpression;$/;"	t
tUniCount	ext/ngram/ngram.h	/^typedef std::map<int, int> tUniCount;$/;"	t
tUnigram	ext/ngram/ngram.h	/^typedef std::map<int, cnn::real>  tUnigram;  \/\/\/ unigram$/;"	t
tWord2TfIdf	cnn/dict.h	/^typedef boost::unordered::unordered_map<std::string, cnn::real> tWord2TfIdf;$/;"	t	namespace:cnn
tWordid2TfIdf	cnn/dict.h	/^typedef boost::unordered::unordered_map<int, cnn::real> tWordid2TfIdf;$/;"	t	namespace:cnn
tanh	cnn/expr.cc	/^Expression tanh(const Expression& x) { return Expression(x.pg, x.pg->add_function<Tanh>({x.i})); }$/;"	f	namespace:cnn::expr
target	cnn/decode.h	/^    std::vector<int> target;$/;"	m	struct:cnn::Hypothesis
target	examples/attentional.h	/^    std::vector<int> target;$/;"	m	struct:cnn::Hypothesis
target	examples/cxtattentional.h	/^    std::vector<int> target;$/;"	m	struct:cnn::Hypothesis
td	examples/attentional.cc	/^cnn::Dict td;$/;"	v
td	examples/embed-cl.cc	/^cnn::Dict td;$/;"	v
td	examples/mem_seq2seq_encdec.cc	/^cnn::Dict sd, td;$/;"	v
td	examples/seq2seq_encdec.cc	/^cnn::Dict sd, td;$/;"	v
td	examples/tag-bilstm.cc	/^cnn::Dict td;$/;"	v
td	ext/trainer/train_proc.h	/^cnn::Dict td;$/;"	v
temp_b	examples/mp.cc	/^  cnn::real temp_b;$/;"	m	struct:SharedObject	file:
temp_m	examples/mp.cc	/^  cnn::real temp_m;$/;"	m	struct:SharedObject	file:
test	examples/attentional.cc	/^void test(Model &model, AM_t &am, Corpus &devel, string out_file)$/;"	f
test	examples/attentional.cc	/^void test(Model &model, AM_t &am, string test_file)$/;"	f
test	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.bat	/^:test$/;"	l
test	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.10k.test.bat	/^:test$/;"	l
test	exp/dialogue/s41.rmspropwithmomentum.gru.AWI_InputFeedingDropout.s01.eta.hd.i50.bat	/^:test$/;"	l
test	ext/lda/lda.h	/^int ldaModel::test(Dict& sd)$/;"	f	class:ldaModel
test	ext/lda/lda.h	/^int ldaModel::test(Dict& sd, const SentencePair& obs)$/;"	f	class:ldaModel
test	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::test(Model &model, AM_t &am, Corpus &devel, string out_file, Dict & sd)$/;"	f	class:TrainProcess
test	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::test(Model &model, AM_t &am, Corpus &devel, string out_file, Dict & td, NumTurn2DialogId& test_corpusinfo,$/;"	f	class:TrainProcess
test	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::test(Model &model, AM_t &am, TupleCorpus &devel, string out_file, Dict & sd, Dict & td)$/;"	f	class:TrainProcess
testPPL	ext/trainer/train_proc.h	/^cnn::real TrainProcess<AM_t>::testPPL(Model &model, AM_t &am, Corpus &devel, NumTurn2DialogId&  test_corpusinfo, string out_file, bool segmental_training, cnn::real & ddchars_s, cnn::real& ddchars_t)$/;"	f	class:TrainProcess
test_M	ext/lda/lda.h	/^	int test_M;$/;"	m	class:ldaModel
test_kbest_arcs	examples/attentional.cc	/^void test_kbest_arcs(Model &model, AM_t &am, string test_file, int top_k)$/;"	f
test_n_iters	ext/lda/lda.h	/^	int test_n_iters;$/;"	m	class:ldaModel
test_n_k	ext/lda/lda.h	/^	int * test_n_k;$/;"	m	class:ldaModel
test_n_mk	ext/lda/lda.h	/^	int ** test_n_mk;$/;"	m	class:ldaModel
test_n_wk	ext/lda/lda.h	/^	int ** test_n_wk;$/;"	m	class:ldaModel
test_numturn2did	ext/trainer/train_proc.h	/^NumTurn2DialogId test_numturn2did;$/;"	v
test_rescore	examples/attentional.cc	/^void test_rescore(Model &model, AM_t &am, string test_file, string out_file)$/;"	f
test_segmental	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::test_segmental(Model &model, AM_t &am, Corpus &devel, string out_file, Dict & sd)$/;"	f	class:TrainProcess
test_z	ext/lda/lda.h	/^	int ** test_z;$/;"	m	class:ldaModel
testcorpus	examples/rnnlm2.cc	/^void testcorpus(Model &model, LM_t &lm,$/;"	f
testcorpus	examples/rnnlm2_cls_based.cc	/^void testcorpus(Model &model, LM_t &lm,$/;"	f
testdata	ext/lda/lda.h	/^	Sentences testdata;				\/\/ test dataset$/;"	m	class:ldaModel
testing_type	ext/lda/lda.h	/^	} testing_type;$/;"	m	class:ldaModel	typeref:enum:ldaModel::__anon22
testresponses	ext/lda/lda.h	/^    Sentences testresponses;         \/\/ responses$/;"	m	class:ldaModel
tfile	ext/lda/lda.h	/^	const Corpus& tfile;				\/\/ test data corpus $/;"	m	class:ldaModel
tgt_words	ext/dialogue/attention_with_intention.h	/^    size_t tgt_words;$/;"	m	class:cnn::DynamicMemoryNetDialogue
tgt_words	ext/dialogue/dialogue.h	/^    size_t tgt_words;$/;"	m	class:cnn::DialogueBuilder
tgt_words	ext/encdec/encdec.h	/^    size_t tgt_words;$/;"	m	class:cnn::EncModel
time_ellapsed	ext/lda/lda.h	/^	std::vector<double> time_ellapsed; \/\/ time ellapsed after each iteration$/;"	m	class:ldaModel
time_embedding	cnn/expr-xtra.cc	/^vector<Expression> time_embedding(unsigned & slen, const vector<vector<int>>& source, ComputationGraph& cg, LookupParameters* p_cs, vector<cnn::real>& zero, size_t feat_dim, map<size_t, map<size_t, tExpression>>  &m_time_embedding_weight)$/;"	f
time_embedding_weight	cnn/expr-xtra.cc	/^Expression time_embedding_weight(size_t t, unsigned feat_dim, unsigned slen, ComputationGraph& cg, map<size_t, map<size_t, tExpression>> & m_time_embedding_weight)$/;"	f
to	cnn/nodes.h	/^  Dim to;$/;"	m	struct:cnn::Reshape
to_cxt	ext/dialogue/dialogue.h	/^    vector<Expression> to_cxt;  \/\/\/ this is the final_s from decoder RNNm$/;"	m	class:cnn::DialogueBuilder
to_cxt_value	ext/dialogue/dialogue.h	/^    map<int, vector<vector<cnn::real>>> to_cxt_value; \/\/\/ memory of to_cxt$/;"	m	class:cnn::DialogueBuilder
to_string	cnn/cnn-helper.h	/^    inline std::string to_string(T value)$/;"	f	namespace:cnn
topic_of	ext/lda/lda.h	/^int ldaModel::topic_of(int m)$/;"	f	class:ldaModel
trace_of_product	cnn/expr.cc	/^Expression trace_of_product(const Expression& x, const Expression& y) {return Expression(x.pg, x.pg->add_function<TraceOfProduct>({x.i, y.i}));}$/;"	f	namespace:cnn::expr
train	examples/attentional.cc	/^void train(Model &model, AM_t &am, Corpus &training, Corpus &devel, $/;"	f
train	examples/rnnlm2.cc	/^void train(Model &model, LM_t &lm,$/;"	f
train	examples/rnnlm2_cls_based.cc	/^void train(Model &model, LM_t &lm,$/;"	f
train	exp/encdec/encdec.bat	/^:train$/;"	l
train	ext/lda/lda.h	/^int ldaModel::train()$/;"	f	class:ldaModel
train	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::train(Model &model, AM_t &am, Corpus &training, Corpus &devel,$/;"	f	class:TrainProcess
train	ext/trainer/train_proc.h	/^void TrainProcess<AM_t>::train(Model &model, AM_t &am, TupleCorpus &training, Trainer &sgd, string out_file, int max_epochs)$/;"	f	class:TrainProcess
training_numturn2did	ext/trainer/train_proc.h	/^NumTurn2DialogId training_numturn2did;$/;"	v
training_score_buf_size	ext/trainer/train_proc.h	/^    int training_score_buf_size;$/;"	m	struct:TrainingScores
training_score_current_location	ext/trainer/train_proc.h	/^    int training_score_current_location;$/;"	m	struct:TrainingScores
training_scores	ext/trainer/train_proc.h	/^    cnn::real *training_scores;$/;"	m	struct:TrainingScores
training_set_scores	ext/trainer/train_proc.h	/^    TrainingScores* training_set_scores;$/;"	m	class:TrainProcess
transition	cnn/rnn-state-machine.h	/^  void transition(RNNOp op) {$/;"	f	class:cnn::RNNStateMachine
transpose	cnn/dim.h	/^  inline Dim transpose() const {$/;"	f	struct:cnn::Dim
transpose	cnn/expr.cc	/^Expression transpose(const Expression& x) { return Expression(x.pg, x.pg->add_function<Transpose>({x.i})); }$/;"	f	namespace:cnn::expr
triplet	cnn/data-util.h	/^struct triplet$/;"	s
trngdata	ext/lda/lda.h	/^	Sentences trngdata;				\/\/ training dataset$/;"	m	class:ldaModel
trngresponses	ext/lda/lda.h	/^    Sentences trngresponses;         \/\/ responses$/;"	m	class:ldaModel
true_attention_layer	ext/dialogue/attention_with_intention.h	/^    ReluDNNBuilder true_attention_layer;$/;"	m	class:cnn::AWI_InputFeedingWithNNAttention
truncate	cnn/dim.h	/^  inline Dim truncate() const {$/;"	f	struct:cnn::Dim
tuple_main_body	ext/trainer/train_proc_wrapper.h	/^int tuple_main_body(variables_map vm, size_t nreplicate = 0, size_t decoder_additiona_input_to = 0, size_t mem_slots = MEM_SIZE)$/;"	f
turn	exp/lm/create_lm_class.py	/^turn = 0$/;"	v
turn	exp/lm/lm.py	/^turn = 0$/;"	v
turnid	ext/dialogue/attention_with_intention.h	/^    size_t turnid;$/;"	m	class:cnn::DynamicMemoryNetDialogue
turnid	ext/dialogue/dialogue.h	/^    size_t turnid;$/;"	m	class:cnn::DialogueBuilder
turnid	ext/encdec/encdec.h	/^    size_t turnid;$/;"	m	class:cnn::EncModel
twords	ext/dialogue/dialogue_process.h	/^        int twords;$/;"	m	class:cnn::DialogueProcessInfo
twords	ext/trainer/train_proc.h	/^    long twords; \/\/\/ target side number of words$/;"	m	struct:TrainingScores
ty	cnn/nodes.h	/^  unsigned ty;$/;"	m	struct:cnn::PoissonRegressionLoss
unaryExprKernel	cnn/gpu-kernels.h	/^__global__ void unaryExprKernel(int n, const cnn::real* x, cnn::real* y, Func func) {$/;"	f	namespace:cnn::gpu
unicnt	ext/ngram/ngram.h	/^    tUniCount unicnt;$/;"	m	class:nGram
unk_id	cnn/dict.h	/^  int unk_id; $/;"	m	class:cnn::stDict
update	cnn/training.cc	/^void AdadeltaTrainer::update(cnn::real nutt, cnn::real scale) {$/;"	f	class:cnn::AdadeltaTrainer
update	cnn/training.cc	/^void AdagradTrainer::update(cnn::real nsamples, cnn::real scale) {$/;"	f	class:cnn::AdagradTrainer
update	cnn/training.cc	/^void AdamTrainer::update(cnn::real nutt, cnn::real scale) {$/;"	f	class:cnn::AdamTrainer
update	cnn/training.cc	/^void MomentumSGDTrainer::update(cnn::real nutt, cnn::real scale) {$/;"	f	class:cnn::MomentumSGDTrainer
update	cnn/training.cc	/^void RmsPropTrainer::update(cnn::real nutt, cnn::real scale) {$/;"	f	class:cnn::RmsPropTrainer
update	cnn/training.cc	/^void RmsPropWithMomentumTrainer::update(cnn::real nutt, cnn::real scale) {$/;"	f	class:cnn::RmsPropWithMomentumTrainer
update	cnn/training.cc	/^void SimpleSGDTrainer::update(cnn::real nutt, cnn::real scale) {$/;"	f	class:cnn::SimpleSGDTrainer
update	cnn/training.cc	/^void SimpleSGDTrainer::update(const std::vector<LookupParameters*> &lookup_params, const std::vector<Parameters*> &params, cnn::real samples, cnn::real scale) {$/;"	f	class:cnn::SimpleSGDTrainer
update_epoch	cnn/training.h	/^  void update_epoch(cnn::real r = 1) {$/;"	f	struct:cnn::Trainer
update_memory	cnn/rnnem.cc	/^    vector<Expression> NMNBuilder::update_memory(const int& t, const Expression & x_t, $/;"	f	class:cnn::NMNBuilder
updates	cnn/training.h	/^  cnn::real updates;$/;"	m	struct:cnn::Trainer
used	cnn/aligned-mem-pool.h	/^  unsigned long used;$/;"	m	class:cnn::AlignedMemoryPool
utf8_to_wstring	cnn/data-util.cc	/^std::wstring utf8_to_wstring(const std::string& str)$/;"	f
v	cnn/tensor.h	/^  cnn::real* v;$/;"	m	struct:cnn::Tensor
v	cnn/training.h	/^  std::vector<ShadowParameters> v; \/\/ History of deltas$/;"	m	struct:cnn::AdamTrainer
vNumTurns	cnn/data-util.h	/^    vector<int> vNumTurns;  \/\/\/ vector saving number of turns to be accessed, can shuffle this vector so that the access of dialogues are randomized$/;"	m	struct:__anon18
vWordEmbedding	ext/trainer/eval_proc.h	/^    map<int, vector<cnn::real>> vWordEmbedding;$/;"	m	class:EvaluateProcess
v_att_gate_b	ext/dialogue/attention_with_intention.h	/^    Expression i_att_gate_A, i_att_gate_b, v_att_gate_b;$/;"	m	class:cnn::GatedAttention
v_decoder	ext/dialogue/dialogue.h	/^    vector<Decoder*> v_decoder;$/;"	m	class:cnn::DialogueBuilder
v_decoder_context	ext/dialogue/dialogue.h	/^    vector<vector<Expression>> v_decoder_context; \/\/\/\/ [nutt][rep_hidden * layers] $/;"	m	class:cnn::DialogueBuilder
v_encoder_bwd	ext/dialogue/dialogue.h	/^    vector<Builder*> v_encoder_fwd, v_encoder_bwd;$/;"	m	class:cnn::DialogueBuilder
v_encoder_fwd	ext/dialogue/dialogue.h	/^    vector<Builder*> v_encoder_fwd, v_encoder_bwd;$/;"	m	class:cnn::DialogueBuilder
v_errs	ext/dialogue/attention_with_intention.h	/^    vector<Expression> v_errs;$/;"	m	class:cnn::DynamicMemoryNetDialogue
v_errs	ext/dialogue/dialogue.h	/^    vector<Expression> v_errs;$/;"	m	class:cnn::DialogueBuilder
v_errs	ext/encdec/encdec.h	/^    vector<Expression> v_errs;$/;"	m	class:cnn::EncModel
v_max_ent_obs	ext/dialogue/attention_with_intention.h	/^    vector<Expression> v_max_ent_obs; \/\/\/ observation from max-ent feature$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
v_max_ent_obs	ext/dialogue/attention_with_intention.h	/^    vector<Expression> v_max_ent_obs; \/\/\/ observation from max-ent feature$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
v_parameters_exp	ext/encdec/encdec.h	/^    vector<Expression> v_parameters_exp;$/;"	m	class:cnn::EncModel
v_src	ext/dialogue/attention_with_intention.h	/^    vector<Expression> v_src;$/;"	m	class:cnn::DynamicMemoryNetDialogue
v_src	ext/dialogue/dialogue.h	/^    vector<Expression> v_src;$/;"	m	class:cnn::DialogueBuilder
v_src	ext/encdec/encdec.h	/^    vector<Expression> v_src;$/;"	m	class:cnn::EncModel
val	cnn/nodes.h	/^  unsigned val;$/;"	m	struct:cnn::PickElement
value	cnn/expr.h	/^  const Tensor& value() { return pg->get_value(i); }$/;"	f	struct:cnn::expr::Expression
values	cnn/model.h	/^  Tensor values;$/;"	m	struct:cnn::Parameters
values	cnn/model.h	/^  std::vector<Tensor> values;$/;"	m	struct:cnn::LookupParameters
values_for_non_zero_grads	cnn/model.h	/^  std::unordered_map<unsigned, Tensor> values_for_non_zero_grads;$/;"	m	struct:cnn::LookupParameters
vanilla_sampling	ext/lda/lda.h	/^int ldaModel::vanilla_sampling(const Sentence& obs)$/;"	f	class:ldaModel
vanilla_sampling	ext/lda/lda.h	/^int ldaModel::vanilla_sampling(int m)$/;"	f	class:ldaModel
vec	cnn/tensor.h	/^  Eigen::Map<EVector, Eigen::Unaligned> vec() {$/;"	f	struct:cnn::Tensor
vec	cnn/tensor.h	/^  const Eigen::Map<EVector, Eigen::Unaligned> vec() const {$/;"	f	struct:cnn::Tensor
vec2exp	cnn/data-util.cc	/^Expression vec2exp(const vector<cnn::real>& v_data, ComputationGraph& cg)$/;"	f
velocity_allocated	cnn/training.h	/^  bool velocity_allocated;$/;"	m	struct:cnn::MomentumSGDTrainer
verbose	examples/attentional.cc	/^bool verbose;$/;"	v
verbose	examples/rnnlm2.cc	/^int verbose = 0; $/;"	v
verbose	examples/rnnlm2_cls_based.cc	/^int verbose = 0; $/;"	v
verbose	ext/trainer/train_proc.h	/^int verbose;$/;"	v
vlp	cnn/training.h	/^    std::vector<ShadowLookupParameters> vlp;$/;"	m	struct:cnn::RmsPropWithMomentumTrainer
vlp	cnn/training.h	/^  std::vector<ShadowLookupParameters> vlp;$/;"	m	struct:cnn::AdagradTrainer
vlp	cnn/training.h	/^  std::vector<ShadowLookupParameters> vlp;$/;"	m	struct:cnn::MomentumSGDTrainer
vocab_size	examples/cxtattentional.h	/^    int vocab_size;$/;"	m	struct:cnn::CxtAttentionalModel
vocab_size	ext/dialogue/attention_with_intention.h	/^    int vocab_size;$/;"	m	class:cnn::DynamicMemoryNetDialogue
vocab_size	ext/dialogue/dialogue.h	/^    unsigned vocab_size;$/;"	m	class:cnn::DialogueBuilder
vocab_size	ext/encdec/encdec.h	/^    int vocab_size;$/;"	m	class:cnn::EncModel
vocab_size	ext/ir/ir.h	/^        int vocab_size; \/\/\/ input vocabulary size$/;"	m	class:cnn::ClassificationEncoderDecoder
vocab_size	ext/ngram/ngram.h	/^    unsigned long vocab_size;$/;"	m	class:nGram
vocab_size_tgt	examples/attentional.h	/^    unsigned vocab_size_tgt;$/;"	m	struct:cnn::AttentionalModel
vocab_size_tgt	ext/dialogue/attention_with_intention.h	/^    int vocab_size_tgt;$/;"	m	class:cnn::DynamicMemoryNetDialogue
vocab_size_tgt	ext/dialogue/dialogue.h	/^    unsigned vocab_size_tgt;$/;"	m	class:cnn::DialogueBuilder
vp	cnn/training.h	/^    std::vector<ShadowParameters> vp;$/;"	m	struct:cnn::RmsPropWithMomentumTrainer
vp	cnn/training.h	/^  std::vector<ShadowParameters> vp;$/;"	m	struct:cnn::AdagradTrainer
vp	cnn/training.h	/^  std::vector<ShadowParameters> vp;$/;"	m	struct:cnn::MomentumSGDTrainer
vy	examples/regattentional.h	/^    std::vector<Expression> vy; \/\/\/ the target to predict$/;"	m	struct:cnn::RegAttentionalModel
w	cnn/rnnem.h	/^  std::vector<std::vector<Expression>> h, c, w;$/;"	m	struct:cnn::NMNBuilder
w0	cnn/rnnem.h	/^  std::vector<Expression> w0, h0, c0, M0;$/;"	m	struct:cnn::NMNBuilder
width	cnn/nodes.h	/^  unsigned width;$/;"	m	struct:cnn::MaxPooling1D
word2cls	cnn/approximator.h	/^        vector<long> word2cls;$/;"	m	class:cnn::ClsBasedBuilder
word2cls	examples/rnnlm2_cls_based.cc	/^  vector<long> word2cls;$/;"	m	struct:RNNLanguageModel	file:
wordid2vi	cnn/c2w.h	/^  std::map<int, VariableIndex> wordid2vi;$/;"	m	struct:cnn::C2WBuilder
words	cnn/c2w.h	/^  std::vector<VariableIndex> words;$/;"	m	struct:cnn::C2WBuilder
words_	cnn/dict.h	/^    T2IMap words_;$/;"	m	class:cnn::stId2String
words_	cnn/dict.h	/^  std::vector<T> words_;$/;"	m	class:cnn::stDict
wstring_to_utf8	cnn/data-util.cc	/^std::string wstring_to_utf8(const std::wstring& str)$/;"	f
z	ext/lda/lda.h	/^	int ** z;						\/\/ topic assignment for each word$/;"	m	class:ldaModel
zero	ext/dialogue/attention_with_intention.h	/^    vector<cnn::real> zero;$/;"	m	class:cnn::DynamicMemoryNetDialogue
zero	ext/dialogue/dialogue.h	/^    vector<cnn::real> zero;$/;"	m	class:cnn::DialogueBuilder
zero	ext/encdec/encdec.h	/^    vector<cnn::real> zero;$/;"	m	class:cnn::EncModel
zero_all	cnn/aligned-mem-pool.h	/^  void zero_all() {$/;"	f	class:cnn::AlignedMemoryPool
zero_allocated_memory	cnn/aligned-mem-pool.h	/^  void zero_allocated_memory() {$/;"	f	class:cnn::AlignedMemoryPool
zero_emb	ext/dialogue/attention_with_intention.h	/^    vector<cnn::real> zero_emb; $/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithMaxEntropyFeature
zero_emb	ext/dialogue/attention_with_intention.h	/^    vector<cnn::real> zero_emb;$/;"	m	class:cnn::AttMultiSource_LinearEncoder_WithHashingMaxEntropyFeature
zeroes	cnn/expr.cc	/^Expression zeroes(ComputationGraph& g, const Dim& d) { return Expression(&g, g.add_function<Zeroes>(d)); }$/;"	f	namespace:cnn::expr
~AlignedMemoryPool	cnn/aligned-mem-pool.h	/^  ~AlignedMemoryPool()$/;"	f	class:cnn::AlignedMemoryPool
~AttentionalModel	examples/attentional.h	/^AttentionalModel<Builder>::~AttentionalModel()$/;"	f	class:cnn::AttentionalModel
~BleuMetric	cnn/metric-util.h	/^    ~BleuMetric()$/;"	f	class:BleuMetric
~ClassificationEncoderDecoder	ext/ir/ir.h	/^        ~ClassificationEncoderDecoder()$/;"	f	class:cnn::ClassificationEncoderDecoder
~ClsBasedBuilder	cnn/approximator.h	/^        ~ClsBasedBuilder() {}$/;"	f	class:cnn::ClsBasedBuilder
~ClsBasedMultiSource_LinearEncoder	ext/dialogue/attention_with_intention.h	/^    ~ClsBasedMultiSource_LinearEncoder()$/;"	f	class:cnn::ClsBasedMultiSource_LinearEncoder
~ComputationGraph	cnn/cnn.cc	/^ComputationGraph::~ComputationGraph() {$/;"	f	class:cnn::ComputationGraph
~CxtAttentionalModel	examples/cxtattentional.h	/^CxtAttentionalModel<Builder>::~CxtAttentionalModel()$/;"	f	class:cnn::CxtAttentionalModel
~DNNBuilder	cnn/dnn.h	/^        ~DNNBuilder() {}$/;"	f	class:cnn::DNNBuilder
~DataReader	cnn/data-util.h	/^    ~DataReader() { m_ifs.close();  }$/;"	f	class:DataReader
~DialogueBuilder	ext/dialogue/dialogue.h	/^    ~DialogueBuilder(){$/;"	f	class:cnn::DialogueBuilder
~EncModel	ext/encdec/encdec.h	/^    ~EncModel(){};$/;"	f	class:cnn::EncModel
~ExecutionEngine	cnn/exec.cc	/^ExecutionEngine::~ExecutionEngine() {}$/;"	f	class:cnn::ExecutionEngine
~LookupParameters	cnn/model.cc	/^LookupParameters::~LookupParameters()$/;"	f	class:cnn::LookupParameters
~Model	cnn/model.cc	/^Model::~Model() {$/;"	f	class:cnn::Model
~Node	cnn/cnn.cc	/^Node::~Node() {}$/;"	f	class:cnn::Node
~Parameters	cnn/model.h	/^  ~Parameters() {$/;"	f	struct:cnn::Parameters
~ParametersBase	cnn/model.cc	/^ParametersBase::~ParametersBase() {}$/;"	f	class:cnn::ParametersBase
~RNNBuilder	cnn/rnn.cc	/^RNNBuilder::~RNNBuilder() {}$/;"	f	class:cnn::RNNBuilder
~RegAttentionalModel	examples/regattentional.h	/^    ~RegAttentionalModel(){};$/;"	f	struct:cnn::RegAttentionalModel
~RmsPropWithMomentumTrainer	cnn/training.cc	/^RmsPropWithMomentumTrainer::~RmsPropWithMomentumTrainer()$/;"	f	class:cnn::RmsPropWithMomentumTrainer
~Timer	cnn/timing.h	/^  ~Timer() {$/;"	f	struct:cnn::Timer
~TrainProcess	ext/trainer/train_proc.h	/^    ~TrainProcess()$/;"	f	class:TrainProcess
~Trainer	cnn/training.cc	/^Trainer::~Trainer() {}$/;"	f	class:cnn::Trainer
~TrainingScores	ext/trainer/train_proc.h	/^    ~TrainingScores()$/;"	f	struct:TrainingScores
~ldaModel	ext/lda/lda.h	/^ldaModel::~ldaModel()$/;"	f	class:ldaModel
